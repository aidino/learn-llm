{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhZfe4RyQNij"
   },
   "source": [
    "# MatFormer Lab\n",
    "\n",
    "`Gemma 3n` lÃ  má»™t mÃ´ hÃ¬nh Ä‘a phÆ°Æ¡ng thá»©c (`multimodal`), Ä‘a ngÃ´n ngá»¯ (`multilingual`) thuá»™c há» mÃ´ hÃ¬nh `Gemma`. Báº¡n cÃ³ thá»ƒ Ä‘á»c vá» `Gemma 3n` trong [tÃ i liá»‡u (docs)](https://www.google.com/search?q=https://ai.google.dev/gemma/docs/gemma2) vÃ  [bÃ i Ä‘Äƒng blog ra máº¯t](https://www.google.com/search?q=https://ai.google.dev/blog/gemma-2) cá»§a nÃ³. ÄÃ¢y lÃ  má»™t mÃ´ hÃ¬nh Ä‘á»™c Ä‘Ã¡o cÃ³ kháº£ nÄƒng co giÃ£n tá»± nhiÃªn (`natively elastic`), nghÄ©a lÃ  báº¡n sáº½ cÃ³ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c lá»“ng vÃ o nhau (`nested models`)\\! `Gemma 3n` Ä‘Æ°á»£c huáº¥n luyá»‡n nhÆ° má»™t mÃ´ hÃ¬nh `E4B` (effectively loads 4B parameters) vá»›i 35 lá»›p vÃ  16,384 FFN hidden dimension. NÃ³ cÃ³ má»™t mÃ´ hÃ¬nh `E2B` (30 lá»›p vÃ  8,192 FFN hidden dimension) Ä‘Æ°á»£c lá»“ng bÃªn trong vÃ  Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»“ng thá»i dÆ°á»›i dáº¡ng má»™t `MatFormer`.\n",
    "\n",
    "Kiáº¿n trÃºc [MatFormer](https://arxiv.org/abs/2310.07707) (ðŸª†`Matryoshka Transformer`) lÃ  má»™t kiáº¿n trÃºc `transformer` lá»“ng nhau má»›i láº¡ Ä‘Æ°á»£c xÃ¢y dá»±ng cho viá»‡c suy luáº­n co giÃ£n (`elastic inference`). HÃ£y tÆ°á»Ÿng tÆ°á»£ng nÃ³ giá»‘ng nhÆ° nhá»¯ng con bÃºp bÃª `Matryoshka`: má»™t mÃ´ hÃ¬nh lá»›n hÆ¡n chá»©a cÃ¡c phiÃªn báº£n nhá» hÆ¡n, Ä‘áº§y Ä‘á»§ chá»©c nÄƒng cá»§a chÃ­nh nÃ³. CÃ¡ch tiáº¿p cáº­n nÃ y má»Ÿ rá»™ng khÃ¡i niá»‡m cá»§a `Matryoshka Representation Learning` tá»« chá»‰ cÃ¡c `embeddings` sang táº¥t cáº£ cÃ¡c thÃ nh pháº§n cá»§a `transformer`.\n",
    "\n",
    "Viá»‡c tiáº¿t kiá»‡m bá»™ nhá»› báº±ng cÃ¡ch lá»“ng `E2B` bÃªn trong `E4B` lÃ  ráº¥t há»¯u Ã­ch trong thá»±c táº¿, nhÆ°ng Ä‘iá»u lÃ m cho `MatFormer` trá»Ÿ nÃªn máº¡nh máº½ lÃ  kháº£ nÄƒng cá»§a nÃ³ cÃ³ thá»ƒ tráº£i dÃ i mÆ°á»£t mÃ  trÃªn toÃ n bá»™ Ä‘Æ°á»ng cong tá»‘i Æ°u Pareto vá» Ä‘á»™ chÃ­nh xÃ¡c-so vá»›i-kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh (`Pareto-optimal accuracy-vs-model size curve`) giá»¯a `E2B` vÃ  `E4B` mÃ  khÃ´ng cáº§n huáº¥n luyá»‡n bá»• sung. Sá»­ dá»¥ng má»™t ká»¹ thuáº­t Ä‘Æ¡n giáº£n gá»i lÃ  `Mix-n-Match`, ngÆ°á»i ta cÃ³ thá»ƒ trÃ­ch xuáº¥t má»™t mÃ´ hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c báº¥t ká»³ giá»¯a `E2B` vÃ  `E4B` tá»« mÃ´ hÃ¬nh `E4B` chÃ­nh.\n",
    "\n",
    "Táº¡i sao báº¡n láº¡i muá»‘n \"cáº¯t lÃ¡t\" (`slice`) má»™t mÃ´ hÃ¬nh? Dá»±a trÃªn cÃ¡c yÃªu cáº§u triá»ƒn khai (`deployment requirements`) cá»¥ thá»ƒ cá»§a báº¡n, `E2B` vÃ  `E4B` cÃ³ thá»ƒ khÃ´ng pháº£i lÃ  lá»±a chá»n phÃ¹ há»£p. VÃ­ dá»¥, báº¡n cÃ³ thá»ƒ muá»‘n cÃ³ má»™t mÃ´ hÃ¬nh `E3B`, vá»›i cháº¥t lÆ°á»£ng cao hÆ¡n `E2B` trong khi yÃªu cáº§u Ã­t tÃ i nguyÃªn tÃ­nh toÃ¡n (`compute`) hÆ¡n `E4B`.\n",
    "\n",
    "Trong `notebook` nÃ y, báº¡n sáº½ Ä‘Æ°á»£c thá»­ nghiá»‡m vá»›i `MatFormers` vÃ  `Mix-n-Match`. Báº¡n sáº½ chá»‰ Ä‘á»‹nh cáº¥u hÃ¬nh mong muá»‘n cho mÃ´ hÃ¬nh con (`submodel`) dá»±a trÃªn chiá»u `FFN` vÃ  cÃ¡c lá»›p `skip layers`, vÃ  sau Ä‘Ã³ báº¡n sáº½ xuáº¥t mÃ´ hÃ¬nh sang `Hugging Face`, cho phÃ©p báº¡n sá»­ dá»¥ng nÃ³ vá»›i cÃ¡c cÃ´ng cá»¥ yÃªu thÃ­ch cá»§a mÃ¬nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102447,
     "status": "ok",
     "timestamp": 1753268463048,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "QNaYXucmP9sL",
    "outputId": "221c89ae-f33c-4e31-f429-c8ddb3da6094"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "# @markdown Run this cell to install all the required dependencies. In particular, you'll need Hugging Face `transformers` and `timm` versions that support Gemma 3n. Note that you may need to restart the notebook after executing the following cell.\n",
    "\n",
    "# Install a transformers version that supports Gemma 3n (>= 4.53)\n",
    "!pip install \"transformers>=4.53\" \"timm>=1.0.16\" -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303,
     "referenced_widgets": [
      "2f184c7541bb48b68ef4d9e908ec4632",
      "618290a83b8640cd92a04af53c8d3dc4",
      "fe7b3a7a08534c8fa0ffcd6d70ea679d",
      "4cc3f543f21e4502ab0e027cc99946ce",
      "4f941bd663bd4321b31d899c3818e5e6",
      "dc6fc547dd5f42a4a0b10b379a473102",
      "e901deb71818453ea0d452cfceae2347",
      "49bf2d6cc1da408faf6c752a9225e7dc",
      "337c2ba459e04d5a946b680e8598f21d",
      "ce064ed719b347f6a9ca629cadbfa609",
      "54aa43966e8d4649920516da818a5930",
      "de924f5124f3401680fa421244bc4cbd",
      "06d0c33c422f46c6b55daa6de076b53c",
      "b543af171d4443caa282d017daebcd05",
      "3bf3a6b3248b4aeeb6f5228e5d9c0d67",
      "86b0b1f8225145f088281f166cfa343a",
      "fa3d76524eab45129a1a0eaf7adafd75"
     ]
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1753268463848,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "frQhZJ9aQUAf",
    "outputId": "cc4ee566-2762-469b-fff0-708bc153b9c8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1adb57bc8e44cf19a4a1ee1c418dd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# @title Login to Hugging Face\n",
    "# @markdown This is required so you can push the model to Hugging Face. You also need to make sure you have access to the Gemma 3n model repositories.\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1753268463921,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "8c0G-3ajqPf-"
   },
   "outputs": [],
   "source": [
    "\n",
    "# @title Import and Export Options\n",
    "# @markdown The MatFormer Lab allows you to load a Gemma 3n 4B checkpoint (either pre-trained or instruct-tuned) and to slice it. Below, please specify:\n",
    "\n",
    "# @markdown * The original repository ID from the checkpoint in Hugging Face\n",
    "\n",
    "# @markdown * A local path where the model will be saved\n",
    "\n",
    "# @markdown * A name of a repository to push the new checkpoint to\n",
    "\n",
    "original_model_id = \"google/gemma-3n-E4B-it\" # @param [\"google/gemma-3n-E4B-it\", \"google/gemma-3n-E4B-pt\"]\n",
    "local_output_path = \"my_modified_gemma_3n_model\" # @param {type:\"string\"}\n",
    "push_hf_repo_id = \"ngohongthai/test-submodel\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avc-LkhGqo-o"
   },
   "source": [
    "## Cáº¥u hÃ¬nh cáº¯t lÃ¡t (Slicing configuration)\n",
    "\n",
    "LÃ  má»™t pháº§n cá»§a viá»‡c phÃ¡t hÃ nh `Gemma 3n`, chÃºng tÃ´i chia sáº» cÃ¡c cáº¥u hÃ¬nh cáº¯t lÃ¡t tá»‘i Æ°u dÆ°á»›i dáº¡ng má»™t kho dá»¯ liá»‡u (`dataset repository`) trÃªn **[Hugging Face](https://www.google.com/search?q=https://huggingface.co/datasets/google/gemma-3n-slicing-configs)**, máº·c dÃ¹ báº¡n cÅ©ng cÃ³ thá»ƒ tá»± khÃ¡m phÃ¡ cÃ¡c cáº¥u hÃ¬nh cá»§a riÃªng mÃ¬nh á»Ÿ bÃªn dÆ°á»›i.\n",
    "\n",
    "Má»—i cáº¥u hÃ¬nh sáº½ chá»‰ Ä‘á»‹nh:\n",
    "\n",
    "  * The hidden dimensions of the FFN\n",
    "  * Which layers, if any, to skip\n",
    "  * Äá»™ chÃ­nh xÃ¡c `MMLU` tÆ°Æ¡ng á»©ng vá»›i cÃ¡c `checkpoint` Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c\n",
    "  \n",
    "CÃ¡c cáº¥u hÃ¬nh cáº¥p Ä‘á»™ lá»›p (`layer-level`) vÃ  cáº¥p Ä‘á»™ khá»‘i (`block-level`) lÃ  káº¿t quáº£ cá»§a viá»‡c thay Ä‘á»•i chiá»u áº©n cá»§a `FFN` á»Ÿ cáº¥p Ä‘á»™ lá»›p (chi tiáº¿t - `fine-grained`) hoáº·c á»Ÿ cáº¥p Ä‘á»™ khá»‘i (4 lá»›p cá»¥c bá»™ + 1 lá»›p toÃ n cá»¥c).\n",
    "\n",
    "á»ž **cáº¥p Ä‘á»™ lá»›p (`layer-level`)**, chÃºng tÃ´i nháº­n tháº¥y ráº±ng viá»‡c cho cÃ¡c lá»›p toÃ n cá»¥c (`global layers`) (thay vÃ¬ cÃ¡c lá»›p cá»¥c bá»™ - `local layers`) cÃ³ nÄƒng lá»±c (`capacity`) cao hÆ¡n sáº½ giÃºp cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vá»›i cÃ¹ng má»™t kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh.\n",
    "\n",
    "á»ž **cáº¥p Ä‘á»™ khá»‘i (`block-level`)**, chÃºng tÃ´i tháº¥y ráº±ng khá»‘i bá»‹ bá» qua Ä‘á»‘i vá»›i `E2B` (tá»©c lÃ  cÃ¡c lá»›p 20-24) sáº½ Ä‘Æ°á»£c hÆ°á»Ÿng lá»£i tá»« nÄƒng lá»±c cao hÆ¡n khi khÃ´ng bá»‹ bá» qua, vÃ  cÃ¡c khá»‘i á»Ÿ táº§ng sá»›m hÆ¡n cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng tá»‘t vá»›i nÄƒng lá»±c tháº¥p hÆ¡n so vá»›i cÃ¡c khá»‘i á»Ÿ táº§ng sau.\n",
    "\n",
    "ChÃºng tÃ´i má»i cá»™ng Ä‘á»“ng cÃ¹ng tÃ¬m ra nhá»¯ng cáº¥u hÃ¬nh tá»‘t hÆ¡n ná»¯a náº±m trÃªn Ä‘Æ°á»ng cong tá»‘i Æ°u Pareto (`Pareto-optimal curve`) giá»¯a `E2B` vÃ  `E4B`\\!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 1756,
     "status": "ok",
     "timestamp": 1753268465656,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "s9EVWkANqdwK",
    "outputId": "b63dcfaa-2003-4e6a-a35b-9eb27b600531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th># Layers</th>\n",
       "      <th># Effective Params (B)</th>\n",
       "      <th>MMLU PT accuracy</th>\n",
       "      <th>FFN Hidden Dims</th>\n",
       "      <th>Layers Skipped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main model</td>\n",
       "      <td>35</td>\n",
       "      <td>3.98</td>\n",
       "      <td>62.30%</td>\n",
       "      <td>[2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Config for official E2B Model</td>\n",
       "      <td>30</td>\n",
       "      <td>1.91</td>\n",
       "      <td>50.90%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Config for E1.96B (layer-level)</td>\n",
       "      <td>30</td>\n",
       "      <td>1.96</td>\n",
       "      <td>53.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Config for E2.54B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.54</td>\n",
       "      <td>55.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Config for E2.69B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.69</td>\n",
       "      <td>57.70%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Config for E2.98B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.98</td>\n",
       "      <td>59.50%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Config for E3.18B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.18</td>\n",
       "      <td>61.80%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Config for E3.39B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.39</td>\n",
       "      <td>63.00%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Config for E3.59B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.59</td>\n",
       "      <td>63.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Config for E3.79B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.79</td>\n",
       "      <td>63.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Config for E2.49B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.49</td>\n",
       "      <td>54.50%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Config for E2.73B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.73</td>\n",
       "      <td>57.10%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Config for E2.98B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.98</td>\n",
       "      <td>59.50%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Config for E3.24B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.24</td>\n",
       "      <td>60.70%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Config for E3.49B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.49</td>\n",
       "      <td>61.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Config for E3.79B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.74</td>\n",
       "      <td>62.00%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name  # Layers  # Effective Params (B)  \\\n",
       "0                        Main model        35                    3.98   \n",
       "1     Config for official E2B Model        30                    1.91   \n",
       "2   Config for E1.96B (layer-level)        30                    1.96   \n",
       "3   Config for E2.54B (layer-level)        35                    2.54   \n",
       "4   Config for E2.69B (layer-level)        35                    2.69   \n",
       "5   Config for E2.98B (layer-level)        35                    2.98   \n",
       "6   Config for E3.18B (layer-level)        35                    3.18   \n",
       "7   Config for E3.39B (layer-level)        35                    3.39   \n",
       "8   Config for E3.59B (layer-level)        35                    3.59   \n",
       "9   Config for E3.79B (layer-level)        35                    3.79   \n",
       "10  Config for E2.49B (block-level)        35                    2.49   \n",
       "11  Config for E2.73B (block-level)        35                    2.73   \n",
       "12  Config for E2.98B (block-level)        35                    2.98   \n",
       "13  Config for E3.24B (block-level)        35                    3.24   \n",
       "14  Config for E3.49B (block-level)        35                    3.49   \n",
       "15  Config for E3.79B (block-level)        35                    3.74   \n",
       "\n",
       "   MMLU PT accuracy                                    FFN Hidden Dims  \\\n",
       "0            62.30%  [2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...   \n",
       "1            50.90%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "2            53.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "3            55.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "4            57.70%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "5            59.50%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "6            61.80%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "7            63.00%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "8            63.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "9            63.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "10           54.50%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "11           57.10%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "12           59.50%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "13           60.70%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "14           61.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "15           62.00%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "\n",
       "          Layers Skipped  \n",
       "0                    NaN  \n",
       "1   [20, 21, 22, 23, 24]  \n",
       "2   [20, 21, 22, 23, 24]  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "5                    NaN  \n",
       "6                    NaN  \n",
       "7                    NaN  \n",
       "8                    NaN  \n",
       "9                    NaN  \n",
       "10                   NaN  \n",
       "11                   NaN  \n",
       "12                   NaN  \n",
       "13                   NaN  \n",
       "14                   NaN  \n",
       "15                   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/google/gemma3n-slicing-configs/configs.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l15UQLqu3Ymd"
   },
   "source": [
    "Based on your deployment scenarios, you may want to pick a different config. Select below your preferred one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1753268465687,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "sVBfjQC_wirp"
   },
   "outputs": [],
   "source": [
    "#@title Config details\n",
    "import ast\n",
    "\n",
    "config_name = \"Config for E1.96B (layer-level)\"# @param ['Config for official E2B Model', 'Config for E1.96B (layer-level)', 'Config for E2.54B (layer-level)', 'Config for E2.69B (layer-level)', 'Config for E2.98B (layer-level)', 'Config for E3.18B (layer-level)', 'Config for E3.39B (layer-level)', 'Config for E3.59B (layer-level)', 'Config for E3.79B (layer-level)', 'Config for E2.49B (block-level)', 'Config for E2.73B (block-level)', 'Config for E2.98B (block-level)', 'Config for E3.24B (block-level)', 'Config for E3.49B (block-level)', 'Config for E3.79B (block-level)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1753268465769,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "kJsmisb93qEy"
   },
   "outputs": [],
   "source": [
    "def safe_string_to_list(value):\n",
    "    \"\"\"\n",
    "    Converts a string representation of a list into a Python list.\n",
    "    - Converts NaN/missing values to an empty list [].\n",
    "    - Uses eval() to handle expressions like '2_048 * 8'.\n",
    "    - Safely handles non-string values by returning them as is.\n",
    "    \"\"\"\n",
    "    # First, check if the value is missing (NaN, None, etc.)\n",
    "    if isinstance(value, list):\n",
    "        return value\n",
    "\n",
    "    # Priority 2: Now that we know it's not a list, check if it's a missing value.\n",
    "    if pd.isna(value):\n",
    "        return []\n",
    "\n",
    "    # Priority 3: If it's a string, try to evaluate it.\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            return eval(value)\n",
    "        except (SyntaxError, NameError):\n",
    "            return value  # Return invalid string as is\n",
    "\n",
    "    # Fallback for any other type (like an integer)\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1753268465770,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "jzkaQNUa4R9z",
    "outputId": "ab2b1b66-df36-46c4-f0c9-30eec5b89cc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval('2_048 * 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1753268465775,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "b8dnVr1X4WdX",
    "outputId": "2ba7695c-1d99-49c0-a058-ae8c5840d862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Config for E1.96B (layer-level)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1753268465821,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "zcc2vrBH4iAI",
    "outputId": "8fe872bb-c1b5-4d13-c12c-46d9248052b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FFN Hidden Dims'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1753268465836,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "RWmj5b7E5RUL",
    "outputId": "a55e808d-9717-4b34-90a7-323b1d521154"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 21, 22, 23, 24]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_string_to_list('[20, 21, 22, 23, 24]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1753268465854,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "sfHxOvtv5ayA"
   },
   "outputs": [],
   "source": [
    "df['FFN Hidden Dims List'] = df['FFN Hidden Dims'].apply(safe_string_to_list)\n",
    "df['Layers Skipped'] = df['Layers Skipped'].apply(safe_string_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1753268465890,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "l_bdKfon5pHZ",
    "outputId": "a1424137-279a-4ae3-93a5-04642076ad42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th># Layers</th>\n",
       "      <th># Effective Params (B)</th>\n",
       "      <th>MMLU PT accuracy</th>\n",
       "      <th>FFN Hidden Dims</th>\n",
       "      <th>Layers Skipped</th>\n",
       "      <th>FFN Hidden Dims List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main model</td>\n",
       "      <td>35</td>\n",
       "      <td>3.98</td>\n",
       "      <td>62.30%</td>\n",
       "      <td>[2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[16384, 16384, 16384, 16384, 16384, 16384, 163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Config for official E2B Model</td>\n",
       "      <td>30</td>\n",
       "      <td>1.91</td>\n",
       "      <td>50.90%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 8192, 8192, 8192, 819...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Config for E1.96B (layer-level)</td>\n",
       "      <td>30</td>\n",
       "      <td>1.96</td>\n",
       "      <td>53.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Config for E2.54B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.54</td>\n",
       "      <td>55.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Config for E2.69B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.69</td>\n",
       "      <td>57.70%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  # Layers  # Effective Params (B)  \\\n",
       "0                       Main model        35                    3.98   \n",
       "1    Config for official E2B Model        30                    1.91   \n",
       "2  Config for E1.96B (layer-level)        30                    1.96   \n",
       "3  Config for E2.54B (layer-level)        35                    2.54   \n",
       "4  Config for E2.69B (layer-level)        35                    2.69   \n",
       "\n",
       "  MMLU PT accuracy                                    FFN Hidden Dims  \\\n",
       "0           62.30%  [2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...   \n",
       "1           50.90%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "2           53.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "3           55.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "4           57.70%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "\n",
       "         Layers Skipped                               FFN Hidden Dims List  \n",
       "0                    []  [16384, 16384, 16384, 16384, 16384, 16384, 163...  \n",
       "1  [20, 21, 22, 23, 24]  [8192, 8192, 8192, 8192, 8192, 8192, 8192, 819...  \n",
       "2  [20, 21, 22, 23, 24]  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  \n",
       "3                    []  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  \n",
       "4                    []  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1753268465914,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "rji240NZ5qU4",
    "outputId": "5f45ffc3-1a87-483a-e771-537cee84cdc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Layers</th>\n",
       "      <th># Effective Params (B)</th>\n",
       "      <th>MMLU PT accuracy</th>\n",
       "      <th>FFN Hidden Dims</th>\n",
       "      <th>Layers Skipped</th>\n",
       "      <th>FFN Hidden Dims List</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Main model</th>\n",
       "      <td>35</td>\n",
       "      <td>3.98</td>\n",
       "      <td>62.30%</td>\n",
       "      <td>[2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[16384, 16384, 16384, 16384, 16384, 16384, 163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Config for official E2B Model</th>\n",
       "      <td>30</td>\n",
       "      <td>1.91</td>\n",
       "      <td>50.90%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 8192, 8192, 8192, 819...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Config for E1.96B (layer-level)</th>\n",
       "      <td>30</td>\n",
       "      <td>1.96</td>\n",
       "      <td>53.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Config for E2.54B (layer-level)</th>\n",
       "      <td>35</td>\n",
       "      <td>2.54</td>\n",
       "      <td>55.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Config for E2.69B (layer-level)</th>\n",
       "      <td>35</td>\n",
       "      <td>2.69</td>\n",
       "      <td>57.70%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 # Layers  # Effective Params (B)  \\\n",
       "name                                                                \n",
       "Main model                             35                    3.98   \n",
       "Config for official E2B Model          30                    1.91   \n",
       "Config for E1.96B (layer-level)        30                    1.96   \n",
       "Config for E2.54B (layer-level)        35                    2.54   \n",
       "Config for E2.69B (layer-level)        35                    2.69   \n",
       "\n",
       "                                MMLU PT accuracy  \\\n",
       "name                                               \n",
       "Main model                                62.30%   \n",
       "Config for official E2B Model             50.90%   \n",
       "Config for E1.96B (layer-level)           53.40%   \n",
       "Config for E2.54B (layer-level)           55.40%   \n",
       "Config for E2.69B (layer-level)           57.70%   \n",
       "\n",
       "                                                                   FFN Hidden Dims  \\\n",
       "name                                                                                 \n",
       "Main model                       [2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...   \n",
       "Config for official E2B Model    [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "Config for E1.96B (layer-level)  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "Config for E2.54B (layer-level)  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "Config for E2.69B (layer-level)  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "\n",
       "                                       Layers Skipped  \\\n",
       "name                                                    \n",
       "Main model                                         []   \n",
       "Config for official E2B Model    [20, 21, 22, 23, 24]   \n",
       "Config for E1.96B (layer-level)  [20, 21, 22, 23, 24]   \n",
       "Config for E2.54B (layer-level)                    []   \n",
       "Config for E2.69B (layer-level)                    []   \n",
       "\n",
       "                                                              FFN Hidden Dims List  \n",
       "name                                                                                \n",
       "Main model                       [16384, 16384, 16384, 16384, 16384, 16384, 163...  \n",
       "Config for official E2B Model    [8192, 8192, 8192, 8192, 8192, 8192, 8192, 819...  \n",
       "Config for E1.96B (layer-level)  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  \n",
       "Config for E2.54B (layer-level)  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  \n",
       "Config for E2.69B (layer-level)  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indexed = df.set_index('name')\n",
    "df_indexed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1753268465917,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "632fXqkA50Bx",
    "outputId": "4f09a9b4-8836-4223-86fd-05df30e16c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Layers                                                                 30\n",
       "# Effective Params (B)                                                 1.96\n",
       "MMLU PT accuracy                                                     53.40%\n",
       "FFN Hidden Dims           [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...\n",
       "Layers Skipped                                         [20, 21, 22, 23, 24]\n",
       "FFN Hidden Dims List      [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...\n",
       "Name: Config for E1.96B (layer-level), dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_row = df_indexed.loc[config_name]\n",
    "model_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1753268465921,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "re0L_h-S55Da",
    "outputId": "dd1837aa-a990-4b65-9c24-b8cc060f7bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config for E1.96B (layer-level)\n",
      "\n",
      "Layers Skipped:\n",
      "[20, 21, 22, 23, 24]\n",
      "\n",
      "FFN Hidden Dims:\n",
      "[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 8, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4]\n"
     ]
    }
   ],
   "source": [
    "layers_to_skip = model_row['Layers Skipped']\n",
    "ffn_hidden_dims = model_row['FFN Hidden Dims List']\n",
    "ffn_hidden_dims_str = model_row['FFN Hidden Dims']\n",
    "\n",
    "print(config_name)\n",
    "print(\"\\nLayers Skipped:\")\n",
    "print(layers_to_skip)\n",
    "print(\"\\nFFN Hidden Dims:\")\n",
    "print(ffn_hidden_dims_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1753268465941,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "lpEM1nV86ARI"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom config\n",
    "#\n",
    "# layers_to_skip = [] # e.g. [20, 21, 22, 23, 24]\n",
    "# ffn_hidden_dims = [] # e.g. [2048 * 4, ...]\n",
    "# ffn_hidden_dims_str = str(ffn_hidden_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3R4IbLcZ6QEg"
   },
   "source": [
    "## Slicing\n",
    "\n",
    "### Load the model config and verify slicing configuration\n",
    "\n",
    "Note: we do not load the model at this stage, just verify that the slicing configuration is possible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1753268465944,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "j2orDbHz6ItA",
    "outputId": "28daa584-7269-4ad0-a01c-4060092df60c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google/gemma-3n-E4B-it'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "987550d76b7d45549096cb07928a3278",
      "2079304e45244ec1b53d73e02bff102a",
      "a5f3b3e2bdfd4b49b797b54d3fe6e314",
      "01c902390b5340c9871a4bd30cbe7aad",
      "7c2f552a824f4077a525937e84a40111",
      "527ebf26b7dd4b94a40c9be6dbd7a4c7",
      "5495552f37b6485d8f749fbed718205d",
      "fff785435c9a48a39b5b329ba62df081",
      "4ff13942afcc4592a9495f77756d924e",
      "eb24b163af204e7298ba259e7bbc5965",
      "5aa3381a60404ac9947d88f126d49745"
     ]
    },
    "executionInfo": {
     "elapsed": 33303,
     "status": "ok",
     "timestamp": 1753268499253,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "dz-KdBMR69xo",
    "outputId": "2775816c-a344-4baa-c5ea-6292324fe01d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2a80e5112d46f1b84c0663bbafc7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "original_config = AutoConfig.from_pretrained(original_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1753269284317,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "K9_nvWDy7Vml",
    "outputId": "735be0ca-badf-4982-b586-f6323053ec61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3nConfig {\n",
       "  \"architectures\": [\n",
       "    \"Gemma3nForConditionalGeneration\"\n",
       "  ],\n",
       "  \"audio_config\": {\n",
       "    \"conf_attention_chunk_size\": 12,\n",
       "    \"conf_attention_context_left\": 13,\n",
       "    \"conf_attention_context_right\": 0,\n",
       "    \"conf_attention_logit_cap\": 50.0,\n",
       "    \"conf_conv_kernel_size\": 5,\n",
       "    \"conf_num_attention_heads\": 8,\n",
       "    \"conf_num_hidden_layers\": 12,\n",
       "    \"conf_reduction_factor\": 4,\n",
       "    \"conf_residual_weight\": 0.5,\n",
       "    \"gradient_clipping\": 10000000000.0,\n",
       "    \"hidden_size\": 1536,\n",
       "    \"input_feat_size\": 128,\n",
       "    \"model_type\": \"gemma3n_audio\",\n",
       "    \"rms_norm_eps\": 1e-06,\n",
       "    \"sscp_conv_channel_size\": [\n",
       "      128,\n",
       "      32\n",
       "    ],\n",
       "    \"sscp_conv_group_norm_eps\": 0.001,\n",
       "    \"sscp_conv_kernel_size\": [\n",
       "      [\n",
       "        3,\n",
       "        3\n",
       "      ],\n",
       "      [\n",
       "        3,\n",
       "        3\n",
       "      ]\n",
       "    ],\n",
       "    \"sscp_conv_stride_size\": [\n",
       "      [\n",
       "        2,\n",
       "        2\n",
       "      ],\n",
       "      [\n",
       "        2,\n",
       "        2\n",
       "      ]\n",
       "    ],\n",
       "    \"torch_dtype\": \"bfloat16\",\n",
       "    \"vocab_offset\": 262272,\n",
       "    \"vocab_size\": 128\n",
       "  },\n",
       "  \"audio_soft_tokens_per_image\": 188,\n",
       "  \"audio_token_id\": 262273,\n",
       "  \"boa_token_id\": 256000,\n",
       "  \"boi_token_id\": 255999,\n",
       "  \"eoa_token_id\": 262272,\n",
       "  \"eoi_token_id\": 262144,\n",
       "  \"eos_token_id\": [\n",
       "    1,\n",
       "    106\n",
       "  ],\n",
       "  \"image_token_id\": 262145,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"model_type\": \"gemma3n\",\n",
       "  \"text_config\": {\n",
       "    \"activation_sparsity_pattern\": [\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0\n",
       "    ],\n",
       "    \"altup_active_idx\": 0,\n",
       "    \"altup_coef_clip\": 120.0,\n",
       "    \"altup_correct_scale\": true,\n",
       "    \"altup_num_inputs\": 4,\n",
       "    \"attention_bias\": false,\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"final_logit_softcapping\": 30.0,\n",
       "    \"head_dim\": 256,\n",
       "    \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
       "    \"hidden_size\": 2048,\n",
       "    \"hidden_size_per_layer_input\": 256,\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"intermediate_size\": [\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384\n",
       "    ],\n",
       "    \"laurel_rank\": 64,\n",
       "    \"layer_types\": [\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\"\n",
       "    ],\n",
       "    \"max_position_embeddings\": 32768,\n",
       "    \"model_type\": \"gemma3n_text\",\n",
       "    \"num_attention_heads\": 8,\n",
       "    \"num_hidden_layers\": 35,\n",
       "    \"num_key_value_heads\": 2,\n",
       "    \"num_kv_shared_layers\": 15,\n",
       "    \"rms_norm_eps\": 1e-06,\n",
       "    \"rope_local_base_freq\": 10000.0,\n",
       "    \"rope_scaling\": null,\n",
       "    \"rope_theta\": 1000000.0,\n",
       "    \"sliding_window\": 512,\n",
       "    \"torch_dtype\": \"bfloat16\",\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 262400,\n",
       "    \"vocab_size_per_layer_input\": 262144\n",
       "  },\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.53.1\",\n",
       "  \"vision_config\": {\n",
       "    \"architecture\": \"mobilenetv5_300m_enc\",\n",
       "    \"do_pooling\": false,\n",
       "    \"hidden_size\": 2048,\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"label_names\": [\n",
       "      \"LABEL_0\",\n",
       "      \"LABEL_1\"\n",
       "    ],\n",
       "    \"model_args\": null,\n",
       "    \"model_type\": \"gemma3n_vision\",\n",
       "    \"num_classes\": 2,\n",
       "    \"rms_norm_eps\": 1e-06,\n",
       "    \"torch_dtype\": \"bfloat16\",\n",
       "    \"vocab_offset\": 262144,\n",
       "    \"vocab_size\": 128\n",
       "  },\n",
       "  \"vision_soft_tokens_per_image\": 256\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1753269331385,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "wYcgygMv_ixE",
    "outputId": "98786dcd-a747-47e9-8d2d-8c037db49222"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3nTextConfig {\n",
       "  \"activation_sparsity_pattern\": [\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0\n",
       "  ],\n",
       "  \"altup_active_idx\": 0,\n",
       "  \"altup_coef_clip\": 120.0,\n",
       "  \"altup_correct_scale\": true,\n",
       "  \"altup_num_inputs\": 4,\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"final_logit_softcapping\": 30.0,\n",
       "  \"head_dim\": 256,\n",
       "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
       "  \"hidden_size\": 2048,\n",
       "  \"hidden_size_per_layer_input\": 256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": [\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384\n",
       "  ],\n",
       "  \"laurel_rank\": 64,\n",
       "  \"layer_types\": [\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\"\n",
       "  ],\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"model_type\": \"gemma3n_text\",\n",
       "  \"num_attention_heads\": 8,\n",
       "  \"num_hidden_layers\": 35,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"num_kv_shared_layers\": 15,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_local_base_freq\": 10000.0,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": 512,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.53.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 262400,\n",
       "  \"vocab_size_per_layer_input\": 262144\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = original_config.text_config\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1753269731767,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "7L74MGMc_uR8",
    "outputId": "19cfbdeb-c4ac-424b-e50f-742ecfba8eaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layers = model_config.num_hidden_layers\n",
    "num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1753269758970,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "l_qJZDssBQBd",
    "outputId": "1d47298c-b635-4b00-c09b-144b749450c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 21, 22, 23, 24]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1753269807635,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "k0F93g1hBWrW",
    "outputId": "8fcacdb4-8873-4cbe-e3c8-1dbbd6991d5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_num_layers = num_layers - len(layers_to_skip)\n",
    "final_num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1753269824807,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "idCvehXaBgmm"
   },
   "outputs": [],
   "source": [
    "if len(ffn_hidden_dims) != final_num_layers:\n",
    "    raise ValueError(\n",
    "        f\"The length of ffn_hidden_dims ({len(ffn_hidden_dims)}) must be equal \"\n",
    "        f\"to the final number of layers ({final_num_layers}).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxOgxRxTBtKT"
   },
   "source": [
    "### Update configuration\n",
    "\n",
    " Khi báº¡n quyáº¿t Ä‘á»‹nh \"cáº¯t bá»\" má»™t sá»‘ lá»›p (vÃ­ dá»¥, bá» 5 lá»›p Ä‘á»ƒ táº¡o mÃ´ hÃ¬nh 30 lá»›p), khÃ´ng chá»‰ sá»‘ lÆ°á»£ng lá»›p thay Ä‘á»•i, mÃ  cÃ¡c tham sá»‘ cáº¥u hÃ¬nh khÃ¡c liÃªn quan Ä‘áº¿n cÃ¡c lá»›p Ä‘Ã³ cÅ©ng pháº£i Ä‘Æ°á»£c cáº­p nháº­t má»™t cÃ¡ch thÃ´ng minh. Äoáº¡n code nÃ y lÃ m chÃ­nh xÃ¡c Ä‘iá»u Ä‘Ã³."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cáº­p nháº­t cáº¥u hÃ¬nh chia sáº» Key-Value (KV Sharing):\n",
    "\n",
    "* **Má»¥c Ä‘Ã­ch**: Gemma 3n sá»­ dá»¥ng má»™t ká»¹ thuáº­t gá»i lÃ  KV Sharing Ä‘á»ƒ tiáº¿t kiá»‡m bá»™ nhá»›, trong Ä‘Ã³ má»™t sá»‘ lá»›p sáº½ chia sáº» chung cÃ¡c tham sá»‘ Key (K) vÃ  Value (V) trong cÆ¡ cháº¿ attention. Äoáº¡n code nÃ y Ä‘áº£m báº£o cáº¥u hÃ¬nh KV Sharing Ä‘Æ°á»£c cáº­p nháº­t Ä‘Ãºng khi cÃ¡c lá»›p bá»‹ loáº¡i bá».\n",
    "* **Ã nghÄ©a cÃ¡c biáº¿n**:\n",
    "    * `model_config.num_hidden_layers`: Tá»•ng sá»‘ lá»›p cá»§a mÃ´ hÃ¬nh gá»‘c (lÃ  35).\n",
    "    * `model_config.num_kv_shared_layers`: Sá»‘ lÆ°á»£ng lá»›p chia sáº» KV trong mÃ´ hÃ¬nh gá»‘c.\n",
    "    * `layers_to_skip`: Má»™t danh sÃ¡ch chá»©a chá»‰ sá»‘ cá»§a cÃ¡c lá»›p báº¡n muá»‘n loáº¡i bá» (vÃ­ dá»¥: `[20, 21, 22, 23, 24]`).\n",
    "    * `local_kv_sharing_layer_idx` vÃ  `global_kv_sharing_layer_idx`: ÄÃ¢y lÃ  chá»‰ sá»‘ cá»§a cÃ¡c lá»›p ráº¥t Ä‘áº·c biá»‡t, Ä‘Æ°á»£c dÃ¹ng lÃ m \"trung tÃ¢m\" chia sáº» KV. Äoáº¡n `if` Ä‘áº£m báº£o ráº±ng báº¡n khÃ´ng thá»ƒ vÃ´ tÃ¬nh xÃ³a bá» cÃ¡c lá»›p quan trá»ng nÃ y.\n",
    "    * `count_kv_sharing`: Äáº¿m xem cÃ³ bao nhiÃªu lá»›p chia sáº» KV (cÃ¡c lá»›p tá»« 20 trá»Ÿ Ä‘i) Ä‘Ã£ bá»‹ báº¡n loáº¡i bá».\n",
    "    * `model_config.num_kv_shared_layers -= count_kv_sharing`: Cáº­p nháº­t láº¡i tá»•ng sá»‘ lá»›p chia sáº» KV trong mÃ´ hÃ¬nh má»›i sau khi Ä‘Ã£ trá»« Ä‘i cÃ¡c lá»›p bá»‹ loáº¡i bá»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYawXs_xBmv9"
   },
   "outputs": [],
   "source": [
    "# TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ cá»§a cÃ¡c lá»›p Ä‘áº·c biá»‡t\n",
    "num_kv_comp_layers = model_config.num_hidden_layers - model_config.num_kv_shared_layers\n",
    "local_kv_sharing_layer_idx = num_kv_comp_layers - 2\n",
    "global_kv_sharing_layer_idx = num_kv_comp_layers - 1\n",
    "\n",
    "# Kiá»ƒm tra xem cÃ¡c lá»›p Ä‘áº·c biá»‡t cÃ³ bá»‹ bá» qua hay khÃ´ng\n",
    "if (local_kv_sharing_layer_idx in layers_to_skip or global_kv_sharing_layer_idx in layers_to_skip):\n",
    "  raise ValueError(f'Layers {local_kv_sharing_layer_idx} and {global_kv_sharing_layer_idx} are reserved.')\n",
    "\n",
    "# Äáº¿m vÃ  cáº­p nháº­t láº¡i sá»‘ lá»›p chia sáº» KV\n",
    "count_kv_sharing = sum(1 for layer in layers_to_skip if layer >= 20)\n",
    "model_config.num_kv_shared_layers -= count_kv_sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_config.text_config.num_kv_shared_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cáº­p nháº­t cáº¥u hÃ¬nh Ä‘á»™ thÆ°a cá»§a kÃ­ch hoáº¡t (Activation Sparsity):\n",
    "\n",
    "* **Má»¥c Ä‘Ã­ch**: Gemma 3n Ã¡p dá»¥ng \"Ä‘á»™ thÆ°a\" (sparsity) cho cÃ¡c hÃ m kÃ­ch hoáº¡t á»Ÿ 10 lá»›p Ä‘áº§u tiÃªn Ä‘á»ƒ tÄƒng hiá»‡u quáº£ tÃ­nh toÃ¡n. Khi báº¡n xÃ³a má»™t trong sá»‘ cÃ¡c lá»›p nÃ y, mÃ´ hÃ¬nh Ä‘á»™ thÆ°a cÅ©ng pháº£i Ä‘Æ°á»£c Ä‘iá»u chá»‰nh tÆ°Æ¡ng á»©ng.\n",
    "* **Ã nghÄ©a cÃ¡c biáº¿n**:\n",
    "    * `count_activation_sparsity`: Äáº¿m xem cÃ³ bao nhiÃªu lá»›p trong 10 lá»›p Ä‘áº§u tiÃªn Ä‘Ã£ bá»‹ báº¡n loáº¡i bá».\n",
    "    * `final_num_layers`: Tá»•ng sá»‘ lá»›p cá»§a mÃ´ hÃ¬nh *sau khi* Ä‘Ã£ cáº¯t bá».\n",
    "    * `activation_sparsity_list`: Táº¡o ra má»™t danh sÃ¡ch má»›i. Danh sÃ¡ch nÃ y xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh Ä‘á»™ thÆ°a (sparsity pattern) cho cÃ¡c lá»›p cÃ²n láº¡i, Ä‘áº£m báº£o ráº±ng cáº¥u trÃºc nÃ y váº«n Ä‘Æ°á»£c duy trÃ¬ má»™t cÃ¡ch chÃ­nh xÃ¡c trong mÃ´ hÃ¬nh con."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Äáº¿m sá»‘ lá»›p cÃ³ Ä‘á»™ thÆ°a bá»‹ loáº¡i bá»\n",
    "count_activation_sparsity = sum(1 for layer in layers_to_skip if layer <= 9)\n",
    "\n",
    "# Táº¡o láº¡i danh sÃ¡ch mÃ´ hÃ¬nh Ä‘á»™ thÆ°a cho cÃ¡c lá»›p cÃ²n láº¡i\n",
    "activation_sparsity_list = [0.95] * (10 - count_activation_sparsity) + [0] * (\n",
    "    final_num_layers - 10 + count_activation_sparsity\n",
    ")\n",
    "model_config.activation_sparsity_pattern = activation_sparsity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.num_hidden_layers = final_num_layers\n",
    "model_config.intermediate_size = ffn_hidden_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the configuration and the unchanged tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c7067c28444ac2887436dfe6671c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2721cce8f345a4bf068e1cd58b5c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.70M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c499384f8d459ea7e3472b2834dc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1751e7ad7e488897653e9bd6a45582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/769 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acce0c8756944181ab501c2b09a10f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New config saved to my_modified_gemma_3n_model\n",
      "Final number of layers: 30\n"
     ]
    }
   ],
   "source": [
    "original_config.save_pretrained(local_output_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(original_model_id)\n",
    "tokenizer.save_pretrained(local_output_path)\n",
    "\n",
    "print(f\"New config saved to {local_output_path}\")\n",
    "print(f\"Final number of layers: {model_config.num_hidden_layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model checkpoints\n",
    "\n",
    "Note: we are saving the model to disk, so there's no need to have a large CPU/GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f26ea4ae4049f58b2e3bbc8748ec51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b984952bdd486fa76f44d066eb5233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/2.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a348f50a258d432d9b5daaa173b07968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb38e4c8caa4dc6b9a736444be542fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e6f228d77a4429b2b184570a619c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_path = snapshot_download(original_model_id, allow_patterns=[\"*.safetensors\"])\n",
    "safetensor_files = [os.path.join(model_path, f) for f in os.listdir(model_path) if f.endswith('.safetensors')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58871f7fbe7546f0a7adf7945156a5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving shard model-00001-of-XXXXX.safetensors (size: 4.86 GB)\n",
      "Saving shard model-00002-of-XXXXX.safetensors (size: 4.63 GB)\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "kept_layers_indices = [i for i in range(num_layers) if i not in layers_to_skip]\n",
    "layer_rename_map = {old_idx: new_idx for new_idx, old_idx in enumerate(kept_layers_indices)}\n",
    "\n",
    "# This will store the mapping of tensor names to the file they are saved in\n",
    "weight_map = {}\n",
    "\n",
    "# This will store tensors for the current shard we are building\n",
    "new_shard_state_dict = {}\n",
    "shard_counter = 1\n",
    "total_size = 0\n",
    "\n",
    "pbar = tqdm(total=len(safetensor_files), desc=\"Processing shards\")\n",
    "\n",
    "for shard_path in safetensor_files:\n",
    "    # Open a shard for streaming\n",
    "    with safe_open(shard_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        # Iterate over each tensor in the shard\n",
    "        for tensor_name in f.keys():\n",
    "            new_tensor_name = tensor_name\n",
    "            tensor = f.get_tensor(tensor_name)\n",
    "\n",
    "            # Case 1: Handle layer-specific parameters\n",
    "            match = re.search(r'\\.layers\\.(\\d+)\\.', tensor_name)\n",
    "            if match:\n",
    "                old_layer_idx = int(match.group(1))\n",
    "\n",
    "                # If this layer is meant to be skipped, we just continue to the next tensor\n",
    "                if old_layer_idx in layers_to_skip:\n",
    "                    continue\n",
    "\n",
    "                # Get the new sequential layer index\n",
    "                new_layer_idx = layer_rename_map[old_layer_idx]\n",
    "                new_tensor_name = tensor_name.replace(\n",
    "                    f'.layers.{old_layer_idx}.',\n",
    "                    f'.layers.{new_layer_idx}.'\n",
    "                )\n",
    "\n",
    "                # Get the target FFN dimension for this new layer\n",
    "                target_ffn_dim = ffn_hidden_dims[new_layer_idx]\n",
    "\n",
    "                # Check if this parameter is part of the FFN and needs slicing\n",
    "                if 'mlp.gate_proj.weight' in new_tensor_name or 'mlp.up_proj.weight' in new_tensor_name:\n",
    "                    # These layers project from model_dim -> ffn_hidden_dim.\n",
    "                    # We slice the output dimension (dim 0).\n",
    "                    tensor = tensor[:target_ffn_dim, :].contiguous()\n",
    "                elif 'mlp.down_proj.weight' in new_tensor_name:\n",
    "                    # This layer projects from ffn_hidden_dim -> model_dim.\n",
    "                    # We slice the input dimension (dim 1).\n",
    "                    tensor = tensor[:, :target_ffn_dim].contiguous()\n",
    "\n",
    "            # Case 2: Handle special non-layer parameters that need slicing\n",
    "            elif 'per_layer_model_projection' in tensor_name:\n",
    "                # Reshape, slice based on kept layers, and reshape back\n",
    "                reshaped_params = tensor.reshape((num_layers, tensor.shape[0] // num_layers, tensor.shape[1]))\n",
    "                tensor = reshaped_params[kept_layers_indices, :, :]\n",
    "                tensor = tensor.reshape(-1, tensor.shape[-1]).contiguous()\n",
    "\n",
    "            elif 'embed_tokens_per_layer' in tensor_name:\n",
    "                # Reshape, slice based on kept layers, and reshape back\n",
    "                reshaped_params = tensor.reshape((tensor.shape[0], num_layers, tensor.shape[1] // num_layers))\n",
    "                tensor = reshaped_params[:, kept_layers_indices, :]\n",
    "                tensor = tensor.reshape(tensor.shape[0], -1).contiguous()\n",
    "\n",
    "            # Add the (potentially modified) tensor to the new shard\n",
    "            new_shard_state_dict[new_tensor_name] = tensor\n",
    "\n",
    "            # Check if the current shard is getting too big\n",
    "            current_shard_size = sum(t.numel() * t.element_size() for t in new_shard_state_dict.values())\n",
    "            if current_shard_size > 4000000000: # Create new shard if current is over 4GB\n",
    "                shard_filename = f\"model-{(shard_counter):05d}-of-XXXXX.safetensors\"\n",
    "                print(f\"Saving shard {shard_filename} (size: {current_shard_size / 1e9:.2f} GB)\")\n",
    "                save_file(new_shard_state_dict, os.path.join(local_output_path, shard_filename), metadata={'format': 'pt'})\n",
    "\n",
    "                # Record which tensors are in this shard\n",
    "                for k in new_shard_state_dict.keys():\n",
    "                    weight_map[k] = os.path.basename(shard_filename)\n",
    "\n",
    "                # Reset for the next shard\n",
    "                shard_counter += 1\n",
    "                new_shard_state_dict = {}\n",
    "                gc.collect() # Free up memory\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final shard model-00003-of-XXXXX.safetensors\n"
     ]
    }
   ],
   "source": [
    "# Save any remaining tensors in the last shard\n",
    "if new_shard_state_dict:\n",
    "    shard_filename = f\"model-{(shard_counter):05d}-of-XXXXX.safetensors\"\n",
    "    print(f\"Saving final shard {shard_filename}\")\n",
    "    save_file(new_shard_state_dict, os.path.join(local_output_path, shard_filename), metadata={'format': 'pt'})\n",
    "    for k in new_shard_state_dict.keys():\n",
    "        weight_map[k] = os.path.basename(shard_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del new_shard_state_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Finalizing Model Save ---\n",
      "\n",
      "âœ… Model slicing complete. New model saved in: my_modified_gemma_3n_model\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"\\n--- 3. Finalizing Model Save ---\")\n",
    "\n",
    "# The total number of shards we created\n",
    "num_shards = shard_counter\n",
    "\n",
    "# Update the \"XXXXX\" in the filenames to the correct total number of shards\n",
    "for i in range(1, num_shards + 1):\n",
    "    old_filename = f\"model-{(i):05d}-of-XXXXX.safetensors\"\n",
    "    new_filename = f\"model-{(i):05d}-of-{(num_shards):05d}.safetensors\"\n",
    "\n",
    "    # Rename the file\n",
    "    os.rename(os.path.join(local_output_path, old_filename), os.path.join(local_output_path, new_filename))\n",
    "\n",
    "    # Update the weight_map to point to the new filename\n",
    "    for k, v in weight_map.items():\n",
    "        if v == old_filename:\n",
    "            weight_map[k] = new_filename\n",
    "\n",
    "# Create and save the index.json file\n",
    "index_json = {\n",
    "    \"metadata\": {\n",
    "        \"total_size\": sum(os.path.getsize(os.path.join(local_output_path, f)) for f in os.listdir(local_output_path) if f.endswith('.safetensors'))\n",
    "    },\n",
    "    \"weight_map\": weight_map\n",
    "}\n",
    "\n",
    "with open(os.path.join(local_output_path, \"model.safetensors.index.json\"), \"w\") as f:\n",
    "    json.dump(index_json, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Model slicing complete. New model saved in: {local_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551646c8032f412bbd89c6581625bff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/24.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepended custom description to the model card content.\n",
      "New README.md saved to 'my_modified_gemma_3n_model/README.md'\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import  ModelCard, ModelCardData\n",
    "\n",
    "card = ModelCard.load(original_model_id)\n",
    "card.data.base_model = original_model_id\n",
    "del card.data.extra_gated_heading\n",
    "del card.data.extra_gated_prompt\n",
    "card.data.tags.append(\"matformer\")\n",
    "\n",
    "new_description = f\"\"\"\n",
    "> [!Note]\n",
    "> This is a submodel derived from `{original_model_id}`. It has been modified by slicing specific layers and resizing FFN dimensions. It is not the original model.\n",
    "> To learn more about MatFormers, please review the [launch blog](https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide) and generate your own submodels\n",
    "with the [MatFormer Lab](https://goo.gle/gemma3n-matformer-lab).\n",
    ">\n",
    "\n",
    "Skipped layers: {layers_to_skip}\n",
    "\n",
    "FFN hidden dimensions: {ffn_hidden_dims_str}\n",
    "\"\"\"\n",
    "\n",
    "card.text = new_description + \"\\n\" + card.text\n",
    "print(\"Prepended custom description to the model card content.\")\n",
    "\n",
    "new_readme_path = os.path.join(local_output_path, \"README.md\")\n",
    "card.save(new_readme_path)\n",
    "print(f\"New README.md saved to '{new_readme_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the model to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating private repository: ngohongthai/test-submodel\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "print(f\"Creating private repository: {push_hf_repo_id}\")\n",
    "\n",
    "# Instantiate the HfApi client\n",
    "api = HfApi()\n",
    "\n",
    "# Create a new private repository on the Hub.\n",
    "repo_url = api.create_repo(\n",
    "    repo_id=push_hf_repo_id,\n",
    "    private=True,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading files from 'my_modified_gemma_3n_model' to 'ngohongthai/test-submodel'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550a6cc49740488abf94bf978ebbe950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50aee7c2c1024f86a1985bb189271c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a8dd70c5d54799b7898f6ae7a8b47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a88e2ff661c44da8684d5e9ebc2621b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731aa9c6d7e54028a15503452605b0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.70M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb2dd00be93438b8ec7c222a05a953a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ngohongthai/test-submodel/commit/4085e6ca1324781669801266f9ffe84f44171fd0', commit_message='Upload sliced model checkpoint', commit_description='', oid='4085e6ca1324781669801266f9ffe84f44171fd0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ngohongthai/test-submodel', endpoint='https://huggingface.co', repo_type='model', repo_id='ngohongthai/test-submodel'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Uploading files from '{local_output_path}' to '{push_hf_repo_id}'...\")\n",
    "api.upload_folder(\n",
    "    folder_path=local_output_path,\n",
    "    repo_id=push_hf_repo_id,\n",
    "    repo_type=\"model\",\n",
    "    commit_message=\"Upload sliced model checkpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify new model can be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dc744c31c94f17915a5c39e2827014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 6,027,165,120\n",
      "Total Text Parameters: 4,506,488,416\n",
      "Effective Parameters (excluding vision, audio, and Per-Layer-Embeddings): 1,955,827,296\n"
     ]
    }
   ],
   "source": [
    "#@title Verify new model can be loaded\n",
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(push_hf_repo_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "print(f\"Total Parameters: {model.num_parameters():,}\") # 5,976,833,408\n",
    "print(f\"Total Text Parameters: {model.language_model.num_parameters():,}\") # 4,456,156,768\n",
    "print(f\"Effective Parameters (excluding vision, audio, and Per-Layer-Embeddings): {model.language_model.num_parameters(exclude_embeddings=True):,}\") # 1,905,495,648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzowThlqB7vnEsl4rNHH3/",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "learn-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01c902390b5340c9871a4bd30cbe7aad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb24b163af204e7298ba259e7bbc5965",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5aa3381a60404ac9947d88f126d49745",
      "value": "â€‡4.54k/4.54kâ€‡[00:00&lt;00:00,â€‡170kB/s]"
     }
    },
    "06d0c33c422f46c6b55daa6de076b53c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2079304e45244ec1b53d73e02bff102a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_527ebf26b7dd4b94a40c9be6dbd7a4c7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5495552f37b6485d8f749fbed718205d",
      "value": "config.json:â€‡100%"
     }
    },
    "2f184c7541bb48b68ef4d9e908ec4632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_618290a83b8640cd92a04af53c8d3dc4",
       "IPY_MODEL_fe7b3a7a08534c8fa0ffcd6d70ea679d",
       "IPY_MODEL_4cc3f543f21e4502ab0e027cc99946ce",
       "IPY_MODEL_4f941bd663bd4321b31d899c3818e5e6",
       "IPY_MODEL_dc6fc547dd5f42a4a0b10b379a473102"
      ],
      "layout": "IPY_MODEL_e901deb71818453ea0d452cfceae2347"
     }
    },
    "337c2ba459e04d5a946b680e8598f21d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bf3a6b3248b4aeeb6f5228e5d9c0d67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "49bf2d6cc1da408faf6c752a9225e7dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cc3f543f21e4502ab0e027cc99946ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_de924f5124f3401680fa421244bc4cbd",
      "style": "IPY_MODEL_06d0c33c422f46c6b55daa6de076b53c",
      "value": true
     }
    },
    "4f941bd663bd4321b31d899c3818e5e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_b543af171d4443caa282d017daebcd05",
      "style": "IPY_MODEL_3bf3a6b3248b4aeeb6f5228e5d9c0d67",
      "tooltip": ""
     }
    },
    "4ff13942afcc4592a9495f77756d924e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "527ebf26b7dd4b94a40c9be6dbd7a4c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5495552f37b6485d8f749fbed718205d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54aa43966e8d4649920516da818a5930": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5aa3381a60404ac9947d88f126d49745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "618290a83b8640cd92a04af53c8d3dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49bf2d6cc1da408faf6c752a9225e7dc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_337c2ba459e04d5a946b680e8598f21d",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "7c2f552a824f4077a525937e84a40111": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86b0b1f8225145f088281f166cfa343a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "987550d76b7d45549096cb07928a3278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2079304e45244ec1b53d73e02bff102a",
       "IPY_MODEL_a5f3b3e2bdfd4b49b797b54d3fe6e314",
       "IPY_MODEL_01c902390b5340c9871a4bd30cbe7aad"
      ],
      "layout": "IPY_MODEL_7c2f552a824f4077a525937e84a40111"
     }
    },
    "a5f3b3e2bdfd4b49b797b54d3fe6e314": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fff785435c9a48a39b5b329ba62df081",
      "max": 4536,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4ff13942afcc4592a9495f77756d924e",
      "value": 4536
     }
    },
    "b543af171d4443caa282d017daebcd05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce064ed719b347f6a9ca629cadbfa609": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc6fc547dd5f42a4a0b10b379a473102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86b0b1f8225145f088281f166cfa343a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fa3d76524eab45129a1a0eaf7adafd75",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "de924f5124f3401680fa421244bc4cbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e901deb71818453ea0d452cfceae2347": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "eb24b163af204e7298ba259e7bbc5965": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3d76524eab45129a1a0eaf7adafd75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe7b3a7a08534c8fa0ffcd6d70ea679d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_ce064ed719b347f6a9ca629cadbfa609",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_54aa43966e8d4649920516da818a5930",
      "value": ""
     }
    },
    "fff785435c9a48a39b5b329ba62df081": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
