{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhZfe4RyQNij"
   },
   "source": [
    "# MatFormer Lab\n",
    "\n",
    "`Gemma 3n` là một mô hình đa phương thức (`multimodal`), đa ngôn ngữ (`multilingual`) thuộc họ mô hình `Gemma`. Bạn có thể đọc về `Gemma 3n` trong [tài liệu (docs)](https://www.google.com/search?q=https://ai.google.dev/gemma/docs/gemma2) và [bài đăng blog ra mắt](https://www.google.com/search?q=https://ai.google.dev/blog/gemma-2) của nó. Đây là một mô hình độc đáo có khả năng co giãn tự nhiên (`natively elastic`), nghĩa là bạn sẽ có các mô hình được lồng vào nhau (`nested models`)\\! `Gemma 3n` được huấn luyện như một mô hình `E4B` (effectively loads 4B parameters) với 35 lớp và 16,384 FFN hidden dimension. Nó có một mô hình `E2B` (30 lớp và 8,192 FFN hidden dimension) được lồng bên trong và được huấn luyện đồng thời dưới dạng một `MatFormer`.\n",
    "\n",
    "Kiến trúc [MatFormer](https://arxiv.org/abs/2310.07707) (🪆`Matryoshka Transformer`) là một kiến trúc `transformer` lồng nhau mới lạ được xây dựng cho việc suy luận co giãn (`elastic inference`). Hãy tưởng tượng nó giống như những con búp bê `Matryoshka`: một mô hình lớn hơn chứa các phiên bản nhỏ hơn, đầy đủ chức năng của chính nó. Cách tiếp cận này mở rộng khái niệm của `Matryoshka Representation Learning` từ chỉ các `embeddings` sang tất cả các thành phần của `transformer`.\n",
    "\n",
    "Việc tiết kiệm bộ nhớ bằng cách lồng `E2B` bên trong `E4B` là rất hữu ích trong thực tế, nhưng điều làm cho `MatFormer` trở nên mạnh mẽ là khả năng của nó có thể trải dài mượt mà trên toàn bộ đường cong tối ưu Pareto về độ chính xác-so với-kích thước mô hình (`Pareto-optimal accuracy-vs-model size curve`) giữa `E2B` và `E4B` mà không cần huấn luyện bổ sung. Sử dụng một kỹ thuật đơn giản gọi là `Mix-n-Match`, người ta có thể trích xuất một mô hình có kích thước bất kỳ giữa `E2B` và `E4B` từ mô hình `E4B` chính.\n",
    "\n",
    "Tại sao bạn lại muốn \"cắt lát\" (`slice`) một mô hình? Dựa trên các yêu cầu triển khai (`deployment requirements`) cụ thể của bạn, `E2B` và `E4B` có thể không phải là lựa chọn phù hợp. Ví dụ, bạn có thể muốn có một mô hình `E3B`, với chất lượng cao hơn `E2B` trong khi yêu cầu ít tài nguyên tính toán (`compute`) hơn `E4B`.\n",
    "\n",
    "Trong `notebook` này, bạn sẽ được thử nghiệm với `MatFormers` và `Mix-n-Match`. Bạn sẽ chỉ định cấu hình mong muốn cho mô hình con (`submodel`) dựa trên chiều `FFN` và các lớp `skip layers`, và sau đó bạn sẽ xuất mô hình sang `Hugging Face`, cho phép bạn sử dụng nó với các công cụ yêu thích của mình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102447,
     "status": "ok",
     "timestamp": 1753268463048,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "QNaYXucmP9sL",
    "outputId": "221c89ae-f33c-4e31-f429-c8ddb3da6094"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "# @markdown Run this cell to install all the required dependencies. In particular, you'll need Hugging Face `transformers` and `timm` versions that support Gemma 3n. Note that you may need to restart the notebook after executing the following cell.\n",
    "\n",
    "# Install a transformers version that supports Gemma 3n (>= 4.53)\n",
    "!pip install \"transformers>=4.53\" \"timm>=1.0.16\" -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303,
     "referenced_widgets": [
      "2f184c7541bb48b68ef4d9e908ec4632",
      "618290a83b8640cd92a04af53c8d3dc4",
      "fe7b3a7a08534c8fa0ffcd6d70ea679d",
      "4cc3f543f21e4502ab0e027cc99946ce",
      "4f941bd663bd4321b31d899c3818e5e6",
      "dc6fc547dd5f42a4a0b10b379a473102",
      "e901deb71818453ea0d452cfceae2347",
      "49bf2d6cc1da408faf6c752a9225e7dc",
      "337c2ba459e04d5a946b680e8598f21d",
      "ce064ed719b347f6a9ca629cadbfa609",
      "54aa43966e8d4649920516da818a5930",
      "de924f5124f3401680fa421244bc4cbd",
      "06d0c33c422f46c6b55daa6de076b53c",
      "b543af171d4443caa282d017daebcd05",
      "3bf3a6b3248b4aeeb6f5228e5d9c0d67",
      "86b0b1f8225145f088281f166cfa343a",
      "fa3d76524eab45129a1a0eaf7adafd75"
     ]
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1753268463848,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "frQhZJ9aQUAf",
    "outputId": "cc4ee566-2762-469b-fff0-708bc153b9c8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1adb57bc8e44cf19a4a1ee1c418dd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# @title Login to Hugging Face\n",
    "# @markdown This is required so you can push the model to Hugging Face. You also need to make sure you have access to the Gemma 3n model repositories.\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1753268463921,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "8c0G-3ajqPf-"
   },
   "outputs": [],
   "source": [
    "\n",
    "# @title Import and Export Options\n",
    "# @markdown The MatFormer Lab allows you to load a Gemma 3n 4B checkpoint (either pre-trained or instruct-tuned) and to slice it. Below, please specify:\n",
    "\n",
    "# @markdown * The original repository ID from the checkpoint in Hugging Face\n",
    "\n",
    "# @markdown * A local path where the model will be saved\n",
    "\n",
    "# @markdown * A name of a repository to push the new checkpoint to\n",
    "\n",
    "original_model_id = \"google/gemma-3n-E4B-it\" # @param [\"google/gemma-3n-E4B-it\", \"google/gemma-3n-E4B-pt\"]\n",
    "local_output_path = \"my_modified_gemma_3n_model\" # @param {type:\"string\"}\n",
    "push_hf_repo_id = \"ngohongthai/test-submodel\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avc-LkhGqo-o"
   },
   "source": [
    "## Cấu hình cắt lát (Slicing configuration)\n",
    "\n",
    "Là một phần của việc phát hành `Gemma 3n`, chúng tôi chia sẻ các cấu hình cắt lát tối ưu dưới dạng một kho dữ liệu (`dataset repository`) trên **[Hugging Face](https://www.google.com/search?q=https://huggingface.co/datasets/google/gemma-3n-slicing-configs)**, mặc dù bạn cũng có thể tự khám phá các cấu hình của riêng mình ở bên dưới.\n",
    "\n",
    "Mỗi cấu hình sẽ chỉ định:\n",
    "\n",
    "  * The hidden dimensions of the FFN\n",
    "  * Which layers, if any, to skip\n",
    "  * Độ chính xác `MMLU` tương ứng với các `checkpoint` đã được huấn luyện trước\n",
    "  \n",
    "Các cấu hình cấp độ lớp (`layer-level`) và cấp độ khối (`block-level`) là kết quả của việc thay đổi chiều ẩn của `FFN` ở cấp độ lớp (chi tiết - `fine-grained`) hoặc ở cấp độ khối (4 lớp cục bộ + 1 lớp toàn cục).\n",
    "\n",
    "Ở **cấp độ lớp (`layer-level`)**, chúng tôi nhận thấy rằng việc cho các lớp toàn cục (`global layers`) (thay vì các lớp cục bộ - `local layers`) có năng lực (`capacity`) cao hơn sẽ giúp cải thiện độ chính xác với cùng một kích thước mô hình.\n",
    "\n",
    "Ở **cấp độ khối (`block-level`)**, chúng tôi thấy rằng khối bị bỏ qua đối với `E2B` (tức là các lớp 20-24) sẽ được hưởng lợi từ năng lực cao hơn khi không bị bỏ qua, và các khối ở tầng sớm hơn có thể hoạt động tốt với năng lực thấp hơn so với các khối ở tầng sau.\n",
    "\n",
    "Chúng tôi mời cộng đồng cùng tìm ra những cấu hình tốt hơn nữa nằm trên đường cong tối ưu Pareto (`Pareto-optimal curve`) giữa `E2B` và `E4B`\\!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 1756,
     "status": "ok",
     "timestamp": 1753268465656,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "s9EVWkANqdwK",
    "outputId": "b63dcfaa-2003-4e6a-a35b-9eb27b600531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th># Layers</th>\n",
       "      <th># Effective Params (B)</th>\n",
       "      <th>MMLU PT accuracy</th>\n",
       "      <th>FFN Hidden Dims</th>\n",
       "      <th>Layers Skipped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main model</td>\n",
       "      <td>35</td>\n",
       "      <td>3.98</td>\n",
       "      <td>62.30%</td>\n",
       "      <td>[2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Config for official E2B Model</td>\n",
       "      <td>30</td>\n",
       "      <td>1.91</td>\n",
       "      <td>50.90%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Config for E1.96B (layer-level)</td>\n",
       "      <td>30</td>\n",
       "      <td>1.96</td>\n",
       "      <td>53.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Config for E2.54B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.54</td>\n",
       "      <td>55.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Config for E2.69B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.69</td>\n",
       "      <td>57.70%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Config for E2.98B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.98</td>\n",
       "      <td>59.50%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Config for E3.18B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.18</td>\n",
       "      <td>61.80%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Config for E3.39B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.39</td>\n",
       "      <td>63.00%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Config for E3.59B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.59</td>\n",
       "      <td>63.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Config for E3.79B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.79</td>\n",
       "      <td>63.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Config for E2.49B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.49</td>\n",
       "      <td>54.50%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Config for E2.73B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.73</td>\n",
       "      <td>57.10%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Config for E2.98B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.98</td>\n",
       "      <td>59.50%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Config for E3.24B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.24</td>\n",
       "      <td>60.70%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Config for E3.49B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.49</td>\n",
       "      <td>61.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Config for E3.79B (block-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>3.74</td>\n",
       "      <td>62.00%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name  # Layers  # Effective Params (B)  \\\n",
       "0                        Main model        35                    3.98   \n",
       "1     Config for official E2B Model        30                    1.91   \n",
       "2   Config for E1.96B (layer-level)        30                    1.96   \n",
       "3   Config for E2.54B (layer-level)        35                    2.54   \n",
       "4   Config for E2.69B (layer-level)        35                    2.69   \n",
       "5   Config for E2.98B (layer-level)        35                    2.98   \n",
       "6   Config for E3.18B (layer-level)        35                    3.18   \n",
       "7   Config for E3.39B (layer-level)        35                    3.39   \n",
       "8   Config for E3.59B (layer-level)        35                    3.59   \n",
       "9   Config for E3.79B (layer-level)        35                    3.79   \n",
       "10  Config for E2.49B (block-level)        35                    2.49   \n",
       "11  Config for E2.73B (block-level)        35                    2.73   \n",
       "12  Config for E2.98B (block-level)        35                    2.98   \n",
       "13  Config for E3.24B (block-level)        35                    3.24   \n",
       "14  Config for E3.49B (block-level)        35                    3.49   \n",
       "15  Config for E3.79B (block-level)        35                    3.74   \n",
       "\n",
       "   MMLU PT accuracy                                    FFN Hidden Dims  \\\n",
       "0            62.30%  [2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...   \n",
       "1            50.90%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "2            53.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "3            55.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "4            57.70%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "5            59.50%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "6            61.80%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "7            63.00%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "8            63.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "9            63.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "10           54.50%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "11           57.10%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "12           59.50%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "13           60.70%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "14           61.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "15           62.00%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "\n",
       "          Layers Skipped  \n",
       "0                    NaN  \n",
       "1   [20, 21, 22, 23, 24]  \n",
       "2   [20, 21, 22, 23, 24]  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "5                    NaN  \n",
       "6                    NaN  \n",
       "7                    NaN  \n",
       "8                    NaN  \n",
       "9                    NaN  \n",
       "10                   NaN  \n",
       "11                   NaN  \n",
       "12                   NaN  \n",
       "13                   NaN  \n",
       "14                   NaN  \n",
       "15                   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/google/gemma3n-slicing-configs/configs.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l15UQLqu3Ymd"
   },
   "source": [
    "Based on your deployment scenarios, you may want to pick a different config. Select below your preferred one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1753268465687,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "sVBfjQC_wirp"
   },
   "outputs": [],
   "source": [
    "#@title Config details\n",
    "import ast\n",
    "\n",
    "config_name = \"Config for E1.96B (layer-level)\"# @param ['Config for official E2B Model', 'Config for E1.96B (layer-level)', 'Config for E2.54B (layer-level)', 'Config for E2.69B (layer-level)', 'Config for E2.98B (layer-level)', 'Config for E3.18B (layer-level)', 'Config for E3.39B (layer-level)', 'Config for E3.59B (layer-level)', 'Config for E3.79B (layer-level)', 'Config for E2.49B (block-level)', 'Config for E2.73B (block-level)', 'Config for E2.98B (block-level)', 'Config for E3.24B (block-level)', 'Config for E3.49B (block-level)', 'Config for E3.79B (block-level)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1753268465769,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "kJsmisb93qEy"
   },
   "outputs": [],
   "source": [
    "def safe_string_to_list(value):\n",
    "    \"\"\"\n",
    "    Converts a string representation of a list into a Python list.\n",
    "    - Converts NaN/missing values to an empty list [].\n",
    "    - Uses eval() to handle expressions like '2_048 * 8'.\n",
    "    - Safely handles non-string values by returning them as is.\n",
    "    \"\"\"\n",
    "    # First, check if the value is missing (NaN, None, etc.)\n",
    "    if isinstance(value, list):\n",
    "        return value\n",
    "\n",
    "    # Priority 2: Now that we know it's not a list, check if it's a missing value.\n",
    "    if pd.isna(value):\n",
    "        return []\n",
    "\n",
    "    # Priority 3: If it's a string, try to evaluate it.\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            return eval(value)\n",
    "        except (SyntaxError, NameError):\n",
    "            return value  # Return invalid string as is\n",
    "\n",
    "    # Fallback for any other type (like an integer)\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1753268465770,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "jzkaQNUa4R9z",
    "outputId": "ab2b1b66-df36-46c4-f0c9-30eec5b89cc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval('2_048 * 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1753268465775,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "b8dnVr1X4WdX",
    "outputId": "2ba7695c-1d99-49c0-a058-ae8c5840d862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Config for E1.96B (layer-level)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1753268465821,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "zcc2vrBH4iAI",
    "outputId": "8fe872bb-c1b5-4d13-c12c-46d9248052b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FFN Hidden Dims'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1753268465836,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "RWmj5b7E5RUL",
    "outputId": "a55e808d-9717-4b34-90a7-323b1d521154"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 21, 22, 23, 24]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_string_to_list('[20, 21, 22, 23, 24]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1753268465854,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "sfHxOvtv5ayA"
   },
   "outputs": [],
   "source": [
    "df['FFN Hidden Dims List'] = df['FFN Hidden Dims'].apply(safe_string_to_list)\n",
    "df['Layers Skipped'] = df['Layers Skipped'].apply(safe_string_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1753268465890,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "l_bdKfon5pHZ",
    "outputId": "a1424137-279a-4ae3-93a5-04642076ad42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th># Layers</th>\n",
       "      <th># Effective Params (B)</th>\n",
       "      <th>MMLU PT accuracy</th>\n",
       "      <th>FFN Hidden Dims</th>\n",
       "      <th>Layers Skipped</th>\n",
       "      <th>FFN Hidden Dims List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main model</td>\n",
       "      <td>35</td>\n",
       "      <td>3.98</td>\n",
       "      <td>62.30%</td>\n",
       "      <td>[2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[16384, 16384, 16384, 16384, 16384, 16384, 163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Config for official E2B Model</td>\n",
       "      <td>30</td>\n",
       "      <td>1.91</td>\n",
       "      <td>50.90%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 8192, 8192, 8192, 819...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Config for E1.96B (layer-level)</td>\n",
       "      <td>30</td>\n",
       "      <td>1.96</td>\n",
       "      <td>53.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Config for E2.54B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.54</td>\n",
       "      <td>55.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Config for E2.69B (layer-level)</td>\n",
       "      <td>35</td>\n",
       "      <td>2.69</td>\n",
       "      <td>57.70%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  # Layers  # Effective Params (B)  \\\n",
       "0                       Main model        35                    3.98   \n",
       "1    Config for official E2B Model        30                    1.91   \n",
       "2  Config for E1.96B (layer-level)        30                    1.96   \n",
       "3  Config for E2.54B (layer-level)        35                    2.54   \n",
       "4  Config for E2.69B (layer-level)        35                    2.69   \n",
       "\n",
       "  MMLU PT accuracy                                    FFN Hidden Dims  \\\n",
       "0           62.30%  [2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...   \n",
       "1           50.90%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "2           53.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "3           55.40%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "4           57.70%  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "\n",
       "         Layers Skipped                               FFN Hidden Dims List  \n",
       "0                    []  [16384, 16384, 16384, 16384, 16384, 16384, 163...  \n",
       "1  [20, 21, 22, 23, 24]  [8192, 8192, 8192, 8192, 8192, 8192, 8192, 819...  \n",
       "2  [20, 21, 22, 23, 24]  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  \n",
       "3                    []  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  \n",
       "4                    []  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1753268465914,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "rji240NZ5qU4",
    "outputId": "5f45ffc3-1a87-483a-e771-537cee84cdc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Layers</th>\n",
       "      <th># Effective Params (B)</th>\n",
       "      <th>MMLU PT accuracy</th>\n",
       "      <th>FFN Hidden Dims</th>\n",
       "      <th>Layers Skipped</th>\n",
       "      <th>FFN Hidden Dims List</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Main model</th>\n",
       "      <td>35</td>\n",
       "      <td>3.98</td>\n",
       "      <td>62.30%</td>\n",
       "      <td>[2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[16384, 16384, 16384, 16384, 16384, 16384, 163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Config for official E2B Model</th>\n",
       "      <td>30</td>\n",
       "      <td>1.91</td>\n",
       "      <td>50.90%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 8192, 8192, 8192, 819...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Config for E1.96B (layer-level)</th>\n",
       "      <td>30</td>\n",
       "      <td>1.96</td>\n",
       "      <td>53.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Config for E2.54B (layer-level)</th>\n",
       "      <td>35</td>\n",
       "      <td>2.54</td>\n",
       "      <td>55.40%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Config for E2.69B (layer-level)</th>\n",
       "      <td>35</td>\n",
       "      <td>2.69</td>\n",
       "      <td>57.70%</td>\n",
       "      <td>[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 # Layers  # Effective Params (B)  \\\n",
       "name                                                                \n",
       "Main model                             35                    3.98   \n",
       "Config for official E2B Model          30                    1.91   \n",
       "Config for E1.96B (layer-level)        30                    1.96   \n",
       "Config for E2.54B (layer-level)        35                    2.54   \n",
       "Config for E2.69B (layer-level)        35                    2.69   \n",
       "\n",
       "                                MMLU PT accuracy  \\\n",
       "name                                               \n",
       "Main model                                62.30%   \n",
       "Config for official E2B Model             50.90%   \n",
       "Config for E1.96B (layer-level)           53.40%   \n",
       "Config for E2.54B (layer-level)           55.40%   \n",
       "Config for E2.69B (layer-level)           57.70%   \n",
       "\n",
       "                                                                   FFN Hidden Dims  \\\n",
       "name                                                                                 \n",
       "Main model                       [2_048 * 8, 2_048 * 8, 2_048 * 8, 2_048 * 8, 2...   \n",
       "Config for official E2B Model    [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "Config for E1.96B (layer-level)  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "Config for E2.54B (layer-level)  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "Config for E2.69B (layer-level)  [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...   \n",
       "\n",
       "                                       Layers Skipped  \\\n",
       "name                                                    \n",
       "Main model                                         []   \n",
       "Config for official E2B Model    [20, 21, 22, 23, 24]   \n",
       "Config for E1.96B (layer-level)  [20, 21, 22, 23, 24]   \n",
       "Config for E2.54B (layer-level)                    []   \n",
       "Config for E2.69B (layer-level)                    []   \n",
       "\n",
       "                                                              FFN Hidden Dims List  \n",
       "name                                                                                \n",
       "Main model                       [16384, 16384, 16384, 16384, 16384, 16384, 163...  \n",
       "Config for official E2B Model    [8192, 8192, 8192, 8192, 8192, 8192, 8192, 819...  \n",
       "Config for E1.96B (layer-level)  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  \n",
       "Config for E2.54B (layer-level)  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  \n",
       "Config for E2.69B (layer-level)  [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indexed = df.set_index('name')\n",
    "df_indexed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1753268465917,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "632fXqkA50Bx",
    "outputId": "4f09a9b4-8836-4223-86fd-05df30e16c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Layers                                                                 30\n",
       "# Effective Params (B)                                                 1.96\n",
       "MMLU PT accuracy                                                     53.40%\n",
       "FFN Hidden Dims           [2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2...\n",
       "Layers Skipped                                         [20, 21, 22, 23, 24]\n",
       "FFN Hidden Dims List      [8192, 8192, 8192, 8192, 16384, 8192, 8192, 81...\n",
       "Name: Config for E1.96B (layer-level), dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_row = df_indexed.loc[config_name]\n",
    "model_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1753268465921,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "re0L_h-S55Da",
    "outputId": "dd1837aa-a990-4b65-9c24-b8cc060f7bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config for E1.96B (layer-level)\n",
      "\n",
      "Layers Skipped:\n",
      "[20, 21, 22, 23, 24]\n",
      "\n",
      "FFN Hidden Dims:\n",
      "[2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 8, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4, 2_048 * 4]\n"
     ]
    }
   ],
   "source": [
    "layers_to_skip = model_row['Layers Skipped']\n",
    "ffn_hidden_dims = model_row['FFN Hidden Dims List']\n",
    "ffn_hidden_dims_str = model_row['FFN Hidden Dims']\n",
    "\n",
    "print(config_name)\n",
    "print(\"\\nLayers Skipped:\")\n",
    "print(layers_to_skip)\n",
    "print(\"\\nFFN Hidden Dims:\")\n",
    "print(ffn_hidden_dims_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1753268465941,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "lpEM1nV86ARI"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom config\n",
    "#\n",
    "# layers_to_skip = [] # e.g. [20, 21, 22, 23, 24]\n",
    "# ffn_hidden_dims = [] # e.g. [2048 * 4, ...]\n",
    "# ffn_hidden_dims_str = str(ffn_hidden_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3R4IbLcZ6QEg"
   },
   "source": [
    "## Slicing\n",
    "\n",
    "### Load the model config and verify slicing configuration\n",
    "\n",
    "Note: we do not load the model at this stage, just verify that the slicing configuration is possible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1753268465944,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "j2orDbHz6ItA",
    "outputId": "28daa584-7269-4ad0-a01c-4060092df60c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google/gemma-3n-E4B-it'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "987550d76b7d45549096cb07928a3278",
      "2079304e45244ec1b53d73e02bff102a",
      "a5f3b3e2bdfd4b49b797b54d3fe6e314",
      "01c902390b5340c9871a4bd30cbe7aad",
      "7c2f552a824f4077a525937e84a40111",
      "527ebf26b7dd4b94a40c9be6dbd7a4c7",
      "5495552f37b6485d8f749fbed718205d",
      "fff785435c9a48a39b5b329ba62df081",
      "4ff13942afcc4592a9495f77756d924e",
      "eb24b163af204e7298ba259e7bbc5965",
      "5aa3381a60404ac9947d88f126d49745"
     ]
    },
    "executionInfo": {
     "elapsed": 33303,
     "status": "ok",
     "timestamp": 1753268499253,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "dz-KdBMR69xo",
    "outputId": "2775816c-a344-4baa-c5ea-6292324fe01d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2a80e5112d46f1b84c0663bbafc7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "original_config = AutoConfig.from_pretrained(original_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1753269284317,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "K9_nvWDy7Vml",
    "outputId": "735be0ca-badf-4982-b586-f6323053ec61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3nConfig {\n",
       "  \"architectures\": [\n",
       "    \"Gemma3nForConditionalGeneration\"\n",
       "  ],\n",
       "  \"audio_config\": {\n",
       "    \"conf_attention_chunk_size\": 12,\n",
       "    \"conf_attention_context_left\": 13,\n",
       "    \"conf_attention_context_right\": 0,\n",
       "    \"conf_attention_logit_cap\": 50.0,\n",
       "    \"conf_conv_kernel_size\": 5,\n",
       "    \"conf_num_attention_heads\": 8,\n",
       "    \"conf_num_hidden_layers\": 12,\n",
       "    \"conf_reduction_factor\": 4,\n",
       "    \"conf_residual_weight\": 0.5,\n",
       "    \"gradient_clipping\": 10000000000.0,\n",
       "    \"hidden_size\": 1536,\n",
       "    \"input_feat_size\": 128,\n",
       "    \"model_type\": \"gemma3n_audio\",\n",
       "    \"rms_norm_eps\": 1e-06,\n",
       "    \"sscp_conv_channel_size\": [\n",
       "      128,\n",
       "      32\n",
       "    ],\n",
       "    \"sscp_conv_group_norm_eps\": 0.001,\n",
       "    \"sscp_conv_kernel_size\": [\n",
       "      [\n",
       "        3,\n",
       "        3\n",
       "      ],\n",
       "      [\n",
       "        3,\n",
       "        3\n",
       "      ]\n",
       "    ],\n",
       "    \"sscp_conv_stride_size\": [\n",
       "      [\n",
       "        2,\n",
       "        2\n",
       "      ],\n",
       "      [\n",
       "        2,\n",
       "        2\n",
       "      ]\n",
       "    ],\n",
       "    \"torch_dtype\": \"bfloat16\",\n",
       "    \"vocab_offset\": 262272,\n",
       "    \"vocab_size\": 128\n",
       "  },\n",
       "  \"audio_soft_tokens_per_image\": 188,\n",
       "  \"audio_token_id\": 262273,\n",
       "  \"boa_token_id\": 256000,\n",
       "  \"boi_token_id\": 255999,\n",
       "  \"eoa_token_id\": 262272,\n",
       "  \"eoi_token_id\": 262144,\n",
       "  \"eos_token_id\": [\n",
       "    1,\n",
       "    106\n",
       "  ],\n",
       "  \"image_token_id\": 262145,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"model_type\": \"gemma3n\",\n",
       "  \"text_config\": {\n",
       "    \"activation_sparsity_pattern\": [\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.95,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0,\n",
       "      0.0\n",
       "    ],\n",
       "    \"altup_active_idx\": 0,\n",
       "    \"altup_coef_clip\": 120.0,\n",
       "    \"altup_correct_scale\": true,\n",
       "    \"altup_num_inputs\": 4,\n",
       "    \"attention_bias\": false,\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"final_logit_softcapping\": 30.0,\n",
       "    \"head_dim\": 256,\n",
       "    \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
       "    \"hidden_size\": 2048,\n",
       "    \"hidden_size_per_layer_input\": 256,\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"intermediate_size\": [\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384,\n",
       "      16384\n",
       "    ],\n",
       "    \"laurel_rank\": 64,\n",
       "    \"layer_types\": [\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"sliding_attention\",\n",
       "      \"full_attention\"\n",
       "    ],\n",
       "    \"max_position_embeddings\": 32768,\n",
       "    \"model_type\": \"gemma3n_text\",\n",
       "    \"num_attention_heads\": 8,\n",
       "    \"num_hidden_layers\": 35,\n",
       "    \"num_key_value_heads\": 2,\n",
       "    \"num_kv_shared_layers\": 15,\n",
       "    \"rms_norm_eps\": 1e-06,\n",
       "    \"rope_local_base_freq\": 10000.0,\n",
       "    \"rope_scaling\": null,\n",
       "    \"rope_theta\": 1000000.0,\n",
       "    \"sliding_window\": 512,\n",
       "    \"torch_dtype\": \"bfloat16\",\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 262400,\n",
       "    \"vocab_size_per_layer_input\": 262144\n",
       "  },\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.53.1\",\n",
       "  \"vision_config\": {\n",
       "    \"architecture\": \"mobilenetv5_300m_enc\",\n",
       "    \"do_pooling\": false,\n",
       "    \"hidden_size\": 2048,\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"label_names\": [\n",
       "      \"LABEL_0\",\n",
       "      \"LABEL_1\"\n",
       "    ],\n",
       "    \"model_args\": null,\n",
       "    \"model_type\": \"gemma3n_vision\",\n",
       "    \"num_classes\": 2,\n",
       "    \"rms_norm_eps\": 1e-06,\n",
       "    \"torch_dtype\": \"bfloat16\",\n",
       "    \"vocab_offset\": 262144,\n",
       "    \"vocab_size\": 128\n",
       "  },\n",
       "  \"vision_soft_tokens_per_image\": 256\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1753269331385,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "wYcgygMv_ixE",
    "outputId": "98786dcd-a747-47e9-8d2d-8c037db49222"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3nTextConfig {\n",
       "  \"activation_sparsity_pattern\": [\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.95,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0\n",
       "  ],\n",
       "  \"altup_active_idx\": 0,\n",
       "  \"altup_coef_clip\": 120.0,\n",
       "  \"altup_correct_scale\": true,\n",
       "  \"altup_num_inputs\": 4,\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"final_logit_softcapping\": 30.0,\n",
       "  \"head_dim\": 256,\n",
       "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
       "  \"hidden_size\": 2048,\n",
       "  \"hidden_size_per_layer_input\": 256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": [\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384,\n",
       "    16384\n",
       "  ],\n",
       "  \"laurel_rank\": 64,\n",
       "  \"layer_types\": [\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\"\n",
       "  ],\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"model_type\": \"gemma3n_text\",\n",
       "  \"num_attention_heads\": 8,\n",
       "  \"num_hidden_layers\": 35,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"num_kv_shared_layers\": 15,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_local_base_freq\": 10000.0,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": 512,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.53.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 262400,\n",
       "  \"vocab_size_per_layer_input\": 262144\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = original_config.text_config\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1753269731767,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "7L74MGMc_uR8",
    "outputId": "19cfbdeb-c4ac-424b-e50f-742ecfba8eaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layers = model_config.num_hidden_layers\n",
    "num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1753269758970,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "l_qJZDssBQBd",
    "outputId": "1d47298c-b635-4b00-c09b-144b749450c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 21, 22, 23, 24]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1753269807635,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "k0F93g1hBWrW",
    "outputId": "8fcacdb4-8873-4cbe-e3c8-1dbbd6991d5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_num_layers = num_layers - len(layers_to_skip)\n",
    "final_num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1753269824807,
     "user": {
      "displayName": "Ngo Hong Thai",
      "userId": "17743717354114238702"
     },
     "user_tz": -420
    },
    "id": "idCvehXaBgmm"
   },
   "outputs": [],
   "source": [
    "if len(ffn_hidden_dims) != final_num_layers:\n",
    "    raise ValueError(\n",
    "        f\"The length of ffn_hidden_dims ({len(ffn_hidden_dims)}) must be equal \"\n",
    "        f\"to the final number of layers ({final_num_layers}).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxOgxRxTBtKT"
   },
   "source": [
    "### Update configuration\n",
    "\n",
    " Khi bạn quyết định \"cắt bỏ\" một số lớp (ví dụ, bỏ 5 lớp để tạo mô hình 30 lớp), không chỉ số lượng lớp thay đổi, mà các tham số cấu hình khác liên quan đến các lớp đó cũng phải được cập nhật một cách thông minh. Đoạn code này làm chính xác điều đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cập nhật cấu hình chia sẻ Key-Value (KV Sharing):\n",
    "\n",
    "* **Mục đích**: Gemma 3n sử dụng một kỹ thuật gọi là KV Sharing để tiết kiệm bộ nhớ, trong đó một số lớp sẽ chia sẻ chung các tham số Key (K) và Value (V) trong cơ chế attention. Đoạn code này đảm bảo cấu hình KV Sharing được cập nhật đúng khi các lớp bị loại bỏ.\n",
    "* **Ý nghĩa các biến**:\n",
    "    * `model_config.num_hidden_layers`: Tổng số lớp của mô hình gốc (là 35).\n",
    "    * `model_config.num_kv_shared_layers`: Số lượng lớp chia sẻ KV trong mô hình gốc.\n",
    "    * `layers_to_skip`: Một danh sách chứa chỉ số của các lớp bạn muốn loại bỏ (ví dụ: `[20, 21, 22, 23, 24]`).\n",
    "    * `local_kv_sharing_layer_idx` và `global_kv_sharing_layer_idx`: Đây là chỉ số của các lớp rất đặc biệt, được dùng làm \"trung tâm\" chia sẻ KV. Đoạn `if` đảm bảo rằng bạn không thể vô tình xóa bỏ các lớp quan trọng này.\n",
    "    * `count_kv_sharing`: Đếm xem có bao nhiêu lớp chia sẻ KV (các lớp từ 20 trở đi) đã bị bạn loại bỏ.\n",
    "    * `model_config.num_kv_shared_layers -= count_kv_sharing`: Cập nhật lại tổng số lớp chia sẻ KV trong mô hình mới sau khi đã trừ đi các lớp bị loại bỏ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYawXs_xBmv9"
   },
   "outputs": [],
   "source": [
    "# Tính toán các chỉ số của các lớp đặc biệt\n",
    "num_kv_comp_layers = model_config.num_hidden_layers - model_config.num_kv_shared_layers\n",
    "local_kv_sharing_layer_idx = num_kv_comp_layers - 2\n",
    "global_kv_sharing_layer_idx = num_kv_comp_layers - 1\n",
    "\n",
    "# Kiểm tra xem các lớp đặc biệt có bị bỏ qua hay không\n",
    "if (local_kv_sharing_layer_idx in layers_to_skip or global_kv_sharing_layer_idx in layers_to_skip):\n",
    "  raise ValueError(f'Layers {local_kv_sharing_layer_idx} and {global_kv_sharing_layer_idx} are reserved.')\n",
    "\n",
    "# Đếm và cập nhật lại số lớp chia sẻ KV\n",
    "count_kv_sharing = sum(1 for layer in layers_to_skip if layer >= 20)\n",
    "model_config.num_kv_shared_layers -= count_kv_sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_config.text_config.num_kv_shared_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cập nhật cấu hình độ thưa của kích hoạt (Activation Sparsity):\n",
    "\n",
    "* **Mục đích**: Gemma 3n áp dụng \"độ thưa\" (sparsity) cho các hàm kích hoạt ở 10 lớp đầu tiên để tăng hiệu quả tính toán. Khi bạn xóa một trong số các lớp này, mô hình độ thưa cũng phải được điều chỉnh tương ứng.\n",
    "* **Ý nghĩa các biến**:\n",
    "    * `count_activation_sparsity`: Đếm xem có bao nhiêu lớp trong 10 lớp đầu tiên đã bị bạn loại bỏ.\n",
    "    * `final_num_layers`: Tổng số lớp của mô hình *sau khi* đã cắt bỏ.\n",
    "    * `activation_sparsity_list`: Tạo ra một danh sách mới. Danh sách này xác định mô hình độ thưa (sparsity pattern) cho các lớp còn lại, đảm bảo rằng cấu trúc này vẫn được duy trì một cách chính xác trong mô hình con."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đếm số lớp có độ thưa bị loại bỏ\n",
    "count_activation_sparsity = sum(1 for layer in layers_to_skip if layer <= 9)\n",
    "\n",
    "# Tạo lại danh sách mô hình độ thưa cho các lớp còn lại\n",
    "activation_sparsity_list = [0.95] * (10 - count_activation_sparsity) + [0] * (\n",
    "    final_num_layers - 10 + count_activation_sparsity\n",
    ")\n",
    "model_config.activation_sparsity_pattern = activation_sparsity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.num_hidden_layers = final_num_layers\n",
    "model_config.intermediate_size = ffn_hidden_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the configuration and the unchanged tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c7067c28444ac2887436dfe6671c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2721cce8f345a4bf068e1cd58b5c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.70M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c499384f8d459ea7e3472b2834dc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1751e7ad7e488897653e9bd6a45582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/769 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acce0c8756944181ab501c2b09a10f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New config saved to my_modified_gemma_3n_model\n",
      "Final number of layers: 30\n"
     ]
    }
   ],
   "source": [
    "original_config.save_pretrained(local_output_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(original_model_id)\n",
    "tokenizer.save_pretrained(local_output_path)\n",
    "\n",
    "print(f\"New config saved to {local_output_path}\")\n",
    "print(f\"Final number of layers: {model_config.num_hidden_layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model checkpoints\n",
    "\n",
    "Note: we are saving the model to disk, so there's no need to have a large CPU/GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f26ea4ae4049f58b2e3bbc8748ec51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b984952bdd486fa76f44d066eb5233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/2.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a348f50a258d432d9b5daaa173b07968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb38e4c8caa4dc6b9a736444be542fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e6f228d77a4429b2b184570a619c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_path = snapshot_download(original_model_id, allow_patterns=[\"*.safetensors\"])\n",
    "safetensor_files = [os.path.join(model_path, f) for f in os.listdir(model_path) if f.endswith('.safetensors')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58871f7fbe7546f0a7adf7945156a5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving shard model-00001-of-XXXXX.safetensors (size: 4.86 GB)\n",
      "Saving shard model-00002-of-XXXXX.safetensors (size: 4.63 GB)\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "kept_layers_indices = [i for i in range(num_layers) if i not in layers_to_skip]\n",
    "layer_rename_map = {old_idx: new_idx for new_idx, old_idx in enumerate(kept_layers_indices)}\n",
    "\n",
    "# This will store the mapping of tensor names to the file they are saved in\n",
    "weight_map = {}\n",
    "\n",
    "# This will store tensors for the current shard we are building\n",
    "new_shard_state_dict = {}\n",
    "shard_counter = 1\n",
    "total_size = 0\n",
    "\n",
    "pbar = tqdm(total=len(safetensor_files), desc=\"Processing shards\")\n",
    "\n",
    "for shard_path in safetensor_files:\n",
    "    # Open a shard for streaming\n",
    "    with safe_open(shard_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        # Iterate over each tensor in the shard\n",
    "        for tensor_name in f.keys():\n",
    "            new_tensor_name = tensor_name\n",
    "            tensor = f.get_tensor(tensor_name)\n",
    "\n",
    "            # Case 1: Handle layer-specific parameters\n",
    "            match = re.search(r'\\.layers\\.(\\d+)\\.', tensor_name)\n",
    "            if match:\n",
    "                old_layer_idx = int(match.group(1))\n",
    "\n",
    "                # If this layer is meant to be skipped, we just continue to the next tensor\n",
    "                if old_layer_idx in layers_to_skip:\n",
    "                    continue\n",
    "\n",
    "                # Get the new sequential layer index\n",
    "                new_layer_idx = layer_rename_map[old_layer_idx]\n",
    "                new_tensor_name = tensor_name.replace(\n",
    "                    f'.layers.{old_layer_idx}.',\n",
    "                    f'.layers.{new_layer_idx}.'\n",
    "                )\n",
    "\n",
    "                # Get the target FFN dimension for this new layer\n",
    "                target_ffn_dim = ffn_hidden_dims[new_layer_idx]\n",
    "\n",
    "                # Check if this parameter is part of the FFN and needs slicing\n",
    "                if 'mlp.gate_proj.weight' in new_tensor_name or 'mlp.up_proj.weight' in new_tensor_name:\n",
    "                    # These layers project from model_dim -> ffn_hidden_dim.\n",
    "                    # We slice the output dimension (dim 0).\n",
    "                    tensor = tensor[:target_ffn_dim, :].contiguous()\n",
    "                elif 'mlp.down_proj.weight' in new_tensor_name:\n",
    "                    # This layer projects from ffn_hidden_dim -> model_dim.\n",
    "                    # We slice the input dimension (dim 1).\n",
    "                    tensor = tensor[:, :target_ffn_dim].contiguous()\n",
    "\n",
    "            # Case 2: Handle special non-layer parameters that need slicing\n",
    "            elif 'per_layer_model_projection' in tensor_name:\n",
    "                # Reshape, slice based on kept layers, and reshape back\n",
    "                reshaped_params = tensor.reshape((num_layers, tensor.shape[0] // num_layers, tensor.shape[1]))\n",
    "                tensor = reshaped_params[kept_layers_indices, :, :]\n",
    "                tensor = tensor.reshape(-1, tensor.shape[-1]).contiguous()\n",
    "\n",
    "            elif 'embed_tokens_per_layer' in tensor_name:\n",
    "                # Reshape, slice based on kept layers, and reshape back\n",
    "                reshaped_params = tensor.reshape((tensor.shape[0], num_layers, tensor.shape[1] // num_layers))\n",
    "                tensor = reshaped_params[:, kept_layers_indices, :]\n",
    "                tensor = tensor.reshape(tensor.shape[0], -1).contiguous()\n",
    "\n",
    "            # Add the (potentially modified) tensor to the new shard\n",
    "            new_shard_state_dict[new_tensor_name] = tensor\n",
    "\n",
    "            # Check if the current shard is getting too big\n",
    "            current_shard_size = sum(t.numel() * t.element_size() for t in new_shard_state_dict.values())\n",
    "            if current_shard_size > 4000000000: # Create new shard if current is over 4GB\n",
    "                shard_filename = f\"model-{(shard_counter):05d}-of-XXXXX.safetensors\"\n",
    "                print(f\"Saving shard {shard_filename} (size: {current_shard_size / 1e9:.2f} GB)\")\n",
    "                save_file(new_shard_state_dict, os.path.join(local_output_path, shard_filename), metadata={'format': 'pt'})\n",
    "\n",
    "                # Record which tensors are in this shard\n",
    "                for k in new_shard_state_dict.keys():\n",
    "                    weight_map[k] = os.path.basename(shard_filename)\n",
    "\n",
    "                # Reset for the next shard\n",
    "                shard_counter += 1\n",
    "                new_shard_state_dict = {}\n",
    "                gc.collect() # Free up memory\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final shard model-00003-of-XXXXX.safetensors\n"
     ]
    }
   ],
   "source": [
    "# Save any remaining tensors in the last shard\n",
    "if new_shard_state_dict:\n",
    "    shard_filename = f\"model-{(shard_counter):05d}-of-XXXXX.safetensors\"\n",
    "    print(f\"Saving final shard {shard_filename}\")\n",
    "    save_file(new_shard_state_dict, os.path.join(local_output_path, shard_filename), metadata={'format': 'pt'})\n",
    "    for k in new_shard_state_dict.keys():\n",
    "        weight_map[k] = os.path.basename(shard_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del new_shard_state_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Finalizing Model Save ---\n",
      "\n",
      "✅ Model slicing complete. New model saved in: my_modified_gemma_3n_model\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"\\n--- 3. Finalizing Model Save ---\")\n",
    "\n",
    "# The total number of shards we created\n",
    "num_shards = shard_counter\n",
    "\n",
    "# Update the \"XXXXX\" in the filenames to the correct total number of shards\n",
    "for i in range(1, num_shards + 1):\n",
    "    old_filename = f\"model-{(i):05d}-of-XXXXX.safetensors\"\n",
    "    new_filename = f\"model-{(i):05d}-of-{(num_shards):05d}.safetensors\"\n",
    "\n",
    "    # Rename the file\n",
    "    os.rename(os.path.join(local_output_path, old_filename), os.path.join(local_output_path, new_filename))\n",
    "\n",
    "    # Update the weight_map to point to the new filename\n",
    "    for k, v in weight_map.items():\n",
    "        if v == old_filename:\n",
    "            weight_map[k] = new_filename\n",
    "\n",
    "# Create and save the index.json file\n",
    "index_json = {\n",
    "    \"metadata\": {\n",
    "        \"total_size\": sum(os.path.getsize(os.path.join(local_output_path, f)) for f in os.listdir(local_output_path) if f.endswith('.safetensors'))\n",
    "    },\n",
    "    \"weight_map\": weight_map\n",
    "}\n",
    "\n",
    "with open(os.path.join(local_output_path, \"model.safetensors.index.json\"), \"w\") as f:\n",
    "    json.dump(index_json, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Model slicing complete. New model saved in: {local_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551646c8032f412bbd89c6581625bff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/24.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepended custom description to the model card content.\n",
      "New README.md saved to 'my_modified_gemma_3n_model/README.md'\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import  ModelCard, ModelCardData\n",
    "\n",
    "card = ModelCard.load(original_model_id)\n",
    "card.data.base_model = original_model_id\n",
    "del card.data.extra_gated_heading\n",
    "del card.data.extra_gated_prompt\n",
    "card.data.tags.append(\"matformer\")\n",
    "\n",
    "new_description = f\"\"\"\n",
    "> [!Note]\n",
    "> This is a submodel derived from `{original_model_id}`. It has been modified by slicing specific layers and resizing FFN dimensions. It is not the original model.\n",
    "> To learn more about MatFormers, please review the [launch blog](https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide) and generate your own submodels\n",
    "with the [MatFormer Lab](https://goo.gle/gemma3n-matformer-lab).\n",
    ">\n",
    "\n",
    "Skipped layers: {layers_to_skip}\n",
    "\n",
    "FFN hidden dimensions: {ffn_hidden_dims_str}\n",
    "\"\"\"\n",
    "\n",
    "card.text = new_description + \"\\n\" + card.text\n",
    "print(\"Prepended custom description to the model card content.\")\n",
    "\n",
    "new_readme_path = os.path.join(local_output_path, \"README.md\")\n",
    "card.save(new_readme_path)\n",
    "print(f\"New README.md saved to '{new_readme_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the model to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating private repository: ngohongthai/test-submodel\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "print(f\"Creating private repository: {push_hf_repo_id}\")\n",
    "\n",
    "# Instantiate the HfApi client\n",
    "api = HfApi()\n",
    "\n",
    "# Create a new private repository on the Hub.\n",
    "repo_url = api.create_repo(\n",
    "    repo_id=push_hf_repo_id,\n",
    "    private=True,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading files from 'my_modified_gemma_3n_model' to 'ngohongthai/test-submodel'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550a6cc49740488abf94bf978ebbe950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50aee7c2c1024f86a1985bb189271c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a8dd70c5d54799b7898f6ae7a8b47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a88e2ff661c44da8684d5e9ebc2621b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731aa9c6d7e54028a15503452605b0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.70M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb2dd00be93438b8ec7c222a05a953a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ngohongthai/test-submodel/commit/4085e6ca1324781669801266f9ffe84f44171fd0', commit_message='Upload sliced model checkpoint', commit_description='', oid='4085e6ca1324781669801266f9ffe84f44171fd0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ngohongthai/test-submodel', endpoint='https://huggingface.co', repo_type='model', repo_id='ngohongthai/test-submodel'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Uploading files from '{local_output_path}' to '{push_hf_repo_id}'...\")\n",
    "api.upload_folder(\n",
    "    folder_path=local_output_path,\n",
    "    repo_id=push_hf_repo_id,\n",
    "    repo_type=\"model\",\n",
    "    commit_message=\"Upload sliced model checkpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify new model can be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dc744c31c94f17915a5c39e2827014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 6,027,165,120\n",
      "Total Text Parameters: 4,506,488,416\n",
      "Effective Parameters (excluding vision, audio, and Per-Layer-Embeddings): 1,955,827,296\n"
     ]
    }
   ],
   "source": [
    "#@title Verify new model can be loaded\n",
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(push_hf_repo_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "print(f\"Total Parameters: {model.num_parameters():,}\") # 5,976,833,408\n",
    "print(f\"Total Text Parameters: {model.language_model.num_parameters():,}\") # 4,456,156,768\n",
    "print(f\"Effective Parameters (excluding vision, audio, and Per-Layer-Embeddings): {model.language_model.num_parameters(exclude_embeddings=True):,}\") # 1,905,495,648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzowThlqB7vnEsl4rNHH3/",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "learn-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01c902390b5340c9871a4bd30cbe7aad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb24b163af204e7298ba259e7bbc5965",
      "placeholder": "​",
      "style": "IPY_MODEL_5aa3381a60404ac9947d88f126d49745",
      "value": " 4.54k/4.54k [00:00&lt;00:00, 170kB/s]"
     }
    },
    "06d0c33c422f46c6b55daa6de076b53c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2079304e45244ec1b53d73e02bff102a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_527ebf26b7dd4b94a40c9be6dbd7a4c7",
      "placeholder": "​",
      "style": "IPY_MODEL_5495552f37b6485d8f749fbed718205d",
      "value": "config.json: 100%"
     }
    },
    "2f184c7541bb48b68ef4d9e908ec4632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_618290a83b8640cd92a04af53c8d3dc4",
       "IPY_MODEL_fe7b3a7a08534c8fa0ffcd6d70ea679d",
       "IPY_MODEL_4cc3f543f21e4502ab0e027cc99946ce",
       "IPY_MODEL_4f941bd663bd4321b31d899c3818e5e6",
       "IPY_MODEL_dc6fc547dd5f42a4a0b10b379a473102"
      ],
      "layout": "IPY_MODEL_e901deb71818453ea0d452cfceae2347"
     }
    },
    "337c2ba459e04d5a946b680e8598f21d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bf3a6b3248b4aeeb6f5228e5d9c0d67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "49bf2d6cc1da408faf6c752a9225e7dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cc3f543f21e4502ab0e027cc99946ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_de924f5124f3401680fa421244bc4cbd",
      "style": "IPY_MODEL_06d0c33c422f46c6b55daa6de076b53c",
      "value": true
     }
    },
    "4f941bd663bd4321b31d899c3818e5e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_b543af171d4443caa282d017daebcd05",
      "style": "IPY_MODEL_3bf3a6b3248b4aeeb6f5228e5d9c0d67",
      "tooltip": ""
     }
    },
    "4ff13942afcc4592a9495f77756d924e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "527ebf26b7dd4b94a40c9be6dbd7a4c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5495552f37b6485d8f749fbed718205d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54aa43966e8d4649920516da818a5930": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5aa3381a60404ac9947d88f126d49745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "618290a83b8640cd92a04af53c8d3dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49bf2d6cc1da408faf6c752a9225e7dc",
      "placeholder": "​",
      "style": "IPY_MODEL_337c2ba459e04d5a946b680e8598f21d",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "7c2f552a824f4077a525937e84a40111": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86b0b1f8225145f088281f166cfa343a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "987550d76b7d45549096cb07928a3278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2079304e45244ec1b53d73e02bff102a",
       "IPY_MODEL_a5f3b3e2bdfd4b49b797b54d3fe6e314",
       "IPY_MODEL_01c902390b5340c9871a4bd30cbe7aad"
      ],
      "layout": "IPY_MODEL_7c2f552a824f4077a525937e84a40111"
     }
    },
    "a5f3b3e2bdfd4b49b797b54d3fe6e314": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fff785435c9a48a39b5b329ba62df081",
      "max": 4536,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4ff13942afcc4592a9495f77756d924e",
      "value": 4536
     }
    },
    "b543af171d4443caa282d017daebcd05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce064ed719b347f6a9ca629cadbfa609": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc6fc547dd5f42a4a0b10b379a473102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86b0b1f8225145f088281f166cfa343a",
      "placeholder": "​",
      "style": "IPY_MODEL_fa3d76524eab45129a1a0eaf7adafd75",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "de924f5124f3401680fa421244bc4cbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e901deb71818453ea0d452cfceae2347": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "eb24b163af204e7298ba259e7bbc5965": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3d76524eab45129a1a0eaf7adafd75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe7b3a7a08534c8fa0ffcd6d70ea679d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_ce064ed719b347f6a9ca629cadbfa609",
      "placeholder": "​",
      "style": "IPY_MODEL_54aa43966e8d4649920516da818a5930",
      "value": ""
     }
    },
    "fff785435c9a48a39b5b329ba62df081": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
