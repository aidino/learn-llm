[Sitemap](https://medium.com/sitemap/sitemap.xml)
Sign up
[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)
[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)
[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)
[](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)
Sign up
[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)
![](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)
## [Decoding ML](https://medium.com/decodingml?source=post_page---publication_nav-57b7a1f365ee-9cc01d50a2a0---------------------------------------)
·
[Follow publication](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fdecodingml&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&collection=Decoding+ML&collectionId=57b7a1f365ee&source=post_page---publication_nav-57b7a1f365ee-9cc01d50a2a0---------------------publication_nav------------------)
[![Decoding ML](https://miro.medium.com/v2/resize:fill:38:38/1*26Oyys83TRIKEtdUM1uZRA.png)](https://medium.com/decodingml?source=post_page---post_publication_sidebar-57b7a1f365ee-9cc01d50a2a0---------------------------------------)
Battle-tested content on designing, coding, and deploying production-grade ML & MLOps systems. The hub for continuous learning on ML system design, ML engineering, MLOps, large language models (LLMs), and computer vision (CV).
[Follow publication](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fdecodingml&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&collection=Decoding+ML&collectionId=57b7a1f365ee&source=post_page---post_publication_sidebar-57b7a1f365ee-9cc01d50a2a0---------------------post_publication_sidebar------------------)
# A Real-time Retrieval System for RAG on Social Media Data
## Use a streaming engine to populate a vector DB in real-time. Improve RAG accuracy using rerank & UMAP.
[![Paul Iusztin](https://miro.medium.com/v2/resize:fill:32:32/1*r3Geug_sW6weKSvaqBJtAA.jpeg)](https://medium.com/@pauliusztin?source=post_page---byline--9cc01d50a2a0---------------------------------------)
[Paul Iusztin](https://medium.com/@pauliusztin?source=post_page---byline--9cc01d50a2a0---------------------------------------)
Follow
12 min read
·
Mar 30, 2024
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdecodingml%2F9cc01d50a2a0&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&user=Paul+Iusztin&userId=8323de62a1a1&source=---header_actions--9cc01d50a2a0---------------------clap_footer------------------)
323
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9cc01d50a2a0&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&source=---header_actions--9cc01d50a2a0---------------------bookmark_footer------------------)
[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D9cc01d50a2a0&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&source=---header_actions--9cc01d50a2a0---------------------post_audio_button------------------)
Share
![](https://miro.medium.com/v2/resize:fit:700/1*mm9nB9FZq-u5alVd_chwyg.png)
Image by DALL-E
In this article, you will learn how to build a real-time retrieval system for social media data. In our example, we will use only my LinkedIn posts, but our implementation can easily be extended to other platforms supporting written content, such as X, Instagram, or Medium.
**In this article, you will learn how to:**
  * build a streaming pipeline that ingests LinkedIn posts into a vector DB in real-time
  * clean, chunk, and embed LinkedIn posts
  * build a retrieval client to query LinkedIn posts
  * use a rerank pattern to improve retrieval accuracy
  * visualize content retrieved for a given query in a 2D plot using UMAP


Our implementation focuses on just the retrieval part of an RAG system. But you can quickly hook the retrieved LinkedIn posts to an LLM for post analysis or personalized content generation.
# Table of Contents:
  1. System Design
  2. Data
  3. Streaming ingestion pipeline
  4. Retrieval client
  5. Conclusion


# 1. System Design
The retrieval system is based on 2 detached components:
  1. the streaming ingestion pipeline
  2. the retrieval client


![](https://miro.medium.com/v2/resize:fit:1000/0*SfXvnsaSFcBZUMmi.png)
The architecture of the retrieval system [Image by the Author — in collaboration with VectorHub].
The **streaming ingestion pipeline** runs 24/7 to keep the vector DB synced up with current raw LinkedIn posts data source, while the **retrieval client** is used in RAG applications to query the vector DB. These 2 components **communicate with each other only through the vector DB**.
## 1.1. The streaming ingestion pipeline
The streaming ingestion pipeline implements the between a data source containing the raw LinkedIn posts and the vector DB used for retrieval.
In a real-world scenario, the streaming pipeline listens to a queue populated by all the changes made to the source database. But because we are focusing primarily on the retrieval system, we simulate the data within the queue with a couple of JSON files.
The streaming pipeline is built in Python using Bytewax, and cleans, chunks, and embeds the LinkedIn posts before loading them into a vector DB.
**Why do we need a stream engine?**
Because LinkedIn posts (or any other social media data) evolve frequently, your vector DB can quickly get out of sync. To handle this, you can build a batch pipeline that runs every minute. But to really minimize data lag, to **make sure your vector DB stays current with new social media posts** , you need to use a streaming pipeline that **immediately** takes every new item the moment it’s posted, preprocesses it, and loads it into the vector DB.
**Why Bytewax?**
is a streaming engine built in Rust that exposes a Python interface. We use Bytewax because it combines the impressive speed and reliability of Rust with the ease of use and ecosystem of Python.
## 1.2. The retrieval client
Our retrieval client is a standard Python module that preprocesses user queries and searches the vector DB for most similar results. Qdrant vector DB lets us decouple the retrieval client from the streaming ingestion pipeline.
Using a semantic-based retrieval system lets us query our LinkedIn post collection very flexibly. For example, we can retrieve similar posts using a variety of query types — e.g., posts, questions, sentences.
Also, to improve the retrieval system’s accuracy, we use a rerank pattern.
Lastly, to better understand and explain the retrieval process for particular queries, we visualize our results on a 2D plot using UMAP.
# 2. Data
We will ingest 215 LinkedIn posts from . Though we simulate the post ingestion step using JSON files, the posts themselves are authentic.
Before diving into the code, let’s take a look at an example LinkedIn post to familiarize ourselves with the challenges it will introduce ↓
```
[  {    "text": "𝗪𝗵𝗮𝘁 do you need to 𝗳𝗶𝗻𝗲-𝘁𝘂𝗻𝗲 an open-source 𝗟𝗟𝗠 to create your own 𝗳𝗶𝗻𝗮𝗻𝗰𝗶𝗮𝗹 𝗮𝗱𝘃𝗶𝘀𝗼𝗿?\nThis is the 𝗟𝗟𝗠 𝗳𝗶𝗻𝗲-𝘁𝘂𝗻𝗶𝗻𝗴 𝗸𝗶𝘁 you must know ↓\n𝗗𝗮𝘁𝗮𝘀𝗲𝘁\nThe key component of any successful ML project is the data.\nYou need a 100 - 1000 sample Q&A (questions & answers) dataset with financial scenarios.\nThe best approach is to hire a bunch of experts to create it manually.\nBut, for a PoC, that might get expensive & slow.\nThe good news is that a method called \"𝘍𝘪𝘯𝘦𝘵𝘶𝘯𝘪𝘯𝘨 𝘸𝘪𝘵𝘩 𝘥𝘪𝘴𝘵𝘪𝘭𝘭𝘢𝘵𝘪𝘰𝘯\" exists.\n ...Along with ease of deployment, you can easily add your training code to your CI/CD to add the final piece of the MLOps puzzle, called CT (continuous training).\n↳ Beam: 🔗\nhttps://lnkd.in/dedCaMDh\n.\n↳ To see all these components in action, check out my FREE 𝗛𝗮𝗻𝗱𝘀-𝗼𝗻 𝗟𝗟𝗠𝘀 𝗰𝗼𝘂𝗿𝘀𝗲 & give it a ⭐: 🔗\nhttps://lnkd.in/dZgqtf8f\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops\nhashtag\n#\ndatascience",    "image": "https://media.licdn.com/dms/image/D4D10AQHWQzZcToQQ1Q/image-shrink_800/0/1698388219549?e=1705082400&v=beta&t=9mrDC_NooJgD7u7Qk0PmrTGGaZtuwDIFKh3bEqeBsm0"  }]
```

The following features of the above post are not compatible with embedding models. We’ll need to find some way of handling them in our preprocessing step:
  * emojis
  * bold, italic text
  * other non-ASCII characters
  * URLs
  * content that exceeds the context window limit of the embedding model


Emojis and bolded and italic text are represented by Unicode characters that are not available in the vocabulary of the embedding model. Thus, these items cannot be tokenized and passed to the model; we have to remove them or normalize them to something that can be parsed by the tokenizer. The same holds true for all other non-ASCII characters.
URLs take up space in the context window without providing much semantic value. Still, knowing that there’s a URL in the sentence may add context. For this reason, we replace all URLs with a [URL] token. This lets us ingest whatever value the URL’s presence conveys without it taking up valuable space.
# 3. Streaming ingestion pipeline
Let’s dive into the streaming pipeline, starting from the top and working our way to the bottom ↓
## 3.1. The Bytewax flow
**The Bytewax flow** transparently conveys all the steps of the streaming pipeline.
The first step is ingesting every LinkedIn post from our JSON files. In the next steps, every map operation has a single responsibility:
  * validate the ingested data using a _RawPost pydantic model_
  * clean the posts
  * chunk the posts; because chunking will output a list of ChunkedPost objects, we use a flat_map operation to flatten them out
  * embed the posts
  * load the posts to a Qdrant vector DB

```
def build_flow():  embedding_model = EmbeddingModelSingleton()  flow = Dataflow("flow")  stream = op.input("input", flow, JSONSource(["data/paul.json"]))  stream = op.map("raw_post", stream, RawPost.from_source)  stream = op.map("cleaned_post", stream, CleanedPost.from_raw_post)  stream = op.flat_map(    "chunked_post",    stream,    lambda cleaned_post: ChunkedPost.from_cleaned_post(      cleaned_post, embedding_model=embedding_model    ),  )  stream = op.map(    "embedded_chunked_post",    stream,    lambda chunked_post: EmbeddedChunkedPost.from_chunked_post(      chunked_post, embedding_model=embedding_model    ),  )  op.inspect("inspect", stream, print)  op.output(    "output", stream, QdrantVectorOutput(vector_size=model.embedding_size)  )    return flow
```

## 3.2. The processing steps
Every processing step is incorporated into a _pydantic model_. This way, we can easily validate the data at each step and reuse the code in the retrieval module.
We isolate every step of an ingestion pipeline into its own class:
  * cleaning
  * chunking
  * embedding


Doing so, we follow the separation of concerns good SWE practice. Thus, every class has its own responsibility.
Now the code is easy to read and understand. Also, it’s future-proof, as it’s extremely easy to change or extend either of the 3 steps: cleaning, chunking and embedding.
Here is the interface of the _pydantic models_ :
```
class RawPost(BaseModel):  post_id: str  text: str  image: Optional[str]  @classmethod  def from_source(cls, k_v: Tuple[str, dict]) -> "RawPost":    ... # Mapping a dictionary to a RawPost validated pydantic model.    return cls(...)class CleanedPost(BaseModel):  post_id: str  raw_text: str  text: str  image: Optional[str]  @classmethod  def from_raw_post(cls, raw_post: RawPost) -> "CleanedPost":    ... # Cleaning the raw post    return cls(...)class ChunkedPost(BaseModel):  post_id: str  chunk_id: str  full_raw_text: str  text: str  image: Optional[str]  @classmethod  def from_cleaned_post(    cls, cleaned_post: CleanedPost, embedding_model: EmbeddingModelSingleton  ) -> list["ChunkedPost"]:    chunks = ... # Compute chunks    return [cls(...) for chunk in chunks]class EmbeddedChunkedPost(BaseModel):  post_id: str  chunk_id: str  full_raw_text: str  text: str  text_embedding: list  image: Optional[str] = None  score: Optional[float] = None  rerank_score: Optional[float] = None  @classmethod  def from_chunked_post(    cls, chunked_post: ChunkedPost, embedding_model: EmbeddingModelSingleton  ) -> "EmbeddedChunkedPost":    ... # Compute embedding.    return cls(...)
```

Now, the data at each step is validated and has a clear structure.
**Note:** Providing different types when instantiating a _pydantic_ model will throw a validation error. For example, if the _post_id_ is defined as a _string_ , and we try to instantiate an _EmbeddedChunkedPost_ with a _None_ or _int_ _post_id_ , it will throw an error.
> Check out the full implementation on our 🔗 .
## 3.3. Load to Qdrant
To load the LinkedIn posts to Qdrant, you have to override Bytewax’s _StatelessSinkPartition_ class (which acts as an **output** in a Bytewax flow):
```
class QdrantVectorSink(StatelessSinkPartition):  def __init__(    self,    client: QdrantClient,    collection_name: str  ):    self._client = client    self._collection_name = collection_name  def write_batch(self, chunks: list[EmbeddedChunkedPost]):    ... # Map chunks to ids, embeddings, and metadata.    self._client.upsert(      collection_name=self._collection_name,      points=Batch(        ids=ids,        vectors=embeddings,        payloads=metadata,      ),    )
```

Within this class, you must overwrite the _write_batch()_ method, where we will serialize every _EmbeddedChunkedPost_ to a format expected by Qdrant and load it to the vector DB.
# 4. Retrieval client
Here, we focus on preprocessing a user’s query, searching the vector DB, and postprocessing the retrieved posts for maximum results.
To design the retrieval step, we implement a _QdrantVectorDBRetriever_ class to expose all the necessary features for our retrieval client.
```
class QdrantVectorDBRetriever:  def __init__(    self,    embedding_model: EmbeddingModelSingleton,    vector_db_client: QdrantClient,    cross_encoder_model: CrossEncoderModelSingleton    vector_db_collection: str  ):    self._embedding_model = embedding_model    self._vector_db_client = vector_db_client    self._cross_encoder_model = cross_encoder_model    self._vector_db_collection = vector_db_collection  def search(    self, query: str, limit: int = 3, return_all: bool = False  ) -> Union[list[EmbeddedChunkedPost], dict[str, list]]:    ... # Search the Qdrant vector DB based on the given query.  def embed_query(self, query: str) -> list[list[float]]:    ... # Embed the given query.  def rerank(self, query: str, posts: list[EmbeddedChunkedPost]) -> list[EmbeddedChunkedPost]:    ... # Rerank the posts relative to the given query.  def render_as_html(self, post: EmbeddedChunkedPost) -> None:    ... # Map the embedded post to HTML to display it.
```

## 4.1. Embed query
We must embed the query in precisely the same way we ingested our posts into the vector DB. Because the streaming pipeline is written in Python (thanks to Bytewax), and every preprocessing operation is modular, we can quickly replicate all the steps necessary to embed the query.
```
class QdrantVectorDBRetriever:  ...  def embed_query(self, query: str) -> list[list[float]]:    cleaned_query = CleanedPost.clean(query)    chunks = ChunkedPost.chunk(cleaned_query, self._embedding_model)    embdedded_queries = [      self._embedding_model(chunk, to_list=True) for chunk in chunks    ]    return embdedded_queries
```

> Check out the full implementation on our _🔗_ .
## 4.2. Plain retrieval
Let’s try to retrieve a set of posts without using the rerank algorithm.
```
vector_db_retriever = QdrantVectorDBRetriever(  embedding_model=EmbeddingModelSingleton(),  vector_db_client=build_qdrant_client())query = "Posts about Qdrant"retrieved_results = vector_db_retriever.search(query=query)for post in retrieved_results["posts"]:  vector_db_retriever.render_as_html(post)
```

_Here are the_** _top 2 retrieved results_** _sorted using the cosine similarity score ↓_
**Result 1:**
![](https://miro.medium.com/v2/resize:fit:1000/0*R5L_euGz8OIjuYCU.png)
Result 1 for the “Posts about Qdrant” query (without using reranking) [Image by the Author — in collaboration with VectorHub]
**Result 2:**
![](https://miro.medium.com/v2/resize:fit:1000/0*xhXHUhfATKq8khO9.png)
Result 2 for the “Posts about Qdrant” query (without using reranking) [Image by the Author — in collaboration with VectorHub]
You can see from the results above, that starting from the second post the results are irrelevant. Even though it has a cosine similarly score of ~0.69 the posts doesn’t contain any information about Qdrant or vector DBs.
**Note:** We looked over the top 5 retrieved results. Nothing after the first post was relevant. We haven’t added them here as the article is already too long.
## 4.3. Visualize retrieval
To visualize our retrieval, we implement a dedicated class that uses the UMAP dimensionality reduction algorithm. We have picked UMAP as it preserves the geometric properties between points (e.g., the distance) in higher dimensions when they are projected onto lower dimensions better than its peers (e.g., PCA, t-SNE).
The _RetrievalVisualizer_ computes the projected embeddings for the entire vector space once. Afterwards, it uses the render() method to project only the given query and retrieved posts, and plot them to a 2D graph.
```
class RetrievalVisualizer:  def __init__(self, posts: list[EmbeddedChunkedPost]):    self._posts = posts    self._umap_transform = self._fit_model(self._posts)    self._projected_post_embeddings = self.project_posts(self._posts)  def _fit_model(self, posts: list[EmbeddedChunkedPost]) -> umap.UMAP:    umap_transform = ... # Fit a UMAP model on the given posts.    return umap_transform  def project_posts(self, posts: list[EmbeddedChunkedPost]) -> np.ndarray:    embeddings = np.array([post.text_embedding for post in posts])    return self._project(embeddings=embeddings)  def _project(self, embeddings: np.ndarray) -> np.ndarray:    ... # Project the embeddings to 2D using UMAP.    return umap_embeddings  def render(    self,    embedded_queries: list[list[float]],    retrieved_posts: list[EmbeddedChunkedPost],  ) -> None:   ... # Render the given queries & retrieved posts using matplotlib.
```

_Let’s take a look at the result to see how the “Posts about Qdrant” query looks ↓_
![](https://miro.medium.com/v2/resize:fit:700/0*nHkwv8htoaVo5EQf.png)
Visualization of the “Posts about Qdrant” query using UMAP (without reranking) [Image by the Author — in collaboration with VectorHub].
Our results are not great. You can see how far the retrieved posts are from our query in the vector space.
Can we improve the quality of our retrieval system using the **rerank** algorithm?
## 4.4. Rerank
We use the _reranking_ algorithm to refine our retrieval for the initial query. Our initial retrieval step — because it used cosine similarity (or similar distance metrics) to compute the distance between a query and post embeddings — may have missed more complex (but essential) relationships between the query and the documents in the vector space. Reranking leverages the power of transformer models that are capable of understanding more nuanced semantic relationships.
We use a **cross-encoder** model to implement the reranking step, so we can score the query relative to all retrieved posts individually. These scores take into consideration more complex relationships than cosine similarity can. Under the hood is a BERT classifier that outputs a number between 0 and 1 according to how similar the 2 given sentences are. The BERT classifier outputs 0 if they are entirely different and 1 if they are a perfect match.
![](https://miro.medium.com/v2/resize:fit:700/0*86jt5YNILwTtyhZX.png)
Bi-Encoder vs. Cross-Encoder [Image by the Author — in collaboration with VectorHub]
Bi-Encoder vs. Cross-Encoder [Image by the Author — in collaboration with VectorHub]
But, you might ask, “ _Why not use the_** _cross-encoder_** _model from the start if it is that much better?”_
The answer, in a word, is speed. Using a cross-encoder model to search your whole collection is much slower than using cosine similarity. To optimize your retrieval, therefore, your reranking process should involve 2 steps:
  1. an initial rough retrieval step using cosine similarity, which retrieves the top N items as potential candidates
  2. filtering the rough search using the rerank strategy, which retrieves the top K items as your final results


The implementation is relatively straightforward. For each retrieved post, we create a pair consisting of the (cleaned) query and the text of the post. We do this for all retrieved posts, resulting in a list of pairs.
Next, we call a _cross-encoder/ms-marco-MiniLM-L-6-v2_ model (from sentence-transformers) to give the retrieved posts their rerank score. We then sort the posts in descending order based on their rerank score.
> Check out the rerank algorithm implementation on our 🔗 .
## 4.5. Visualize retrieval with rerank
Now that we’ve added the rerank pattern to our retrieval system, let’s see if it improves the results of our _“Posts about Qdrant”_ query ↓
**Result 1**
![](https://miro.medium.com/v2/resize:fit:1000/0*hKRNu3jQ2V2_JrrM.png)
Result 1 for the “Posts about Qdrant” query (using reranking) [Image by the Author — in collaboration with VectorHub]
**Result 2:**
![](https://miro.medium.com/v2/resize:fit:1000/0*SvKByecO1s8UIZ65.png)
Result 2 for the “Posts about Qdrant” query (using reranking) [Image by the Author — in collaboration with VectorHub]
The improvement is remarkable! All our results are about Qdrant and vector DBs.
**Note:** We looked over the top 5 retrieved results. The top 4 out of 5 posts are relevant to our query, which is incredible.
Now, let’s look at the UMAP visualization:
![](https://miro.medium.com/v2/resize:fit:700/0*46m4qp3GlPAuC82g.png)
Visualization of the “Posts about Qdrant” query using UMAP (with reranking) [Image by the Author — in collaboration with VectorHub].
While the returned posts aren’t very close to the query, they are **a lot closer to the query compared to when we weren’t reranking the retrieved posts**.
# 5. Conclusion
In this article, we learned how to adapt a RAG retrieval pattern to improve LinkedIn post retrieval. To keep our database up to date with rapidly changing social media data, we implemented a real-time streaming pipeline that uses CDC to sync the raw LinkedIn posts data source with a vector DB. You also saw how to use Bytewax to write — using only Python — a streaming pipeline that cleans, chunks, and embeds LinkedIn posts.
Finally, you learned how to implement a standard retrieval client for RAG and saw how to improve it using the rerank pattern. As retrieval is complex to evaluate, you saw how to visualize the retrieval for a given query by rendering all the posts, the query, and the retrieved posts in a 2D space using UMAP.
> _This_** _article_** _is a_** _summary_** _of_** _my contribution_** _from_** _VectorHub_** _.__to_** _dig_**** _into_** _the_** _details,_**_the_** _code_** _and_** _more experiments_** _._
→ Join 5k+ engineers in the 𝗗𝗲𝗰𝗼𝗱𝗶𝗻𝗴 𝗠𝗟 𝗡𝗲𝘄𝘀𝗹𝗲𝘁𝘁𝗲𝗿 for battle-tested content on production-grade ML. 𝗘𝘃𝗲𝗿𝘆 𝘄𝗲𝗲𝗸:
[Ml System Design](https://medium.com/tag/ml-system-design?source=post_page-----9cc01d50a2a0---------------------------------------)
[Artificial Intelligence](https://medium.com/tag/artificial-intelligence?source=post_page-----9cc01d50a2a0---------------------------------------)
[Machine Learning](https://medium.com/tag/machine-learning?source=post_page-----9cc01d50a2a0---------------------------------------)
[Streaming Pipeline](https://medium.com/tag/streaming-pipeline?source=post_page-----9cc01d50a2a0---------------------------------------)
[Data Science](https://medium.com/tag/data-science?source=post_page-----9cc01d50a2a0---------------------------------------)
[![Decoding ML](https://miro.medium.com/v2/resize:fill:48:48/1*26Oyys83TRIKEtdUM1uZRA.png)](https://medium.com/decodingml?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------)
[![Decoding ML](https://miro.medium.com/v2/resize:fill:64:64/1*26Oyys83TRIKEtdUM1uZRA.png)](https://medium.com/decodingml?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------)
Follow
## [Published in Decoding ML](https://medium.com/decodingml?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------)
[1.5K followers](https://medium.com/decodingml/followers?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------)
·[Last published Apr 21, 2025](https://medium.com/decodingml/a-quick-update-find-us-mostly-on-substack-now-4a74e506cc88?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------)
Battle-tested content on designing, coding, and deploying production-grade ML & MLOps systems. The hub for continuous learning on ML system design, ML engineering, MLOps, large language models (LLMs), and computer vision (CV).
Follow
[![Paul Iusztin](https://miro.medium.com/v2/resize:fill:48:48/1*r3Geug_sW6weKSvaqBJtAA.jpeg)](https://medium.com/@pauliusztin?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------)
[![Paul Iusztin](https://miro.medium.com/v2/resize:fill:64:64/1*r3Geug_sW6weKSvaqBJtAA.jpeg)](https://medium.com/@pauliusztin?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------)
Follow
## [Written by Paul Iusztin](https://medium.com/@pauliusztin?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------)
[5.7K followers](https://medium.com/@pauliusztin/followers?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------)
·[242 following](https://medium.com/@pauliusztin/following?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------)
Senior AI/ML Engineer • Founder @ Decoding ML ~ Articles, code, and courses about building production-grade AI systems.
Follow
## No responses yet
[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--9cc01d50a2a0---------------------------------------)
![](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)
Write a response
[What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&source=---post_responses--9cc01d50a2a0---------------------respond_sidebar------------------)
Cancel
Respond
## More from Paul Iusztin and Decoding ML
![An End-to-End Framework for Production-Ready LLM Systems by Building Your LLM Twin](https://miro.medium.com/v2/resize:fit:679/1*3HhjepgNW8LXIszD7OBSXw.png)
[![Decoding ML](https://miro.medium.com/v2/resize:fill:20:20/1*26Oyys83TRIKEtdUM1uZRA.png)](https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----0---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
In
[Decoding ML](https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----0---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
by
[Paul Iusztin](https://medium.com/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0----0---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
## [An End-to-End Framework for Production-Ready LLM Systems by Building Your LLM TwinFrom data gathering to productionizing LLMs using LLMOps good practices.](https://medium.com/decodingml/an-end-to-end-framework-for-production-ready-llm-systems-by-building-your-llm-twin-2cc6bb01141f?source=post_page---author_recirc--9cc01d50a2a0----0---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
Mar 16, 2024
[A clap icon2.2KA response icon14](https://medium.com/decodingml/an-end-to-end-framework-for-production-ready-llm-systems-by-building-your-llm-twin-2cc6bb01141f?source=post_page---author_recirc--9cc01d50a2a0----0---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2cc6bb01141f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fan-end-to-end-framework-for-production-ready-llm-systems-by-building-your-llm-twin-2cc6bb01141f&source=---author_recirc--9cc01d50a2a0----0-----------------bookmark_preview----d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
![Your Content is Gold: I Turned 3 Years of Blog Posts into an LLM Training](https://miro.medium.com/v2/resize:fit:679/0*N6e1oZxeU9MGCc8q.png)
[![Decoding ML](https://miro.medium.com/v2/resize:fill:20:20/1*26Oyys83TRIKEtdUM1uZRA.png)](https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----1---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
In
[Decoding ML](https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----1---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
by
[Paul Iusztin](https://medium.com/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0----1---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
## [Your Content is Gold: I Turned 3 Years of Blog Posts into an LLM TrainingA practical guide to building custom instruction datasets for fine-tuning LLMs](https://medium.com/decodingml/your-content-is-gold-i-turned-3-years-of-blog-posts-into-an-llm-training-d19c265bdd6e?source=post_page---author_recirc--9cc01d50a2a0----1---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
Nov 18, 2024
[A clap icon128](https://medium.com/decodingml/your-content-is-gold-i-turned-3-years-of-blog-posts-into-an-llm-training-d19c265bdd6e?source=post_page---author_recirc--9cc01d50a2a0----1---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd19c265bdd6e&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fyour-content-is-gold-i-turned-3-years-of-blog-posts-into-an-llm-training-d19c265bdd6e&source=---author_recirc--9cc01d50a2a0----1-----------------bookmark_preview----d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
![The 4 Advanced RAG Algorithms You Must Know to Implement](https://miro.medium.com/v2/resize:fit:679/0*N6e1oZxeU9MGCc8q.png)
[![Decoding ML](https://miro.medium.com/v2/resize:fill:20:20/1*26Oyys83TRIKEtdUM1uZRA.png)](https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----2---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
In
[Decoding ML](https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----2---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
by
[Paul Iusztin](https://medium.com/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0----2---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
## [The 4 Advanced RAG Algorithms You Must Know to ImplementImplement from scratch 4 advanced RAG methods to optimize your retrieval and post-retrieval algorithm](https://medium.com/decodingml/the-4-advanced-rag-algorithms-you-must-know-to-implement-5d0c7f1199d2?source=post_page---author_recirc--9cc01d50a2a0----2---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
May 4, 2024
[A clap icon1.8KA response icon15](https://medium.com/decodingml/the-4-advanced-rag-algorithms-you-must-know-to-implement-5d0c7f1199d2?source=post_page---author_recirc--9cc01d50a2a0----2---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d0c7f1199d2&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fthe-4-advanced-rag-algorithms-you-must-know-to-implement-5d0c7f1199d2&source=---author_recirc--9cc01d50a2a0----2-----------------bookmark_preview----d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
![Building a TikTok-like recommender](https://miro.medium.com/v2/resize:fit:679/0*4GdmHgtbvEeN-6-k.png)
[![Data Science Collective](https://miro.medium.com/v2/resize:fill:20:20/1*0nV0Q-FBHj94Kggq00pG2Q.jpeg)](https://medium.com/data-science-collective?source=post_page---author_recirc--9cc01d50a2a0----3---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
In
[Data Science Collective](https://medium.com/data-science-collective?source=post_page---author_recirc--9cc01d50a2a0----3---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
by
[Paul Iusztin](https://medium.com/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0----3---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
## [Building a TikTok-like recommenderScaling a personalized recommender to millions of items in real-time](https://medium.com/data-science-collective/1-building-a-tiktok-like-recommender-a64563262c1a?source=post_page---author_recirc--9cc01d50a2a0----3---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
Mar 9
[A clap icon301A response icon3](https://medium.com/data-science-collective/1-building-a-tiktok-like-recommender-a64563262c1a?source=post_page---author_recirc--9cc01d50a2a0----3---------------------d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa64563262c1a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-collective%2F1-building-a-tiktok-like-recommender-a64563262c1a&source=---author_recirc--9cc01d50a2a0----3-----------------bookmark_preview----d4924552_497e_4ea8_82d6_d7a1afb7c0cd--------------)
[See all from Paul Iusztin](https://medium.com/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0---------------------------------------)
[See all from Decoding ML](https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0---------------------------------------)
## Recommended from Medium
![Agentic AI Course with 14 AI Agent Projects](https://miro.medium.com/v2/resize:fit:679/1*Yk5FWh9Y81CX9nGU_yTieg.png)
[![Simranjeet Singh](https://miro.medium.com/v2/resize:fill:20:20/1*UEfr3ehRbACbOK7f-lqruQ.jpeg)](https://medium.com/@simranjeetsingh1497?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
[Simranjeet Singh](https://medium.com/@simranjeetsingh1497?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
## [Agentic AI Projects: Build 14 Hands‑On AI Agents + Key Design Patterns [FREE]Explore 14 real-world Agentic AI projects and 2 key tutorials. Learn to build autonomous agents using OpenAI, Gemini, Ollama, and more.](https://medium.com/@simranjeetsingh1497/agentic-ai-projects-build-14-hands-on-ai-agents-key-design-patterns-free-b2ae0729e035?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
4d ago
[A clap icon210A response icon4](https://medium.com/@simranjeetsingh1497/agentic-ai-projects-build-14-hands-on-ai-agents-key-design-patterns-free-b2ae0729e035?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2ae0729e035&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40simranjeetsingh1497%2Fagentic-ai-projects-build-14-hands-on-ai-agents-key-design-patterns-free-b2ae0729e035&source=---read_next_recirc--9cc01d50a2a0----0-----------------bookmark_preview----0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
![Tech Professionals in the UK — What You Need to Learn About Personal Finance for your FIRE planning?](https://miro.medium.com/v2/resize:fit:679/0*PzUdJ91-bP9zD_uk.gif)
[![The Algorithmic Minds](https://miro.medium.com/v2/resize:fill:20:20/1*UE5GuhTAna40YZEOTagZSw.png)](https://medium.com/the-algorithmic-minds?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
In
[The Algorithmic Minds](https://medium.com/the-algorithmic-minds?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
by
[Rahul Agarwal](https://medium.com/@mlwhiz?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
## [Tech Professionals in the UK — What You Need to Learn About Personal Finance for your FIRE planning?A Journey Through the Trenches for Fellow Tech Brothers and Sisters](https://medium.com/the-algorithmic-minds/tech-professionals-in-the-uk-what-you-need-to-learn-about-personal-finance-for-your-fire-planning-bc1eac59a9c9?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
Feb 22
[A clap icon17](https://medium.com/the-algorithmic-minds/tech-professionals-in-the-uk-what-you-need-to-learn-about-personal-finance-for-your-fire-planning-bc1eac59a9c9?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbc1eac59a9c9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fthe-algorithmic-minds%2Ftech-professionals-in-the-uk-what-you-need-to-learn-about-personal-finance-for-your-fire-planning-bc1eac59a9c9&source=---read_next_recirc--9cc01d50a2a0----1-----------------bookmark_preview----0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
![Build an AI Finance Agent Team with phidata](https://miro.medium.com/v2/resize:fit:679/1*4aXb1I6vrfe9McQ9XjzWAA.jpeg)
[![Towards Finance](https://miro.medium.com/v2/resize:fill:20:20/1*c_euhvHDcrNzBybdNNKaNQ.png)](https://medium.com/towards-finance?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
In
[Towards Finance](https://medium.com/towards-finance?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
by
[Tinz Twins](https://medium.com/@tinztwins?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
## [Build an AI Finance Agent Team with phidataLocal Multi-Agent System with Web Access Using Llama 3.1 (Step-by-Step Guide)](https://medium.com/towards-finance/build-an-ai-finance-agent-team-with-phidata-fd6d2d984dc5?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
Jan 11
[A clap icon99](https://medium.com/towards-finance/build-an-ai-finance-agent-team-with-phidata-fd6d2d984dc5?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffd6d2d984dc5&operation=register&redirect=https%3A%2F%2Fblog.towardsfinance.com%2Fbuild-an-ai-finance-agent-team-with-phidata-fd6d2d984dc5&source=---read_next_recirc--9cc01d50a2a0----0-----------------bookmark_preview----0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
![How I Built a Custom AI Document Assistant That Understands 1000s of PDFs and Talks Like a Human](https://miro.medium.com/v2/resize:fit:679/0*u1dCRt0cYIeU9vCh)
[![Stackademic](https://miro.medium.com/v2/resize:fill:20:20/1*U-kjsW7IZUobnoy1gAp1UQ.png)](https://medium.com/stackademic?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
In
[Stackademic](https://medium.com/stackademic?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
by
[Abdul Ahad](https://medium.com/@abdul.ahadmahmood555?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
## [How I Built a Custom AI Document Assistant That Understands 1000s of PDFs and Talks Like a HumanForget basic search. I designed a Retrieval-Augmented Generation (RAG) system that reads technical documents, extracts diagrams, interprets…](https://medium.com/stackademic/how-i-built-a-custom-ai-document-assistant-that-understands-1000s-of-pdfs-and-talks-like-a-human-ec3aa57f370f?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
Jul 3
[A clap icon126A response icon7](https://medium.com/stackademic/how-i-built-a-custom-ai-document-assistant-that-understands-1000s-of-pdfs-and-talks-like-a-human-ec3aa57f370f?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fec3aa57f370f&operation=register&redirect=https%3A%2F%2Fblog.stackademic.com%2Fhow-i-built-a-custom-ai-document-assistant-that-understands-1000s-of-pdfs-and-talks-like-a-human-ec3aa57f370f&source=---read_next_recirc--9cc01d50a2a0----1-----------------bookmark_preview----0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
![Building Agentic RAG Pipelines for Medical Data with CrewAI and Qdrant](https://miro.medium.com/v2/resize:fit:679/1*Nr8wzNBPmhp-uCBne9_MzQ.png)
[![AI Advances](https://miro.medium.com/v2/resize:fill:20:20/1*R8zEd59FDf0l8Re94ImV0Q.png)](https://medium.com/ai-advances?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
In
[AI Advances](https://medium.com/ai-advances?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
by
[M K Pavan Kumar](https://medium.com/@manthapavankumar11?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
## [Building Agentic RAG Pipelines for Medical Data with CrewAI and QdrantThis post will demonstrate the construction of a data intake pipeline and RAG agents utilizing Qdrant and Crewai. We consider an existing…](https://medium.com/ai-advances/building-agentic-rag-pipelines-for-medical-data-with-crewai-and-qdrant-3a00a48fb0d1?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
Jan 12
[A clap icon287A response icon1](https://medium.com/ai-advances/building-agentic-rag-pipelines-for-medical-data-with-crewai-and-qdrant-3a00a48fb0d1?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a00a48fb0d1&operation=register&redirect=https%3A%2F%2Fai.gopubby.com%2Fbuilding-agentic-rag-pipelines-for-medical-data-with-crewai-and-qdrant-3a00a48fb0d1&source=---read_next_recirc--9cc01d50a2a0----2-----------------bookmark_preview----0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
![LangGraph + DeepSeek-R1 + Function Call + Agentic RAG \(Insane Results\)](https://miro.medium.com/v2/resize:fit:679/1*BKXwuROR5irypuU3XIG4uw.png)
[![Towards AI](https://miro.medium.com/v2/resize:fill:20:20/1*JyIThO-cLjlChQLb6kSlVQ.png)](https://medium.com/towards-artificial-intelligence?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
In
[Towards AI](https://medium.com/towards-artificial-intelligence?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
by
[Gao Dalie (Ilyass)](https://medium.com/@GaoDalie_AI?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
## [LangGraph + DeepSeek-R1 + Function Call + Agentic RAG (Insane Results)In this video, I have a super quick tutorial showing you how to create a multi-agent chatbot using LangGraph, Deepseek-R1, function calling,](https://medium.com/towards-artificial-intelligence/langgraph-deepseek-r1-function-call-agentic-rag-insane-results-b3f878e23a86?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
Feb 23
[A clap icon1.1KA response icon9](https://medium.com/towards-artificial-intelligence/langgraph-deepseek-r1-function-call-agentic-rag-insane-results-b3f878e23a86?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb3f878e23a86&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Flanggraph-deepseek-r1-function-call-agentic-rag-insane-results-b3f878e23a86&source=---read_next_recirc--9cc01d50a2a0----3-----------------bookmark_preview----0165257e_76d1_40fd_9023_fe76e26e8a84--------------)
[See more recommendations](https://medium.com/?source=post_page---read_next_recirc--9cc01d50a2a0---------------------------------------)
[Help](https://help.medium.com/hc/en-us?source=post_page-----9cc01d50a2a0---------------------------------------)
[About](https://medium.com/about?autoplay=1&source=post_page-----9cc01d50a2a0---------------------------------------)
[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----9cc01d50a2a0---------------------------------------)
[Blog](https://blog.medium.com/?source=post_page-----9cc01d50a2a0---------------------------------------)
[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9cc01d50a2a0---------------------------------------)
[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----9cc01d50a2a0---------------------------------------)
[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9cc01d50a2a0---------------------------------------)
