<div><a href="/sitemap/sitemap.xml">Sitemap</a><div><div><div><div><p><span><button>Sign up</button></span></p><div><p><span><a href="/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------">Sign in</a></span></p></div></div></div><div><div><a href="/?source=post_page---top_nav_layout_nav-----------------------------------------"><svg height="160" width="719"><desc>Medium Logo</desc></svg></a></div><div><div><span><a href="/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------"><div><div>Write</div></div></a></span></div></div><div><div><a href="/search?source=post_page---top_nav_layout_nav-----------------------------------------"></a></div></div><div><div><p><span><button>Sign up</button></span></p><div><p><span><a href="/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------">Sign in</a></span></p></div></div></div><div><button><div><img alt="" class="m fd bx by bz cx" height="32" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png" width="32"/></div></button></div></div></div><div><div><div><div><div><div><div><div><div><a href="https://medium.com/decodingml?source=post_page---publication_nav-57b7a1f365ee-9cc01d50a2a0---------------------------------------"><h2><div>Decoding ML</div></h2></a></div><div><span><span>·</span></span><p><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fdecodingml&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&amp;collection=Decoding+ML&amp;collectionId=57b7a1f365ee&amp;source=post_page---publication_nav-57b7a1f365ee-9cc01d50a2a0---------------------publication_nav------------------">Follow publication</a></span></p></div></div></div></div></div></div><div><div><div><div><div><div><a href="https://medium.com/decodingml?source=post_page---post_publication_sidebar-57b7a1f365ee-9cc01d50a2a0---------------------------------------"><div><img alt="Decoding ML" class="cx hj m hl hk" height="38" loading="lazy" src="https://miro.medium.com/v2/resize:fill:38:38/1*26Oyys83TRIKEtdUM1uZRA.png" width="38"/></div></a><p><span>Battle-tested content on designing, coding, and deploying production-grade ML &amp; MLOps systems. The hub for continuous learning on ML system design, ML engineering, MLOps, large language models (LLMs), and computer vision (CV).</span></p><p><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fdecodingml&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&amp;collection=Decoding+ML&amp;collectionId=57b7a1f365ee&amp;source=post_page---post_publication_sidebar-57b7a1f365ee-9cc01d50a2a0---------------------post_publication_sidebar------------------">Follow publication</a></span></p></div></div></div></div></div></div><div><article><div><div><section><div><div><div><div><div><h1>A Real-time Retrieval System for RAG on Social Media Data</h1></div><div><h2>Use a streaming engine to populate a vector DB in real-time. Improve RAG accuracy using rerank &amp; UMAP.</h2><div><div><div><div><div><div><div><div><div><a href="/@pauliusztin?source=post_page---byline--9cc01d50a2a0---------------------------------------"><div><div><img alt="Paul Iusztin" class="m fd bx by bz cx" data-testid="authorPhoto" height="32" loading="lazy" src="https://miro.medium.com/v2/resize:fill:32:32/1*r3Geug_sW6weKSvaqBJtAA.jpeg" width="32"/></div></div></a></div></div></div></div><span><div><div><div><div><div><div><span><a href="/@pauliusztin?source=post_page---byline--9cc01d50a2a0---------------------------------------">Paul Iusztin</a></span></div></div></div></div><div><button><span><span>Follow</span></span></button></div></div></div></span></div><div><span><div><span>12 min read</span><div><span><span>·</span></span></div><span>Mar 30, 2024</span></div></span></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdecodingml%2F9cc01d50a2a0&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&amp;user=Paul+Iusztin&amp;userId=8323de62a1a1&amp;source=---header_actions--9cc01d50a2a0---------------------clap_footer------------------"></a></span></div><div><div><div><div><p><button>323</button></p></div></div></div></div></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9cc01d50a2a0&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&amp;source=---header_actions--9cc01d50a2a0---------------------bookmark_footer------------------"></a></span></div></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D9cc01d50a2a0&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&amp;source=---header_actions--9cc01d50a2a0---------------------post_audio_button------------------"><div><div><div><button><div><p>Listen</p></div></button></div></div></div></a></span></div></div></div></div></div><div><div><div><div><button><div><p>Share</p></div></button></div></div></div></div></div></div></div></div></div></div><figure><div><div><picture><source><source><img alt="" class="bh fw ow c" height="700" loading="eager" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*mm9nB9FZq-u5alVd_chwyg.png" width="700"/></source></source></picture></div></div><figcaption>Image by DALL-E</figcaption></figure><p>In this article, you will learn how to build a real-time retrieval system for social media data. In our example, we will use only my LinkedIn posts, but our implementation can easily be extended to other platforms supporting written content, such as X, Instagram, or Medium.</p><p><strong>In this article, you will learn how to:</strong></p><ul><li>build a streaming pipeline that ingests LinkedIn posts into a vector DB in real-time</li><li>clean, chunk, and embed LinkedIn posts</li><li>build a retrieval client to query LinkedIn posts</li><li>use a rerank pattern to improve retrieval accuracy</li><li>visualize content retrieved for a given query in a 2D plot using UMAP</li></ul><p>Our implementation focuses on just the retrieval part of an RAG system. But you can quickly hook the retrieved LinkedIn posts to an LLM for post analysis or personalized content generation.</p></div></div></div><div><div><div><h1>Table of Contents:</h1><ol><li>System Design</li><li>Data</li><li>Streaming ingestion pipeline</li><li>Retrieval client</li><li>Conclusion</li></ol></div></div></div><div><div><div><h1>1. System Design</h1><p>The retrieval system is based on 2 detached components:</p><ol><li>the streaming ingestion pipeline</li><li>the retrieval client</li></ol></div></div><div><div><div><figure><div><div><picture><source><source><img alt="" class="bh fw ow c" height="563" loading="eager" role="presentation" src="https://miro.medium.com/v2/resize:fit:1000/0*SfXvnsaSFcBZUMmi.png" width="1000"/></source></source></picture></div></div><figcaption>The architecture of the retrieval system [Image by the Author — in collaboration with VectorHub].</figcaption></figure></div></div></div><div><div><p>The <strong>streaming ingestion pipeline</strong> runs 24/7 to keep the vector DB synced up with current raw LinkedIn posts data source, while the <strong>retrieval client</strong> is used in RAG applications to query the vector DB. These 2 components <strong>communicate with each other only through the vector DB</strong>.</p><h2>1.1. The streaming ingestion pipeline</h2><p>The streaming ingestion pipeline implements the between a data source containing the raw LinkedIn posts and the vector DB used for retrieval.</p><p>In a real-world scenario, the streaming pipeline listens to a queue populated by all the changes made to the source database. But because we are focusing primarily on the retrieval system, we simulate the data within the queue with a couple of JSON files.</p><p>The streaming pipeline is built in Python using Bytewax, and cleans, chunks, and embeds the LinkedIn posts before loading them into a vector DB.</p><p><strong>Why do we need a stream engine?</strong></p><p>Because LinkedIn posts (or any other social media data) evolve frequently, your vector DB can quickly get out of sync. To handle this, you can build a batch pipeline that runs every minute. But to really minimize data lag, to <strong>make sure your vector DB stays current with new social media posts</strong>, you need to use a streaming pipeline that <strong>immediately</strong> takes every new item the moment it’s posted, preprocesses it, and loads it into the vector DB.</p><p><strong>Why Bytewax?</strong></p><p> is a streaming engine built in Rust that exposes a Python interface. We use Bytewax because it combines the impressive speed and reliability of Rust with the ease of use and ecosystem of Python.</p><h2>1.2. The retrieval client</h2><p>Our retrieval client is a standard Python module that preprocesses user queries and searches the vector DB for most similar results. Qdrant vector DB lets us decouple the retrieval client from the streaming ingestion pipeline.</p><p>Using a semantic-based retrieval system lets us query our LinkedIn post collection very flexibly. For example, we can retrieve similar posts using a variety of query types — e.g., posts, questions, sentences.</p><p>Also, to improve the retrieval system’s accuracy, we use a rerank pattern.</p><p>Lastly, to better understand and explain the retrieval process for particular queries, we visualize our results on a 2D plot using UMAP.</p></div></div></div><div><div><div><h1>2. Data</h1><p>We will ingest 215 LinkedIn posts from . Though we simulate the post ingestion step using JSON files, the posts themselves are authentic.</p><p>Before diving into the code, let’s take a look at an example LinkedIn post to familiarize ourselves with the challenges it will introduce ↓</p><pre><span><span>[</span>  <span>{</span>    <span>"text"</span><span>:</span> <span>"𝗪𝗵𝗮𝘁 do you need to 𝗳𝗶𝗻𝗲-𝘁𝘂𝗻𝗲 an open-source 𝗟𝗟𝗠 to create your own 𝗳𝗶𝗻𝗮𝗻𝗰𝗶𝗮𝗹 𝗮𝗱𝘃𝗶𝘀𝗼𝗿?\nThis is the 𝗟𝗟𝗠 𝗳𝗶𝗻𝗲-𝘁𝘂𝗻𝗶𝗻𝗴 𝗸𝗶𝘁 you must know ↓\n𝗗𝗮𝘁𝗮𝘀𝗲𝘁\nThe key component of any successful ML project is the data.\nYou need a 100 - 1000 sample Q&amp;A (questions &amp; answers) dataset with financial scenarios.\nThe best approach is to hire a bunch of experts to create it manually.\nBut, for a PoC, that might get expensive &amp; slow.\nThe good news is that a method called \"𝘍𝘪𝘯𝘦𝘵𝘶𝘯𝘪𝘯𝘨 𝘸𝘪𝘵𝘩 𝘥𝘪𝘴𝘵𝘪𝘭𝘭𝘢𝘵𝘪𝘰𝘯\" exists.\n ...Along with ease of deployment, you can easily add your training code to your CI/CD to add the final piece of the MLOps puzzle, called CT (continuous training).\n↳ Beam: 🔗\nhttps://lnkd.in/dedCaMDh\n.\n↳ To see all these components in action, check out my FREE 𝗛𝗮𝗻𝗱𝘀-𝗼𝗻 𝗟𝗟𝗠𝘀 𝗰𝗼𝘂𝗿𝘀𝗲 &amp; give it a ⭐: 🔗\nhttps://lnkd.in/dZgqtf8f\nhashtag\n#\nmachinelearning\nhashtag\n#\nmlops\nhashtag\n#\ndatascience"</span><span>,</span>    <span>"image"</span><span>:</span> <span>"https://media.licdn.com/dms/image/D4D10AQHWQzZcToQQ1Q/image-shrink_800/0/1698388219549?e=1705082400&amp;v=beta&amp;t=9mrDC_NooJgD7u7Qk0PmrTGGaZtuwDIFKh3bEqeBsm0"</span>  <span>}</span><span>]</span></span></pre><p>The following features of the above post are not compatible with embedding models. We’ll need to find some way of handling them in our preprocessing step:</p><ul><li>emojis</li><li>bold, italic text</li><li>other non-ASCII characters</li><li>URLs</li><li>content that exceeds the context window limit of the embedding model</li></ul><p>Emojis and bolded and italic text are represented by Unicode characters that are not available in the vocabulary of the embedding model. Thus, these items cannot be tokenized and passed to the model; we have to remove them or normalize them to something that can be parsed by the tokenizer. The same holds true for all other non-ASCII characters.</p><p>URLs take up space in the context window without providing much semantic value. Still, knowing that there’s a URL in the sentence may add context. For this reason, we replace all URLs with a [URL] token. This lets us ingest whatever value the URL’s presence conveys without it taking up valuable space.</p></div></div></div><div><div><div><h1>3. Streaming ingestion pipeline</h1><p>Let’s dive into the streaming pipeline, starting from the top and working our way to the bottom ↓</p><h2>3.1. The Bytewax flow</h2><p><strong>The Bytewax flow</strong> transparently conveys all the steps of the streaming pipeline.</p><p>The first step is ingesting every LinkedIn post from our JSON files. In the next steps, every map operation has a single responsibility:</p><ul><li>validate the ingested data using a <em>RawPost pydantic model</em></li><li>clean the posts</li><li>chunk the posts; because chunking will output a list of ChunkedPost objects, we use a flat_map operation to flatten them out</li><li>embed the posts</li><li>load the posts to a Qdrant vector DB</li></ul><pre><span><span>def</span> <span>build_flow</span>():  embedding_model = EmbeddingModelSingleton()  flow = Dataflow(<span>"flow"</span>)  stream = op.<span>input</span>(<span>"input"</span>, flow, JSONSource([<span>"data/paul.json"</span>]))  stream = op.<span>map</span>(<span>"raw_post"</span>, stream, RawPost.from_source)  stream = op.<span>map</span>(<span>"cleaned_post"</span>, stream, CleanedPost.from_raw_post)  stream = op.flat_map(    <span>"chunked_post"</span>,    stream,    <span>lambda</span> cleaned_post: ChunkedPost.from_cleaned_post(      cleaned_post, embedding_model=embedding_model    ),  )  stream = op.<span>map</span>(    <span>"embedded_chunked_post"</span>,    stream,    <span>lambda</span> chunked_post: EmbeddedChunkedPost.from_chunked_post(      chunked_post, embedding_model=embedding_model    ),  )  op.inspect(<span>"inspect"</span>, stream, <span>print</span>)  op.output(    <span>"output"</span>, stream, QdrantVectorOutput(vector_size=model.embedding_size)  )    <span>return</span> flow</span></pre><h2>3.2. The processing steps</h2><p>Every processing step is incorporated into a <em>pydantic model</em>. This way, we can easily validate the data at each step and reuse the code in the retrieval module.</p><p>We isolate every step of an ingestion pipeline into its own class:</p><ul><li>cleaning</li><li>chunking</li><li>embedding</li></ul><p>Doing so, we follow the separation of concerns good SWE practice. Thus, every class has its own responsibility.</p><p>Now the code is easy to read and understand. Also, it’s future-proof, as it’s extremely easy to change or extend either of the 3 steps: cleaning, chunking and embedding.</p><p>Here is the interface of the <em>pydantic models</em>:</p><pre><span><span>class</span> <span>RawPost</span>(<span>BaseModel</span>):  post_id: <span>str</span>  text: <span>str</span>  image: <span>Optional</span>[<span>str</span>]<span>  @classmethod</span>  <span>def</span> <span>from_source</span>(<span>cls, k_v: <span>Tuple</span>[<span>str</span>, <span>dict</span>]</span>) -&gt; <span>"RawPost"</span>:    ... <span># Mapping a dictionary to a RawPost validated pydantic model.</span>    <span>return</span> cls(...)<span>class</span> <span>CleanedPost</span>(<span>BaseModel</span>):  post_id: <span>str</span>  raw_text: <span>str</span>  text: <span>str</span>  image: <span>Optional</span>[<span>str</span>]<span>  @classmethod</span>  <span>def</span> <span>from_raw_post</span>(<span>cls, raw_post: RawPost</span>) -&gt; <span>"CleanedPost"</span>:    ... <span># Cleaning the raw post</span>    <span>return</span> cls(...)<span>class</span> <span>ChunkedPost</span>(<span>BaseModel</span>):  post_id: <span>str</span>  chunk_id: <span>str</span>  full_raw_text: <span>str</span>  text: <span>str</span>  image: <span>Optional</span>[<span>str</span>]<span>  @classmethod</span>  <span>def</span> <span>from_cleaned_post</span>(<span>    cls, cleaned_post: CleanedPost, embedding_model: EmbeddingModelSingleton  </span>) -&gt; <span>list</span>[<span>"ChunkedPost"</span>]:    chunks = ... <span># Compute chunks</span>    <span>return</span> [cls(...) <span>for</span> chunk <span>in</span> chunks]<span>class</span> <span>EmbeddedChunkedPost</span>(<span>BaseModel</span>):  post_id: <span>str</span>  chunk_id: <span>str</span>  full_raw_text: <span>str</span>  text: <span>str</span>  text_embedding: <span>list</span>  image: <span>Optional</span>[<span>str</span>] = <span>None</span>  score: <span>Optional</span>[<span>float</span>] = <span>None</span>  rerank_score: <span>Optional</span>[<span>float</span>] = <span>None</span><span>  @classmethod</span>  <span>def</span> <span>from_chunked_post</span>(<span>    cls, chunked_post: ChunkedPost, embedding_model: EmbeddingModelSingleton  </span>) -&gt; <span>"EmbeddedChunkedPost"</span>:    ... <span># Compute embedding.</span>    <span>return</span> cls(...)</span></pre><p>Now, the data at each step is validated and has a clear structure.</p><p><strong>Note:</strong> Providing different types when instantiating a <em>pydantic</em> model will throw a validation error. For example, if the <em>post_id</em> is defined as a <em>string</em>, and we try to instantiate an <em>EmbeddedChunkedPost</em> with a <em>None</em> or <em>int</em> <em>post_id</em>, it will throw an error.</p><blockquote><p>Check out the full implementation on our 🔗 .</p></blockquote><h2>3.3. Load to Qdrant</h2><p>To load the LinkedIn posts to Qdrant, you have to override Bytewax’s <em>StatelessSinkPartition</em> class (which acts as an <strong>output</strong> in a Bytewax flow):</p><pre><span><span>class</span> <span>QdrantVectorSink</span>(<span>StatelessSinkPartition</span>):  <span>def</span> <span>__init__</span>(<span>    self,    client: QdrantClient,    collection_name: <span>str</span>  </span>):    self._client = client    self._collection_name = collection_name  <span>def</span> <span>write_batch</span>(<span>self, chunks: <span>list</span>[EmbeddedChunkedPost]</span>):    ... <span># Map chunks to ids, embeddings, and metadata.</span>    self._client.upsert(      collection_name=self._collection_name,      points=Batch(        ids=ids,        vectors=embeddings,        payloads=metadata,      ),    )</span></pre><p>Within this class, you must overwrite the <em>write_batch()</em> method, where we will serialize every <em>EmbeddedChunkedPost</em> to a format expected by Qdrant and load it to the vector DB.</p></div></div></div><div><div><div><h1>4. Retrieval client</h1><p>Here, we focus on preprocessing a user’s query, searching the vector DB, and postprocessing the retrieved posts for maximum results.</p><p>To design the retrieval step, we implement a <em>QdrantVectorDBRetriever</em> class to expose all the necessary features for our retrieval client.</p><pre><span><span>class</span> <span>QdrantVectorDBRetriever</span>:  <span>def</span> <span>__init__</span>(<span>    self,    embedding_model: EmbeddingModelSingleton,    vector_db_client: QdrantClient,    cross_encoder_model: CrossEncoderModelSingleton    vector_db_collection: <span>str</span>  </span>):    self._embedding_model = embedding_model    self._vector_db_client = vector_db_client    self._cross_encoder_model = cross_encoder_model    self._vector_db_collection = vector_db_collection  <span>def</span> <span>search</span>(<span>    self, query: <span>str</span>, limit: <span>int</span> = <span>3</span>, return_all: <span>bool</span> = <span>False</span>  </span>) -&gt; <span>Union</span>[<span>list</span>[EmbeddedChunkedPost], <span>dict</span>[<span>str</span>, <span>list</span>]]:    ... <span># Search the Qdrant vector DB based on the given query.</span>  <span>def</span> <span>embed_query</span>(<span>self, query: <span>str</span></span>) -&gt; <span>list</span>[<span>list</span>[<span>float</span>]]:    ... <span># Embed the given query.</span>  <span>def</span> <span>rerank</span>(<span>self, query: <span>str</span>, posts: <span>list</span>[EmbeddedChunkedPost]</span>) -&gt; <span>list</span>[EmbeddedChunkedPost]:    ... <span># Rerank the posts relative to the given query.</span>  <span>def</span> <span>render_as_html</span>(<span>self, post: EmbeddedChunkedPost</span>) -&gt; <span>None</span>:    ... <span># Map the embedded post to HTML to display it.</span></span></pre><h2>4.1. Embed query</h2><p>We must embed the query in precisely the same way we ingested our posts into the vector DB. Because the streaming pipeline is written in Python (thanks to Bytewax), and every preprocessing operation is modular, we can quickly replicate all the steps necessary to embed the query.</p><pre><span><span>class</span> <span>QdrantVectorDBRetriever</span>:  ...  <span>def</span> <span>embed_query</span>(<span>self, query: <span>str</span></span>) -&gt; <span>list</span>[<span>list</span>[<span>float</span>]]:    cleaned_query = CleanedPost.clean(query)    chunks = ChunkedPost.chunk(cleaned_query, self._embedding_model)    embdedded_queries = [      self._embedding_model(chunk, to_list=<span>True</span>) <span>for</span> chunk <span>in</span> chunks    ]    <span>return</span> embdedded_queries</span></pre><blockquote><p>Check out the full implementation on our <em>🔗</em> .</p></blockquote><h2>4.2. Plain retrieval</h2><p>Let’s try to retrieve a set of posts without using the rerank algorithm.</p><pre><span>vector_db_retriever = QdrantVectorDBRetriever(  embedding_model=EmbeddingModelSingleton(),  vector_db_client=build_qdrant_client())query = <span>"Posts about Qdrant"</span>retrieved_results = vector_db_retriever.search(query=query)<span>for</span> post <span>in</span> retrieved_results[<span>"posts"</span>]:  vector_db_retriever.render_as_html(post)</span></pre><p><em>Here are the </em><strong><em>top 2 retrieved results</em></strong><em> sorted using the cosine similarity score ↓</em></p><p><strong>Result 1:</strong></p></div></div><div><div><div><figure><div><div><picture><source><source><img alt="" class="bh fw ow c" height="615" loading="eager" role="presentation" src="https://miro.medium.com/v2/resize:fit:1000/0*R5L_euGz8OIjuYCU.png" width="1000"/></source></source></picture></div></div><figcaption>Result 1 for the “Posts about Qdrant” query (without using reranking) [Image by the Author — in collaboration with VectorHub]</figcaption></figure></div></div></div><div><div><p><strong>Result 2:</strong></p></div></div><div><div><div><figure><div><div><picture><source><source><img alt="" class="bh fw ow c" height="619" loading="eager" role="presentation" src="https://miro.medium.com/v2/resize:fit:1000/0*xhXHUhfATKq8khO9.png" width="1000"/></source></source></picture></div></div><figcaption>Result 2 for the “Posts about Qdrant” query (without using reranking) [Image by the Author — in collaboration with VectorHub]</figcaption></figure></div></div></div><div><div><p>You can see from the results above, that starting from the second post the results are irrelevant. Even though it has a cosine similarly score of ~0.69 the posts doesn’t contain any information about Qdrant or vector DBs.</p><p><strong>Note:</strong> We looked over the top 5 retrieved results. Nothing after the first post was relevant. We haven’t added them here as the article is already too long.</p><h2>4.3. Visualize retrieval</h2><p>To visualize our retrieval, we implement a dedicated class that uses the UMAP dimensionality reduction algorithm. We have picked UMAP as it preserves the geometric properties between points (e.g., the distance) in higher dimensions when they are projected onto lower dimensions better than its peers (e.g., PCA, t-SNE).</p><p>The <em>RetrievalVisualizer</em> computes the projected embeddings for the entire vector space once. Afterwards, it uses the render() method to project only the given query and retrieved posts, and plot them to a 2D graph.</p><pre><span><span>class</span> <span>RetrievalVisualizer</span>:  <span>def</span> <span>__init__</span>(<span>self, posts: <span>list</span>[EmbeddedChunkedPost]</span>):    self._posts = posts    self._umap_transform = self._fit_model(self._posts)    self._projected_post_embeddings = self.project_posts(self._posts)  <span>def</span> <span>_fit_model</span>(<span>self, posts: <span>list</span>[EmbeddedChunkedPost]</span>) -&gt; umap.UMAP:    umap_transform = ... <span># Fit a UMAP model on the given posts.</span>    <span>return</span> umap_transform  <span>def</span> <span>project_posts</span>(<span>self, posts: <span>list</span>[EmbeddedChunkedPost]</span>) -&gt; np.ndarray:    embeddings = np.array([post.text_embedding <span>for</span> post <span>in</span> posts])    <span>return</span> self._project(embeddings=embeddings)  <span>def</span> <span>_project</span>(<span>self, embeddings: np.ndarray</span>) -&gt; np.ndarray:    ... <span># Project the embeddings to 2D using UMAP.</span>    <span>return</span> umap_embeddings  <span>def</span> <span>render</span>(<span>    self,    embedded_queries: <span>list</span>[<span>list</span>[<span>float</span>]],    retrieved_posts: <span>list</span>[EmbeddedChunkedPost],  </span>) -&gt; <span>None</span>:   ... <span># Render the given queries &amp; retrieved posts using matplotlib.</span></span></pre><p><em>Let’s take a look at the result to see how the “Posts about Qdrant” query looks ↓</em></p><figure><div><div><picture><source><source><img alt="" class="bh fw ow c" height="445" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/0*nHkwv8htoaVo5EQf.png" width="700"/></source></source></picture></div></div><figcaption>Visualization of the “Posts about Qdrant” query using UMAP (without reranking) [Image by the Author — in collaboration with VectorHub].</figcaption></figure><p>Our results are not great. You can see how far the retrieved posts are from our query in the vector space.</p><p>Can we improve the quality of our retrieval system using the <strong>rerank</strong> algorithm?</p><h2>4.4. Rerank</h2><p>We use the <em>reranking</em> algorithm to refine our retrieval for the initial query. Our initial retrieval step — because it used cosine similarity (or similar distance metrics) to compute the distance between a query and post embeddings — may have missed more complex (but essential) relationships between the query and the documents in the vector space. Reranking leverages the power of transformer models that are capable of understanding more nuanced semantic relationships.</p><p>We use a <strong>cross-encoder</strong> model to implement the reranking step, so we can score the query relative to all retrieved posts individually. These scores take into consideration more complex relationships than cosine similarity can. Under the hood is a BERT classifier that outputs a number between 0 and 1 according to how similar the 2 given sentences are. The BERT classifier outputs 0 if they are entirely different and 1 if they are a perfect match.</p><figure><div><div><picture><source><source><img alt="" class="bh fw ow c" height="512" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/0*86jt5YNILwTtyhZX.png" width="700"/></source></source></picture></div></div><figcaption>Bi-Encoder vs. Cross-Encoder [Image by the Author — in collaboration with VectorHub]</figcaption></figure><p>Bi-Encoder vs. Cross-Encoder [Image by the Author — in collaboration with VectorHub]</p><p>But, you might ask, “<em>Why not use the </em><strong><em>cross-encoder</em></strong><em> model from the start if it is that much better?”</em></p><p>The answer, in a word, is speed. Using a cross-encoder model to search your whole collection is much slower than using cosine similarity. To optimize your retrieval, therefore, your reranking process should involve 2 steps:</p><ol><li>an initial rough retrieval step using cosine similarity, which retrieves the top N items as potential candidates</li><li>filtering the rough search using the rerank strategy, which retrieves the top K items as your final results</li></ol><p>The implementation is relatively straightforward. For each retrieved post, we create a pair consisting of the (cleaned) query and the text of the post. We do this for all retrieved posts, resulting in a list of pairs.</p><p>Next, we call a <em>cross-encoder/ms-marco-MiniLM-L-6-v2</em> model (from sentence-transformers) to give the retrieved posts their rerank score. We then sort the posts in descending order based on their rerank score.</p><blockquote><p>Check out the rerank algorithm implementation on our 🔗 .</p></blockquote><h2>4.5. Visualize retrieval with rerank</h2><p>Now that we’ve added the rerank pattern to our retrieval system, let’s see if it improves the results of our <em>“Posts about Qdrant”</em> query ↓</p><p><strong>Result 1</strong></p></div></div><div><div><div><figure><div><div><picture><source><source><img alt="" class="bh fw ow c" height="551" loading="eager" role="presentation" src="https://miro.medium.com/v2/resize:fit:1000/0*hKRNu3jQ2V2_JrrM.png" width="1000"/></source></source></picture></div></div><figcaption>Result 1 for the “Posts about Qdrant” query (using reranking) [Image by the Author — in collaboration with VectorHub]</figcaption></figure></div></div></div><div><div><p><strong>Result 2:</strong></p></div></div><div><div><div><figure><div><div><picture><source><source><img alt="" class="bh fw ow c" height="641" loading="eager" role="presentation" src="https://miro.medium.com/v2/resize:fit:1000/0*SvKByecO1s8UIZ65.png" width="1000"/></source></source></picture></div></div><figcaption>Result 2 for the “Posts about Qdrant” query (using reranking) [Image by the Author — in collaboration with VectorHub]</figcaption></figure></div></div></div><div><div><p>The improvement is remarkable! All our results are about Qdrant and vector DBs.</p><p><strong>Note:</strong> We looked over the top 5 retrieved results. The top 4 out of 5 posts are relevant to our query, which is incredible.</p><p>Now, let’s look at the UMAP visualization:</p><figure><div><div><picture><source><source><img alt="" class="bh fw ow c" height="442" loading="eager" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/0*46m4qp3GlPAuC82g.png" width="700"/></source></source></picture></div></div><figcaption>Visualization of the “Posts about Qdrant” query using UMAP (with reranking) [Image by the Author — in collaboration with VectorHub].</figcaption></figure><p>While the returned posts aren’t very close to the query, they are <strong>a lot closer to the query compared to when we weren’t reranking the retrieved posts</strong>.</p></div></div></div><div><div><div><h1>5. Conclusion</h1><p>In this article, we learned how to adapt a RAG retrieval pattern to improve LinkedIn post retrieval. To keep our database up to date with rapidly changing social media data, we implemented a real-time streaming pipeline that uses CDC to sync the raw LinkedIn posts data source with a vector DB. You also saw how to use Bytewax to write — using only Python — a streaming pipeline that cleans, chunks, and embeds LinkedIn posts.</p><p>Finally, you learned how to implement a standard retrieval client for RAG and saw how to improve it using the rerank pattern. As retrieval is complex to evaluate, you saw how to visualize the retrieval for a given query by rendering all the posts, the query, and the retrieved posts in a 2D space using UMAP.</p><blockquote><p><em>This </em><strong><em>article</em></strong><em> is a </em><strong><em>summary</em></strong> <em>of </em><strong><em>my contribution</em></strong><em> from </em><strong><em>VectorHub</em></strong><em>. </em><em> to </em><strong><em>dig</em></strong><strong><em>into</em></strong><em> the </em><strong><em>details, </em></strong><em>the</em><strong><em> code</em></strong><em> and </em><strong><em>more experiments</em></strong><em>.</em></p></blockquote></div></div></div><div><div><div><p>→ Join 5k+ engineers in the 𝗗𝗲𝗰𝗼𝗱𝗶𝗻𝗴 𝗠𝗟 𝗡𝗲𝘄𝘀𝗹𝗲𝘁𝘁𝗲𝗿 for battle-tested content on production-grade ML. 𝗘𝘃𝗲𝗿𝘆 𝘄𝗲𝗲𝗸:</p></div></div></div></div></section></div></div></article></div><div><div><div><div><div><img class="fu wn id xn" loading="lazy" role="presentation" src="https://miro.medium.com/v2/da:true/resize:fit:0/5c50caa54067fd622d2f0fac18392213bf92f6e2fae89b691e62bceb40885e74"/><div><div><svg height="160" width="719"><desc>Medium Logo</desc></svg></div><div><svg height="160" width="719"><desc>Medium Logo</desc></svg></div><h2>Sign up to discover human stories that deepen your understanding of the world.</h2></div><div><div><div><div><div><h2>Free</h2></div></div><div><p>Distraction-free reading. No ads.</p></div><div><p>Organize your knowledge with lists and highlights.</p></div><div><p>Tell your story. Find your audience.</p></div></div><div><span><button>Sign up for free</button></span></div></div><div><div><div><div><h2>Membership</h2></div></div><div><p>Read member-only stories</p></div><div><p>Support writers you read most</p></div><div><p>Earn money for your writing</p></div><div><p>Listen to audio narrations</p></div><div><p>Read offline with the Medium app</p></div></div><div><span><button>Try for $5/month</button></span></div></div></div></div></div></div></div></div><div><div><div><div><a href="/tag/ml-system-design?source=post_page-----9cc01d50a2a0---------------------------------------"><div>Ml System Design</div></a></div><div><a href="/tag/artificial-intelligence?source=post_page-----9cc01d50a2a0---------------------------------------"><div>Artificial Intelligence</div></a></div><div><a href="/tag/machine-learning?source=post_page-----9cc01d50a2a0---------------------------------------"><div>Machine Learning</div></a></div><div><a href="/tag/streaming-pipeline?source=post_page-----9cc01d50a2a0---------------------------------------"><div>Streaming Pipeline</div></a></div><div><a href="/tag/data-science?source=post_page-----9cc01d50a2a0---------------------------------------"><div>Data Science</div></a></div></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/decodingml?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------"><div><img alt="Decoding ML" class="cx hj m uw uv" height="48" loading="lazy" src="https://miro.medium.com/v2/resize:fill:48:48/1*26Oyys83TRIKEtdUM1uZRA.png" width="48"/></div></a></div><div><a href="https://medium.com/decodingml?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------"><div><img alt="Decoding ML" class="cx hj m uy ux" height="64" loading="lazy" src="https://miro.medium.com/v2/resize:fill:64:64/1*26Oyys83TRIKEtdUM1uZRA.png" width="64"/></div></a></div><div><div><button><span><span>Follow</span></span></button></div></div></div><div><div><a href="https://medium.com/decodingml?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------"><h2><span>Published in Decoding ML</span></h2></a><div><div><span><a href="/decodingml/followers?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------">1.5K followers</a></span></div><div><span><span>·</span></span><a href="/decodingml/a-quick-update-find-us-mostly-on-substack-now-4a74e506cc88?source=post_page---post_publication_info--9cc01d50a2a0---------------------------------------">Last published <span>Apr 21, 2025</span></a></div></div><div><p><span>Battle-tested content on designing, coding, and deploying production-grade ML &amp; MLOps systems. The hub for continuous learning on ML system design, ML engineering, MLOps, large language models (LLMs), and computer vision (CV).</span></p></div></div></div><div><div><button><span><span>Follow</span></span></button></div></div></div></div><div><div><div><a href="/@pauliusztin?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------"><div><img alt="Paul Iusztin" class="m fd bx uv uw cx" height="48" loading="lazy" src="https://miro.medium.com/v2/resize:fill:48:48/1*r3Geug_sW6weKSvaqBJtAA.jpeg" width="48"/></div></a></div><div><a href="/@pauliusztin?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------"><div><img alt="Paul Iusztin" class="m fd bx ux uy cx" height="64" loading="lazy" src="https://miro.medium.com/v2/resize:fill:64:64/1*r3Geug_sW6weKSvaqBJtAA.jpeg" width="64"/></div></a></div><div><div><div><button><span><span>Follow</span></span></button></div></div></div></div><div><div><a href="/@pauliusztin?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------"><h2><span>Written by Paul Iusztin</span></h2></a><div><div><span><a href="/@pauliusztin/followers?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------">5.7K followers</a></span></div><div><span><span>·</span></span><a href="/@pauliusztin/following?source=post_page---post_author_info--9cc01d50a2a0---------------------------------------">242 following</a></div></div><div><p><span>Senior AI/ML Engineer • Founder @ Decoding ML ~ Articles, code, and courses about building production-grade AI systems.</span></p></div></div></div><div><div><div><button><span><span>Follow</span></span></button></div></div></div></div></div></div></div><div><div><div><div><h2>No responses yet</h2><div><div><div><div><a href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--9cc01d50a2a0---------------------------------------"></a></div></div></div></div></div><div><div><div><div><div><div><div><img alt="" class="m fd bx by bz cx" height="32" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png" width="32"/></div><div><p>Write a response</p></div></div><div><div><span><a href="/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fa-real-time-retrieval-system-for-rag-on-social-media-data-9cc01d50a2a0&amp;source=---post_responses--9cc01d50a2a0---------------------respond_sidebar------------------"><div><p>What are your thoughts?</p></div></a></span><div><div><div><button>Cancel</button></div><button>Respond</button></div></div></div></div></div></div></div></div></div></div></div></div><div><div><div><div><h2>More from Paul Iusztin and Decoding ML</h2></div><div><div><div><article><div><div><div><div><div><div><div><img alt="An End-to-End Framework for Production-Ready LLM Systems by Building Your LLM Twin" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/1*3HhjepgNW8LXIszD7OBSXw.png"/></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----0---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div><img alt="Decoding ML" class="cx hj m afe afd" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*26Oyys83TRIKEtdUM1uZRA.png" width="20"/></div></a></div></div></div></div><div><p>In</p></div><div><div><div><div><a href="https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----0---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><p>Decoding ML</p></a></div></div></div></div><div><p>by</p></div><div><div><div><a href="/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0----0---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><p>Paul Iusztin</p></a></div></div></div></div><div><div><a href="/decodingml/an-end-to-end-framework-for-production-ready-llm-systems-by-building-your-llm-twin-2cc6bb01141f?source=post_page---author_recirc--9cc01d50a2a0----0---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div title="An End-to-End Framework for Production-Ready LLM Systems by Building Your LLM Twin"><h2>An End-to-End Framework for Production-Ready LLM Systems by Building Your LLM Twin</h2></div><div><h3>From data gathering to productionizing LLMs using LLMOps good practices.</h3></div></a></div></div><span><div><div><span>Mar 16, 2024</span><div><div><a href="/decodingml/an-end-to-end-framework-for-production-ready-llm-systems-by-building-your-llm-twin-2cc6bb01141f?source=post_page---author_recirc--9cc01d50a2a0----0---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>2.2K</span></div></div></div></div><div><div><div><div><svg height="16" width="16"><desc>A response icon</desc></svg><span>14</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2cc6bb01141f&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fan-end-to-end-framework-for-production-ready-llm-systems-by-building-your-llm-twin-2cc6bb01141f&amp;source=---author_recirc--9cc01d50a2a0----0-----------------bookmark_preview----1640223a_6ca0_482e_b528_a5607c7794ea--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div><div><div><article><div><div><div><div><div><div><div><img alt="Your Content is Gold: I Turned 3 Years of Blog Posts into an LLM Training" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/0*N6e1oZxeU9MGCc8q.png"/></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----1---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div><img alt="Decoding ML" class="cx hj m afe afd" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*26Oyys83TRIKEtdUM1uZRA.png" width="20"/></div></a></div></div></div></div><div><p>In</p></div><div><div><div><div><a href="https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----1---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><p>Decoding ML</p></a></div></div></div></div><div><p>by</p></div><div><div><div><a href="/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0----1---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><p>Paul Iusztin</p></a></div></div></div></div><div><div><a href="/decodingml/your-content-is-gold-i-turned-3-years-of-blog-posts-into-an-llm-training-d19c265bdd6e?source=post_page---author_recirc--9cc01d50a2a0----1---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div title="Your Content is Gold: I Turned 3 Years of Blog Posts into an LLM Training"><h2>Your Content is Gold: I Turned 3 Years of Blog Posts into an LLM Training</h2></div><div><h3>A practical guide to building custom instruction datasets for fine-tuning LLMs</h3></div></a></div></div><span><div><div><span>Nov 18, 2024</span><div><div><a href="/decodingml/your-content-is-gold-i-turned-3-years-of-blog-posts-into-an-llm-training-d19c265bdd6e?source=post_page---author_recirc--9cc01d50a2a0----1---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>128</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd19c265bdd6e&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fyour-content-is-gold-i-turned-3-years-of-blog-posts-into-an-llm-training-d19c265bdd6e&amp;source=---author_recirc--9cc01d50a2a0----1-----------------bookmark_preview----1640223a_6ca0_482e_b528_a5607c7794ea--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div><div><div><article><div><div><div><div><div><div><div><img alt="The 4 Advanced RAG Algorithms You Must Know to Implement" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/0*N6e1oZxeU9MGCc8q.png"/></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----2---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div><img alt="Decoding ML" class="cx hj m afe afd" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*26Oyys83TRIKEtdUM1uZRA.png" width="20"/></div></a></div></div></div></div><div><p>In</p></div><div><div><div><div><a href="https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0----2---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><p>Decoding ML</p></a></div></div></div></div><div><p>by</p></div><div><div><div><a href="/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0----2---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><p>Paul Iusztin</p></a></div></div></div></div><div><div><a href="/decodingml/the-4-advanced-rag-algorithms-you-must-know-to-implement-5d0c7f1199d2?source=post_page---author_recirc--9cc01d50a2a0----2---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div title=""><h2>The 4 Advanced RAG Algorithms You Must Know to Implement</h2></div><div><h3>Implement from scratch 4 advanced RAG methods to optimize your retrieval and post-retrieval algorithm</h3></div></a></div></div><span><div><div><span>May 4, 2024</span><div><div><a href="/decodingml/the-4-advanced-rag-algorithms-you-must-know-to-implement-5d0c7f1199d2?source=post_page---author_recirc--9cc01d50a2a0----2---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>1.8K</span></div></div></div></div><div><div><div><div><svg height="16" width="16"><desc>A response icon</desc></svg><span>15</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d0c7f1199d2&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdecodingml%2Fthe-4-advanced-rag-algorithms-you-must-know-to-implement-5d0c7f1199d2&amp;source=---author_recirc--9cc01d50a2a0----2-----------------bookmark_preview----1640223a_6ca0_482e_b528_a5607c7794ea--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div><div><div><article><div><div><div><div><div><div><div><img alt="Building a TikTok-like recommender" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/0*4GdmHgtbvEeN-6-k.png"/></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/data-science-collective?source=post_page---author_recirc--9cc01d50a2a0----3---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div><img alt="Data Science Collective" class="cx hj m afe afd" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*0nV0Q-FBHj94Kggq00pG2Q.jpeg" width="20"/></div></a></div></div></div></div><div><p>In</p></div><div><div><div><div><a href="https://medium.com/data-science-collective?source=post_page---author_recirc--9cc01d50a2a0----3---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><p>Data Science Collective</p></a></div></div></div></div><div><p>by</p></div><div><div><div><a href="/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0----3---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><p>Paul Iusztin</p></a></div></div></div></div><div><div><a href="/data-science-collective/1-building-a-tiktok-like-recommender-a64563262c1a?source=post_page---author_recirc--9cc01d50a2a0----3---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div title=""><h2>Building a TikTok-like recommender</h2></div><div><h3>Scaling a personalized recommender to millions of items in real-time</h3></div></a></div></div><span><div><div><span>Mar 9</span><div><div><a href="/data-science-collective/1-building-a-tiktok-like-recommender-a64563262c1a?source=post_page---author_recirc--9cc01d50a2a0----3---------------------1640223a_6ca0_482e_b528_a5607c7794ea--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>301</span></div></div></div></div><div><div><div><div><svg height="16" width="16"><desc>A response icon</desc></svg><span>3</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa64563262c1a&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdata-science-collective%2F1-building-a-tiktok-like-recommender-a64563262c1a&amp;source=---author_recirc--9cc01d50a2a0----3-----------------bookmark_preview----1640223a_6ca0_482e_b528_a5607c7794ea--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div><a href="/@pauliusztin?source=post_page---author_recirc--9cc01d50a2a0---------------------------------------"><div>See all from Paul Iusztin</div></a><div><a href="https://medium.com/decodingml?source=post_page---author_recirc--9cc01d50a2a0---------------------------------------"><div>See all from Decoding ML</div></a></div></div></div></div><div><div><div><h2>Recommended from Medium</h2><div><div><div><div><article><div><div><div><div><div><div><div><img alt="Agentic AI Course with 14 AI Agent Projects" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/1*Yk5FWh9Y81CX9nGU_yTieg.png"/></div></div></div><div><div><div><div><div><div><div><div><a href="/@simranjeetsingh1497?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><img alt="Simranjeet Singh" class="m fd bx afd afe cx" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*UEfr3ehRbACbOK7f-lqruQ.jpeg" width="20"/></div></a></div></div></div></div></div><div><div><div><a href="/@simranjeetsingh1497?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>Simranjeet Singh</p></a></div></div></div></div><div><div><a href="/@simranjeetsingh1497/agentic-ai-projects-build-14-hands-on-ai-agents-key-design-patterns-free-b2ae0729e035?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div title="Agentic AI Projects: Build 14 Hands‑On AI Agents + Key Design Patterns [FREE]"><h2>Agentic AI Projects: Build 14 Hands‑On AI Agents + Key Design Patterns [FREE]</h2></div><div><h3>Explore 14 real-world Agentic AI projects and 2 key tutorials. Learn to build autonomous agents using OpenAI, Gemini, Ollama, and more.</h3></div></a></div></div><span><div><div>4d ago<div><div><a href="/@simranjeetsingh1497/agentic-ai-projects-build-14-hands-on-ai-agents-key-design-patterns-free-b2ae0729e035?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>210</span></div></div></div></div><div><div><div><div><svg height="16" width="16"><desc>A response icon</desc></svg><span>4</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2ae0729e035&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40simranjeetsingh1497%2Fagentic-ai-projects-build-14-hands-on-ai-agents-key-design-patterns-free-b2ae0729e035&amp;source=---read_next_recirc--9cc01d50a2a0----0-----------------bookmark_preview----a7defac2_abfd_40a8_8222_2699c04919ae--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div><div><div><article><div><div><div><div><div><div><div><img alt="Tech Professionals in the UK — What You Need to Learn About Personal Finance for your FIRE planning?" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/0*PzUdJ91-bP9zD_uk.gif"/></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/the-algorithmic-minds?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><img alt="The Algorithmic Minds" class="cx hj m afe afd" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*UE5GuhTAna40YZEOTagZSw.png" width="20"/></div></a></div></div></div></div><div><p>In</p></div><div><div><div><div><a href="https://medium.com/the-algorithmic-minds?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>The Algorithmic Minds</p></a></div></div></div></div><div><p>by</p></div><div><div><div><a href="/@mlwhiz?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>Rahul Agarwal</p></a></div></div></div></div><div><div><a href="/the-algorithmic-minds/tech-professionals-in-the-uk-what-you-need-to-learn-about-personal-finance-for-your-fire-planning-bc1eac59a9c9?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div title="Tech Professionals in the UK — What You Need to Learn About Personal Finance for your FIRE planning?"><h2>Tech Professionals in the UK — What You Need to Learn About Personal Finance for your FIRE planning?</h2></div><div><h3>A Journey Through the Trenches for Fellow Tech Brothers and Sisters</h3></div></a></div></div><span><div><div><span>Feb 22</span><div><div><a href="/the-algorithmic-minds/tech-professionals-in-the-uk-what-you-need-to-learn-about-personal-finance-for-your-fire-planning-bc1eac59a9c9?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>17</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbc1eac59a9c9&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fthe-algorithmic-minds%2Ftech-professionals-in-the-uk-what-you-need-to-learn-about-personal-finance-for-your-fire-planning-bc1eac59a9c9&amp;source=---read_next_recirc--9cc01d50a2a0----1-----------------bookmark_preview----a7defac2_abfd_40a8_8222_2699c04919ae--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div></div><div><div><div><article><div><div><div><div><div><div><div><img alt="Build an AI Finance Agent Team with phidata" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/1*4aXb1I6vrfe9McQ9XjzWAA.jpeg"/></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/towards-finance?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><img alt="Towards Finance" class="cx hj m afe afd" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*c_euhvHDcrNzBybdNNKaNQ.png" width="20"/></div></a></div></div></div></div><div><p>In</p></div><div><div><div><div><a href="https://medium.com/towards-finance?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>Towards Finance</p></a></div></div></div></div><div><p>by</p></div><div><div><div><a href="/@tinztwins?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>Tinz Twins</p></a></div></div></div></div><div><div><a href="/towards-finance/build-an-ai-finance-agent-team-with-phidata-fd6d2d984dc5?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div title=""><h2>Build an AI Finance Agent Team with phidata</h2></div><div><h3>Local Multi-Agent System with Web Access Using Llama 3.1 (Step-by-Step Guide)</h3></div></a></div></div><span><div><div><span>Jan 11</span><div><div><a href="/towards-finance/build-an-ai-finance-agent-team-with-phidata-fd6d2d984dc5?source=post_page---read_next_recirc--9cc01d50a2a0----0---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>99</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffd6d2d984dc5&amp;operation=register&amp;redirect=https%3A%2F%2Fblog.towardsfinance.com%2Fbuild-an-ai-finance-agent-team-with-phidata-fd6d2d984dc5&amp;source=---read_next_recirc--9cc01d50a2a0----0-----------------bookmark_preview----a7defac2_abfd_40a8_8222_2699c04919ae--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div><div><div><article><div><div><div><div><div><div><div><img alt="How I Built a Custom AI Document Assistant That Understands 1000s of PDFs and Talks Like a Human" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/0*u1dCRt0cYIeU9vCh"/></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/stackademic?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><img alt="Stackademic" class="cx hj m afe afd" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*U-kjsW7IZUobnoy1gAp1UQ.png" width="20"/></div></a></div></div></div></div><div><p>In</p></div><div><div><div><div><a href="https://medium.com/stackademic?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>Stackademic</p></a></div></div></div></div><div><p>by</p></div><div><div><div><a href="/@abdul.ahadmahmood555?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>Abdul Ahad</p></a></div></div></div></div><div><div><a href="/stackademic/how-i-built-a-custom-ai-document-assistant-that-understands-1000s-of-pdfs-and-talks-like-a-human-ec3aa57f370f?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div title="How I Built a Custom AI Document Assistant That Understands 1000s of PDFs and Talks Like a Human"><h2>How I Built a Custom AI Document Assistant That Understands 1000s of PDFs and Talks Like a Human</h2></div><div><h3>Forget basic search. I designed a Retrieval-Augmented Generation (RAG) system that reads technical documents, extracts diagrams, interprets…</h3></div></a></div></div><span><div><div><span>Jul 3</span><div><div><a href="/stackademic/how-i-built-a-custom-ai-document-assistant-that-understands-1000s-of-pdfs-and-talks-like-a-human-ec3aa57f370f?source=post_page---read_next_recirc--9cc01d50a2a0----1---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>126</span></div></div></div></div><div><div><div><div><svg height="16" width="16"><desc>A response icon</desc></svg><span>7</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fec3aa57f370f&amp;operation=register&amp;redirect=https%3A%2F%2Fblog.stackademic.com%2Fhow-i-built-a-custom-ai-document-assistant-that-understands-1000s-of-pdfs-and-talks-like-a-human-ec3aa57f370f&amp;source=---read_next_recirc--9cc01d50a2a0----1-----------------bookmark_preview----a7defac2_abfd_40a8_8222_2699c04919ae--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div><div><div><article><div><div><div><div><div><div><div><img alt="Building Agentic RAG Pipelines for Medical Data with CrewAI and Qdrant" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/1*Nr8wzNBPmhp-uCBne9_MzQ.png"/></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/ai-advances?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><img alt="AI Advances" class="cx hj m afe afd" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*R8zEd59FDf0l8Re94ImV0Q.png" width="20"/></div></a></div></div></div></div><div><p>In</p></div><div><div><div><div><a href="https://medium.com/ai-advances?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>AI Advances</p></a></div></div></div></div><div><p>by</p></div><div><div><div><a href="/@manthapavankumar11?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>M K Pavan Kumar</p></a></div></div></div></div><div><div><a href="/ai-advances/building-agentic-rag-pipelines-for-medical-data-with-crewai-and-qdrant-3a00a48fb0d1?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div title=""><h2>Building Agentic RAG Pipelines for Medical Data with CrewAI and Qdrant</h2></div><div><h3>This post will demonstrate the construction of a data intake pipeline and RAG agents utilizing Qdrant and Crewai. We consider an existing…</h3></div></a></div></div><span><div><div><span>Jan 12</span><div><div><a href="/ai-advances/building-agentic-rag-pipelines-for-medical-data-with-crewai-and-qdrant-3a00a48fb0d1?source=post_page---read_next_recirc--9cc01d50a2a0----2---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>287</span></div></div></div></div><div><div><div><div><svg height="16" width="16"><desc>A response icon</desc></svg><span>1</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a00a48fb0d1&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fbuilding-agentic-rag-pipelines-for-medical-data-with-crewai-and-qdrant-3a00a48fb0d1&amp;source=---read_next_recirc--9cc01d50a2a0----2-----------------bookmark_preview----a7defac2_abfd_40a8_8222_2699c04919ae--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div><div><div><article><div><div><div><div><div><div><div><img alt="LangGraph + DeepSeek-R1 + Function Call + Agentic RAG (Insane Results)" class="bh aer aes aet bw" loading="lazy" src="https://miro.medium.com/v2/resize:fit:679/1*BKXwuROR5irypuU3XIG4uw.png"/></div></div></div><div><div><div><div><div><div><div><a href="https://medium.com/towards-artificial-intelligence?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><img alt="Towards AI" class="cx hj m afe afd" height="20" loading="lazy" src="https://miro.medium.com/v2/resize:fill:20:20/1*JyIThO-cLjlChQLb6kSlVQ.png" width="20"/></div></a></div></div></div></div><div><p>In</p></div><div><div><div><div><a href="https://medium.com/towards-artificial-intelligence?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>Towards AI</p></a></div></div></div></div><div><p>by</p></div><div><div><div><a href="/@GaoDalie_AI?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><p>Gao Dalie (Ilyass)</p></a></div></div></div></div><div><div><a href="/towards-artificial-intelligence/langgraph-deepseek-r1-function-call-agentic-rag-insane-results-b3f878e23a86?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div title=""><h2>LangGraph + DeepSeek-R1 + Function Call + Agentic RAG (Insane Results)</h2></div><div><h3>In this video, I have a super quick tutorial showing you how to create a multi-agent chatbot using LangGraph, Deepseek-R1, function calling,</h3></div></a></div></div><span><div><div><span>Feb 23</span><div><div><a href="/towards-artificial-intelligence/langgraph-deepseek-r1-function-call-agentic-rag-insane-results-b3f878e23a86?source=post_page---read_next_recirc--9cc01d50a2a0----3---------------------a7defac2_abfd_40a8_8222_2699c04919ae--------------"><div><div><div><div><svg height="16" width="16"><desc>A clap icon</desc></svg><span>1.1K</span></div></div></div></div><div><div><div><div><svg height="16" width="16"><desc>A response icon</desc></svg><span>9</span></div></div></div></div></a></div></div></div><div><div><div><div><div><span><a href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb3f878e23a86&amp;operation=register&amp;redirect=https%3A%2F%2Fpub.towardsai.net%2Flanggraph-deepseek-r1-function-call-agentic-rag-insane-results-b3f878e23a86&amp;source=---read_next_recirc--9cc01d50a2a0----3-----------------bookmark_preview----a7defac2_abfd_40a8_8222_2699c04919ae--------------"></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><a href="/?source=post_page---read_next_recirc--9cc01d50a2a0---------------------------------------"><div>See more recommendations</div></a></div></div></div><div><div><div><div><div><a href="https://help.medium.com/hc/en-us?source=post_page-----9cc01d50a2a0---------------------------------------"><p>Help</p></a></div><div><a href="/about?autoplay=1&amp;source=post_page-----9cc01d50a2a0---------------------------------------"><p>About</p></a></div><div><a href="/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----9cc01d50a2a0---------------------------------------"><p>Careers</p></a></div><div><a href="https://blog.medium.com/?source=post_page-----9cc01d50a2a0---------------------------------------"><p>Blog</p></a></div><div><a href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9cc01d50a2a0---------------------------------------"><p>Privacy</p></a></div><div><a href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----9cc01d50a2a0---------------------------------------"><p>Rules</p></a></div><div><a href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9cc01d50a2a0---------------------------------------"><p>Terms</p></a></div></div></div></div></div></div></div></div></div></div></div>

















