{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae53775f",
   "metadata": {},
   "source": [
    "# Dataset formats and type\n",
    "\n",
    "- ***Định dạng*** (`format`) của một `dataset` đề cập đến cách dữ liệu được cấu trúc, thường được phân loại là *standard* (tiêu chuẩn) hoặc *conversational* (hội thoại).\n",
    "- ***Loại*** (`type`) được liên kết với tác vụ cụ thể mà `dataset` được thiết kế, chẳng hạn như *prompt-only* (chỉ có prompt) hoặc *preference* (sở thích). Mỗi loại được đặc trưng bởi các cột của nó, các cột này thay đổi tùy theo tác vụ, như được trình bày trong bảng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9085c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b0537e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ffd060680844a1a4ff82e53b1a0795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb999a6b",
   "metadata": {},
   "source": [
    "#### Standard (Tiêu chuẩn)\n",
    "\n",
    "Định dạng `dataset` tiêu chuẩn thường bao gồm các chuỗi văn bản thuần túy. Các cột trong `dataset` thay đổi tùy thuộc vào tác vụ. Đây là định dạng được các `trainer` của `TRL` mong đợi. Dưới đây là các ví dụ về định dạng `dataset` tiêu chuẩn cho các tác vụ khác nhau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03aed5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language modeling\n",
    "language_modeling_example = {\"text\": \"The sky is blue.\"}\n",
    "# Preference\n",
    "preference_example = {\"prompt\": \"The sky is\", \"chosen\": \" blue.\", \"rejected\": \" green.\"}\n",
    "# Unpaired preference\n",
    "unpaired_preference_example = {\"prompt\": \"The sky is\", \"completion\": \" blue.\", \"label\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b00524",
   "metadata": {},
   "source": [
    "\n",
    "#### Conversational (Hội thoại)\n",
    "\n",
    "Các `dataset` hội thoại được sử dụng cho các tác vụ liên quan đến đối thoại hoặc tương tác trò chuyện giữa người dùng và trợ lý. Không giống như các định dạng `dataset` tiêu chuẩn, chúng chứa các chuỗi tin nhắn, trong đó mỗi tin nhắn có một `role` (vai trò, ví dụ: `\"user\"` hoặc `\"assistant\"`) và `content` (nội dung, tức văn bản tin nhắn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a38874",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm doing great. How can I help you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"I'd like to show off how chat templating works!\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82038e3a",
   "metadata": {},
   "source": [
    "\n",
    "Cũng giống như các `dataset` tiêu chuẩn, các cột trong `dataset` hội thoại thay đổi tùy thuộc vào tác vụ. Dưới đây là các ví dụ về định dạng `dataset` hội thoại cho các tác vụ khác nhau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb6bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt-completion\n",
    "prompt_completion_example = {\"prompt\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
    "                             \"completion\": [{\"role\": \"assistant\", \"content\": \"It is blue.\"}]}\n",
    "# Preference\n",
    "preference_example = {\n",
    "    \"prompt\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
    "    \"chosen\": [{\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "    \"rejected\": [{\"role\": \"assistant\", \"content\": \"It is green.\"}],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30518d0",
   "metadata": {},
   "source": [
    "Các `dataset` hội thoại rất hữu ích để huấn luyện các mô hình trò chuyện (`chat models`), nhưng phải được chuyển đổi sang định dạng `standard` trước khi sử dụng với các `trainer` của `TRL`. Điều này thường được thực hiện bằng cách sử dụng các `chat templates` dành riêng cho mô hình đang được sử dụng. Để biết thêm thông tin, hãy tham khảo phần [Làm việc với dataset hội thoại trong TRL](https://www.google.com/search?q=%23l%C3%A0m-vi%E1%BB%87c-v%E1%BB%9Bi-dataset-h%E1%BB%99i-tho%E1%BA%A1i-trong-trl)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db42f2e",
   "metadata": {},
   "source": [
    "## Tool Calling (Gọi công cụ)\n",
    "\n",
    "Một số `chat templates` hỗ trợ *tool calling*, cho phép mô hình tương tác với các hàm bên ngoài—được gọi là **tools** (công cụ)—trong quá trình sinh văn bản. Điều này mở rộng khả năng hội thoại của mô hình bằng cách cho phép nó xuất ra một trường `\"tool_calls\"` thay vì một tin nhắn `\"content\"` tiêu chuẩn mỗi khi nó quyết định gọi một công cụ.\n",
    "\n",
    "Sau khi trợ lý khởi tạo một lệnh gọi công cụ, công cụ sẽ thực thi và trả về kết quả. Trợ lý sau đó có thể xử lý kết quả này và tiếp tục cuộc hội thoại một cách phù hợp.\n",
    "\n",
    "Đây là một ví dụ đơn giản về tương tác gọi công cụ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544e5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Turn on the living room lights.\"},\n",
    "    {\"role\": \"assistant\", \"tool_calls\": [\n",
    "        {\"type\": \"function\", \"function\": {\n",
    "            \"name\": \"control_light\",\n",
    "            \"arguments\": {\"room\": \"living room\", \"state\": \"on\"}\n",
    "        }}]\n",
    "    },\n",
    "    {\"role\": \"tool\", \"name\": \"control_light\", \"content\": \"The lights in the living room are now on.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Done!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46454416",
   "metadata": {},
   "source": [
    "Khi chuẩn bị `dataset` cho Supervised Fine-Tuning (`SFT`) với `tool calling`, điều quan trọng là `dataset` của bạn phải bao gồm một cột bổ sung có tên là `tools`. Cột này chứa danh sách các công cụ có sẵn cho mô hình, thường được `chat template` sử dụng để xây dựng `system prompt`.\n",
    "\n",
    "Các công cụ phải được chỉ định ở định dạng `JSON schema` đã được mã hóa. Bạn có thể tự động tạo `schema` này từ chữ ký hàm Python bằng cách sử dụng tiện ích [`~transformers.utils.get_json_schema`]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a29350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'control_light',\n",
       "  'description': 'Controls the lights in a room.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'room': {'type': 'string',\n",
       "     'description': 'The name of the room.'},\n",
       "    'state': {'type': 'string',\n",
       "     'description': 'The desired state of the light (\"on\" or \"off\").'}},\n",
       "   'required': ['room', 'state']},\n",
       "  'return': {'type': 'string',\n",
       "   'description': 'str: A message indicating the new state of the lights.'}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.utils import get_json_schema\n",
    "\n",
    "def control_light(room: str, state: str) -> str:\n",
    "    \"\"\"\n",
    "    Controls the lights in a room.\n",
    "\n",
    "    Args:\n",
    "        room: The name of the room.\n",
    "        state: The desired state of the light (\"on\" or \"off\").\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating the new state of the lights.\n",
    "    \"\"\"\n",
    "    return f\"The lights in {room} are now {state}.\"\n",
    "\n",
    "# Generate JSON schema\n",
    "json_schema = get_json_schema(control_light)\n",
    "json_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1fb92",
   "metadata": {},
   "source": [
    "A complete dataset entry for SFT might look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0203b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'Turn on the living room lights.'},\n",
       "  {'role': 'assistant',\n",
       "   'tool_calls': [{'type': 'function',\n",
       "     'function': {'name': 'control_light',\n",
       "      'arguments': {'room': 'living room', 'state': 'on'}}}]},\n",
       "  {'role': 'tool',\n",
       "   'name': 'control_light',\n",
       "   'content': 'The lights in the living room are now on.'},\n",
       "  {'role': 'assistant', 'content': 'Done!'}],\n",
       " 'tools': [{'type': 'function',\n",
       "   'function': {'name': 'control_light',\n",
       "    'description': 'Controls the lights in a room.',\n",
       "    'parameters': {'type': 'object',\n",
       "     'properties': {'room': {'type': 'string',\n",
       "       'description': 'The name of the room.'},\n",
       "      'state': {'type': 'string',\n",
       "       'description': 'The desired state of the light (\"on\" or \"off\").'}},\n",
       "     'required': ['room', 'state']},\n",
       "    'return': {'type': 'string',\n",
       "     'description': 'str: A message indicating the new state of the lights.'}}}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"messages\": messages, \"tools\": [json_schema]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a1836",
   "metadata": {},
   "source": [
    "### Types\n",
    "\n",
    "#### Mô hình hóa ngôn ngữ (Language modeling)\n",
    "\n",
    "Một `dataset` mô hình hóa ngôn ngữ bao gồm một cột `\"text\"` (hoặc `\"messages\"` cho các `dataset` hội thoại) chứa một chuỗi văn bản hoàn chỉnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec024ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard format\n",
    "language_modeling_example = {\"text\": \"The sky is blue.\"}\n",
    "# Conversational format\n",
    "language_modeling_example = {\"messages\": [\n",
    "    {\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"It is blue.\"}\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee251bb",
   "metadata": {},
   "source": [
    "#### Chỉ có prompt (Prompt-only)\n",
    "\n",
    "Trong một `dataset` chỉ có `prompt`, chỉ có `prompt` ban đầu (câu hỏi hoặc câu chưa hoàn chỉnh) được cung cấp dưới khóa `\"prompt\"`. Quá trình huấn luyện thường bao gồm việc tạo ra `completion` dựa trên `prompt` này, nơi mô hình học cách tiếp tục hoặc hoàn thành đầu vào đã cho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06bd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard format\n",
    "prompt_only_example = {\"prompt\": \"The sky is\"}\n",
    "# Conversational format\n",
    "prompt_only_example = {\"prompt\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11c528",
   "metadata": {},
   "source": [
    "> Mặc dù cả hai loại `prompt-only` và `language modeling` đều tương tự nhau, chúng khác nhau ở cách xử lý đầu vào. Trong loại `prompt-only`, `prompt` đại diện cho một đầu vào chưa hoàn chỉnh mà mong đợi mô hình sẽ hoàn thành hoặc tiếp tục, trong khi ở loại `language modeling`, đầu vào được coi là một câu hoặc chuỗi hoàn chỉnh. Hai loại này được `TRL` xử lý khác nhau. Dưới đây là một ví dụ cho thấy sự khác biệt trong đầu ra của hàm `apply_chat_template` cho mỗi loại:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "315ff922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1ee65fac90482ab4d0948ed6ce2d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e26e4f9e1f848f890e354788aaadad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097475a7570641c6afdd6e2710e4ed47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba98108adc0496b8d1351140d41866d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8624422592f8448897bb9a505a46c62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': '<|user|>\\nWhat color is the sky?<|end|>\\n<|endoftext|>'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from trl import apply_chat_template\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3n-E4B\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
    "\n",
    "# Example for prompt-only type\n",
    "prompt_only_example = {\"prompt\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}]}\n",
    "apply_chat_template(prompt_only_example, tokenizer)\n",
    "# Output: {'prompt': '<|user|>\\nWhat color is the sky?<|end|>\\n<|assistant|>\\n'}\n",
    "\n",
    "# Example for language modeling type\n",
    "lm_example = {\"messages\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}]}\n",
    "apply_chat_template(lm_example, tokenizer)\n",
    "# Output: {'text': '<|user|>\\nWhat color is the sky?<|end|>\\n<|endoftext|>'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca53b3",
   "metadata": {},
   "source": [
    "- Đầu ra của `prompt-only` bao gồm một `'<|assistant|>\\n'`, cho biết sự bắt đầu lượt của trợ lý và mong đợi mô hình tạo ra một `completion`.\n",
    "- Ngược lại, đầu ra của `language modeling` coi đầu vào là một chuỗi hoàn chỉnh và kết thúc nó bằng `'<|endoftext|>'`, báo hiệu sự kết thúc của văn bản và không mong đợi bất kỳ nội dung bổ sung nào."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e77a40",
   "metadata": {},
   "source": [
    "#### Prompt và completion (Prompt-completion)\n",
    "\n",
    "Một `dataset` `prompt-completion` bao gồm một `\"prompt\"` và một `\"completion\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c9df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard format\n",
    "prompt_completion_example = {\"prompt\": \"The sky is\", \"completion\": \" blue.\"}\n",
    "# Conversational format\n",
    "prompt_completion_example = {\"prompt\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
    "                            \"completion\": [{\"role\": \"assistant\", \"content\": \"It is blue.\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4721904",
   "metadata": {},
   "source": [
    "#### Preference\n",
    "\n",
    "Một preference dataset (`preference`) được sử dụng cho các tác vụ mà mô hình được huấn luyện để chọn giữa hai hoặc nhiều `completion` có thể có cho cùng một `prompt`. `Dataset` này bao gồm một `\"prompt\"`, một `completion` `\"chosen\"` (được chọn), và một `completion` `\"rejected\"` (bị từ chối). Mô hình được huấn luyện để chọn câu trả lời `\"chosen\"` thay vì câu trả lời `\"rejected\"`.\n",
    "Một số `dataset` có thể không bao gồm cột `\"prompt\"`, trong trường hợp đó `prompt` là ngầm định và được bao gồm trực tiếp trong các `completion` `\"chosen\"` và `\"rejected\"`. Chúng tôi khuyên bạn nên sử dụng `prompt` tường minh bất cứ khi nào có thể.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8057ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard format\n",
    "## Explicit prompt (recommended)\n",
    "preference_example = {\"prompt\": \"The sky is\", \"chosen\": \" blue.\", \"rejected\": \" green.\"}\n",
    "# Implicit prompt\n",
    "preference_example = {\"chosen\": \"The sky is blue.\", \"rejected\": \"The sky is green.\"}\n",
    "\n",
    "# Conversational format\n",
    "## Explicit prompt (recommended)\n",
    "preference_example = {\"prompt\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
    "                    \"chosen\": [{\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "                    \"rejected\": [{\"role\": \"assistant\", \"content\": \"It is green.\"}]}\n",
    "## Implicit prompt\n",
    "preference_example = {\"chosen\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
    "                                {\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "                    \"rejected\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
    "                                {\"role\": \"assistant\", \"content\": \"It is green.\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e3eba",
   "metadata": {},
   "source": [
    "Để xem các ví dụ về preference dataset, hãy tham khảo [bộ sưu tập Preference datasets](https://huggingface.co/collections/trl-lib/preference-datasets-677e99b581018fcad9abd82c).\n",
    "\n",
    "Một số preference dataset có thể được tìm thấy với [thẻ `dpo` trên Hugging Face Hub](https://www.google.com/search?q=%5Bhttps://huggingface.co/datasets%3Fother%3Ddpo%5D\\(https://huggingface.co/datasets%3Fother%3Ddpo\\)). Bạn cũng có thể khám phá [DPO Collections của librarian-bots](https://huggingface.co/collections/librarian-bots/direct-preference-optimization-datasets-66964b12835f46289b6ef2fc) để xác định các preference dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7a8a9",
   "metadata": {},
   "source": [
    "####  unpaired preference dataset (Unpaired preference)\n",
    "\n",
    "Một `dataset`  unpaired preference dataset (`unpaired preference`) tương tự như một preference dataset nhưng thay vì có các `completion` `\"chosen\"` và `\"rejected\"` cho cùng một `prompt`, nó bao gồm một `\"completion\"` duy nhất và một `\"label\"` cho biết `completion` đó có được ưa thích hay không.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "974b54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard format\n",
    "unpaired_preference_example = {\"prompt\": \"The sky is\", \"completion\": \" blue.\", \"label\": True}\n",
    "# Conversational format\n",
    "unpaired_preference_example = {\"prompt\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
    "                               \"completion\": [{\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "                               \"label\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8fc42",
   "metadata": {},
   "source": [
    "Để xem các ví dụ về `dataset`  unpaired preference dataset, hãy tham khảo [bộ sưu tập Unpaired preference datasets](https://huggingface.co/collections/trl-lib/unpaired-preference-datasets-677ea22bf5f528c125b0bcdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559fa29",
   "metadata": {},
   "source": [
    "#### Giám sát theo từng bước (Stepwise supervision)\n",
    "\n",
    "Một `dataset` giám sát theo từng bước (hoặc quy trình) tương tự như một `dataset` [ unpaired preference dataset](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-unpaired-preference) nhưng bao gồm nhiều bước của `completion`, mỗi bước có nhãn riêng. Cấu trúc này hữu ích cho các tác vụ cần ghi nhãn chi tiết, từng bước, chẳng hạn như các tác vụ suy luận. Bằng cách đánh giá từng bước riêng biệt và cung cấp các nhãn mục tiêu, phương pháp này giúp xác định chính xác nơi suy luận đúng và nơi xảy ra lỗi, cho phép phản hồi có mục tiêu trên từng phần của quá trình suy luận."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48599438",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_example = {\n",
    "    \"prompt\": \"Which number is larger, 9.8 or 9.11?\",\n",
    "    \"completions\": [\"The fractional part of 9.8 is 0.8, while the fractional part of 9.11 is 0.11.\", \"Since 0.11 is greater than 0.8, the number 9.11 is larger than 9.8.\"],\n",
    "    \"labels\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de89e4",
   "metadata": {},
   "source": [
    "Để xem các ví dụ về `dataset` giám sát theo từng bước, hãy tham khảo [bộ sưu tập Stepwise supervision datasets](https://huggingface.co/collections/trl-lib/stepwise-supervision-datasets-677ea27fd4c5941beed7a96e)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2da5ce",
   "metadata": {},
   "source": [
    "## Nên sử dụng loại dataset nào?\n",
    "\n",
    "Việc chọn đúng loại `dataset` phụ thuộc vào tác vụ bạn đang thực hiện và các yêu cầu cụ thể của `trainer` `TRL` bạn đang sử dụng. Dưới đây là tổng quan ngắn gọn về các loại `dataset` được hỗ trợ bởi mỗi `trainer` `TRL`.\n",
    "\n",
    "| Trainer                 | Loại dataset mong đợi                                                                                  |\n",
    "| ----------------------- | ------------------------------------------------------------------------------------------------------ |\n",
    "| [`BCOTrainer`]          | [ unpaired preference dataset](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-unpaired-preference)                                                            |\n",
    "| [`CPOTrainer`]          | [Sở thích (khuyến nghị prompt tường minh)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference)                                                |\n",
    "| [`DPOTrainer`]          | [Sở thích (khuyến nghị prompt tường minh)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference)                                                |\n",
    "| [`GKDTrainer`]          | [Prompt và completion](https://www.google.com/search?q=%23prompt-v%C3%A0-completion-prompt-completion)                                                    |\n",
    "| [`GRPOTrainer`]         | [Chỉ có prompt](https://www.google.com/search?q=%23ch%E1%BB%89-c%C3%B3-prompt-prompt-only)                                                                            |\n",
    "| [`IterativeSFTTrainer`] | [ unpaired preference dataset](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-unpaired-preference)                                                            |\n",
    "| [`KTOTrainer`]          | [ unpaired preference dataset](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-unpaired-preference) hoặc [Sở thích (khuyến nghị prompt tường minh)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference) |\n",
    "| [`NashMDTrainer`]       | [Chỉ có prompt](https://www.google.com/search?q=%23ch%E1%BB%89-c%C3%B3-prompt-prompt-only)                                                                            |\n",
    "| [`OnlineDPOTrainer`]    | [Chỉ có prompt](https://www.google.com/search?q=%23ch%E1%BB%89-c%C3%B3-prompt-prompt-only)                                                                            |\n",
    "| [`ORPOTrainer`]         | [Sở thích (khuyến nghị prompt tường minh)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference)                                                |\n",
    "| [`PPOTrainer`]          | Mô hình hóa ngôn ngữ đã được token hóa (`Tokenized language modeling`)                                                                            |\n",
    "| [`PRMTrainer`]          | [Giám sát theo từng bước](https://www.google.com/search?q=%23gi%C3%A1m-s%C3%A1t-theo-t%E1%BB%ABng-b%C6%B0%E1%BB%9Bc-stepwise-supervision)                                                          |\n",
    "| [`RewardTrainer`]       | [Sở thích (khuyến nghị prompt ngầm định)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference)                                                |\n",
    "| [`SFTTrainer`]          | [Mô hình hóa ngôn ngữ](https://www.google.com/search?q=%23m%C3%B4-h%C3%ACnh-h%C3%B3a-ng%C3%B4n-ng%E1%BB%AF-language-modeling) hoặc [Prompt và completion](https://www.google.com/search?q=%23prompt-v%C3%A0-completion-prompt-completion)                     |\n",
    "| [`XPOTrainer`]          | [Chỉ có prompt](https://www.google.com/search?q=%23ch%E1%BB%89-c%C3%B3-prompt-prompt-only) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076dbd4",
   "metadata": {},
   "source": [
    "> Các `trainer` của `TRL` chỉ hỗ trợ các định dạng `dataset` tiêu chuẩn, [tính đến thời điểm hiện tại](https://github.com/huggingface/trl/issues/2071). Nếu bạn có một `dataset` hội thoại, trước tiên bạn phải chuyển đổi nó sang định dạng tiêu chuẩn.\n",
    "Để biết thêm thông tin về cách làm việc với `dataset` hội thoại, hãy tham khảo phần [Làm việc với dataset hội thoại trong TRL](https://www.google.com/search?q=%23l%C3%A0m-vi%E1%BB%87c-v%E1%BB%9Bi-dataset-h%E1%BB%99i-tho%E1%BA%A1i-trong-trl)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d87dc7",
   "metadata": {},
   "source": [
    "## Làm việc với dataset hội thoại trong TRL\n",
    "\n",
    "Các `dataset` hội thoại ngày càng phổ biến, đặc biệt là để huấn luyện các mô hình trò chuyện (`chat models`). Tuy nhiên, một số `trainer` của `TRL` không hỗ trợ `dataset` hội thoại ở định dạng thô của chúng. (Để biết thêm thông tin, xem [issue \\#2071](https://github.com/huggingface/trl/issues/2071).) Các `dataset` này trước tiên phải được chuyển đổi sang định dạng tiêu chuẩn.\n",
    "May mắn thay, `TRL` cung cấp các công cụ để dễ dàng xử lý việc chuyển đổi này, được trình bày chi tiết dưới đây.\n",
    "\n",
    "### Chuyển đổi một dataset hội thoại thành một dataset tiêu chuẩn\n",
    "\n",
    "Để chuyển đổi một `dataset` hội thoại thành một `dataset` tiêu chuẩn, bạn cần *áp dụng một chat template* cho `dataset`. Một `chat template` là một cấu trúc được xác định trước thường bao gồm các trình giữ chỗ cho tin nhắn của người dùng và trợ lý. `Template` này được cung cấp bởi `tokenizer` của mô hình bạn sử dụng.\n",
    "\n",
    "Để biết hướng dẫn chi tiết về cách sử dụng `chat templating`, hãy tham khảo [mục Chat templating trong tài liệu của `transformers`](https://www.google.com/search?q=%5Bhttps://huggingface.co/docs/transformers/en/chat_templating%5D\\(https://huggingface.co/docs/transformers/en/chat_templating\\)).\n",
    "\n",
    "Trong `TRL`, phương thức bạn áp dụng để chuyển đổi `dataset` sẽ thay đổi tùy thuộc vào tác vụ. May mắn thay, `TRL` cung cấp một hàm trợ giúp có tên là [`apply_chat_template`] để đơn giản hóa quá trình này. Đây là một ví dụ về cách sử dụng nó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13fc2dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b40454886a645c78a97f005993a36e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52b7119f20645c4ac4600312037ab36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.70M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ba1fbeff064075b4b113275a58894e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2844f0148bb4e9996c3d66aaec2f755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/769 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048ff6a9aefe4825a1ba7fd702548b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': '<bos><start_of_turn>user\\nWhat color is the sky?<end_of_turn>\\n<start_of_turn>model\\n',\n",
       " 'completion': 'It is blue.<end_of_turn>\\n'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from trl import apply_chat_template\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3n-E2B-it\")\n",
    "\n",
    "example = {\n",
    "    \"prompt\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
    "    \"completion\": [{\"role\": \"assistant\", \"content\": \"It is blue.\"}]\n",
    "}\n",
    "\n",
    "apply_chat_template(example, tokenizer)\n",
    "# Output:\n",
    "# {'prompt': '<|user|>\\nWhat color is the sky?<|end|>\\n<|assistant|>\\n', 'completion': 'It is blue.<|end|>\\n<|endoftext|>'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b70eac",
   "metadata": {},
   "source": [
    "Alternatively, you can use the `map` method to apply the template across an entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e8dd85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3680a04e0e0742e2bd2226713ba78b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from trl import apply_chat_template\n",
    "\n",
    "dataset_dict = {\n",
    "    \"prompt\": [[{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
    "               [{\"role\": \"user\", \"content\": \"Where is the sun?\"}]],\n",
    "    \"completion\": [[{\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "                   [{\"role\": \"assistant\", \"content\": \"In the sky.\"}]]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "dataset = dataset.map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce5b69fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\nWhat color is the sky?<end_of_turn>\\n<start_of_turn>model\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abbaa13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is blue.<end_of_turn>\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['completion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49614b95",
   "metadata": {},
   "source": [
    "Chúng tôi khuyên bạn nên sử dụng hàm [`apply_chat_template`] thay vì gọi trực tiếp `tokenizer.apply_chat_template`. Việc xử lý các `chat template` cho các `dataset` không phải là `language modeling` có thể phức tạp và có thể dẫn đến lỗi, chẳng hạn như đặt nhầm `system prompt` vào giữa một cuộc hội thoại.\n",
    "Để biết thêm ví dụ, xem [\\#1930 (comment)](https://github.com/huggingface/trl/pull/1930#issuecomment-2292908614). Hàm [`apply_chat_template`] được thiết kế để xử lý những sự phức tạp này và đảm bảo áp dụng đúng các `chat template` cho các tác vụ khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cfacc6",
   "metadata": {},
   "source": [
    "> Điều quan trọng cần lưu ý là các `chat template` là đặc trưng cho từng mô hình. Ví dụ, nếu bạn sử dụng `chat template` từ [meta-llama/Meta-Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct) với ví dụ trên, bạn sẽ nhận được một đầu ra khác.\n",
    "\n",
    "> Luôn sử dụng `chat template` được liên kết với mô hình bạn đang làm việc. Sử dụng sai `template` có thể dẫn đến kết quả không chính xác hoặc không mong muốn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb7364",
   "metadata": {},
   "source": [
    "## Sử dụng bất kỳ dataset nào với TRL: tiền xử lý và chuyển đổi\n",
    "\n",
    "Nhiều `dataset` có định dạng được thiết kế riêng cho các tác vụ cụ thể, có thể không tương thích trực tiếp với `TRL`. Để sử dụng các `dataset` như vậy với `TRL`, bạn có thể cần phải tiền xử lý và chuyển đổi chúng sang định dạng bắt buộc.\n",
    "\n",
    "Để làm điều này dễ dàng hơn, chúng tôi cung cấp một bộ [script ví dụ](https://github.com/huggingface/trl/tree/main/examples/datasets) bao gồm các chuyển đổi `dataset` phổ biến.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f5740",
   "metadata": {},
   "source": [
    "## Các tiện ích để chuyển đổi các loại dataset\n",
    "\n",
    "Phần này cung cấp mã ví dụ để giúp bạn chuyển đổi giữa các loại `dataset` khác nhau. Mặc dù một số chuyển đổi có thể được thực hiện sau khi áp dụng `chat template` (tức là ở định dạng `standard`), chúng tôi khuyên bạn nên thực hiện chuyển đổi trước khi áp dụng `chat template` để đảm bảo nó hoạt động nhất quán.\n",
    "\n",
    "Để đơn giản, một số ví dụ dưới đây không tuân theo khuyến nghị này và sử dụng định dạng `standard`. Tuy nhiên, các chuyển đổi có thể được áp dụng trực tiếp cho định dạng hội thoại mà không cần sửa đổi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739ae9aa",
   "metadata": {},
   "source": [
    "### Từ dataset prompt-completion sang language modeling\n",
    "\n",
    "Để chuyển đổi một `dataset` `prompt-completion` thành một `dataset` `language modeling`, hãy nối `prompt` và `completion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "412e9feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20aa7d18942d44e98009df470edf6409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"The sky is\", \"The sun is\"],\n",
    "    \"completion\": [\" blue.\", \" in the sky.\"],\n",
    "})\n",
    "\n",
    "def concat_prompt_completion(example):\n",
    "    return {\"text\": example[\"prompt\"] + example[\"completion\"]}\n",
    "\n",
    "dataset = dataset.map(concat_prompt_completion, remove_columns=[\"prompt\", \"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1a3f2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The sky is blue.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875beaf",
   "metadata": {},
   "source": [
    "### Từ dataset prompt-completion sang prompt-only\n",
    "\n",
    "Để chuyển đổi một `dataset` `prompt-completion` thành một `dataset` `prompt-only`, hãy xóa `completion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a87f26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"The sky is\", \"The sun is\"],\n",
    "    \"completion\": [\" blue.\", \" in the sky.\"],\n",
    "})\n",
    "\n",
    "dataset = dataset.remove_columns(\"completion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bbb8747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'The sky is'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada7eef",
   "metadata": {},
   "source": [
    "### From preference with implicit prompt to language modeling dataset\n",
    "\n",
    "Để chuyển đổi một `dataset` preference với `prompt` ngầm định thành một `dataset` `language modeling`, hãy xóa cột `rejected` và đổi tên cột `\"chosen\"` thành `\"text\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "295a1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"chosen\": [\"The sky is blue.\", \"The sun is in the sky.\"],\n",
    "    \"rejected\": [\"The sky is green.\", \"The sun is in the sea.\"],\n",
    "})\n",
    "\n",
    "dataset = dataset.rename_column(\"chosen\", \"text\").remove_columns(\"rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ae36f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The sky is blue.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae6006",
   "metadata": {},
   "source": [
    "### From preference with implicit prompt to prompt-completion dataset\n",
    "\n",
    "Để chuyển đổi một preference dataset với `prompt` ngầm định thành một `dataset` `prompt-completion`, hãy trích xuất `prompt` bằng [`extract_prompt`], xóa cột `rejected`, và đổi tên cột `\"chosen\"` thành `\"completion\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9c943ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8614585b8f94715ab34a9f52012596e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chosen', 'rejected', 'prompt'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from trl import extract_prompt\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"chosen\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}, {\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}, {\"role\": \"assistant\", \"content\": \"In the sky.\"}],\n",
    "    ],\n",
    "    \"rejected\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}, {\"role\": \"assistant\", \"content\": \"It is green.\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}, {\"role\": \"assistant\", \"content\": \"In the sea.\"}],\n",
    "    ],\n",
    "})\n",
    "dataset = dataset.map(extract_prompt)#.remove_columns(\"rejected\").rename_column(\"chosen\", \"completion\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7afebb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'What color is the sky?', 'role': 'user'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aea06546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion': [{'content': 'It is blue.', 'role': 'assistant'}],\n",
       " 'prompt': [{'content': 'What color is the sky?', 'role': 'user'}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns(\"rejected\").rename_column(\"chosen\", \"completion\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4552d5ab",
   "metadata": {},
   "source": [
    "### Từ preference dataset với prompt ngầm định sang prompt-only\n",
    "\n",
    "Để chuyển đổi một preference dataset với `prompt` ngầm định thành một `dataset` `prompt-only`, hãy trích xuất `prompt` bằng [`extract_prompt`], và xóa các cột `rejected` và `chosen`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "998a931c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abfbccc310040718da58c5e08653e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from trl import extract_prompt\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"chosen\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}, {\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}, {\"role\": \"assistant\", \"content\": \"In the sky.\"}],\n",
    "    ],\n",
    "    \"rejected\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}, {\"role\": \"assistant\", \"content\": \"It is green.\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}, {\"role\": \"assistant\", \"content\": \"In the sea.\"}],\n",
    "    ],\n",
    "})\n",
    "dataset = dataset.map(extract_prompt).remove_columns([\"chosen\", \"rejected\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e98d56f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': [{'content': 'What color is the sky?', 'role': 'user'}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e9935",
   "metadata": {},
   "source": [
    "### Từ preference dataset với prompt ngầm định sang tường minh\n",
    "\n",
    "Để chuyển đổi một preference dataset với `prompt` ngầm định thành một preference dataset với `prompt` tường minh, hãy trích xuất `prompt` bằng [`extract_prompt`].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "398bf8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15ec833347d4b549813b0b073898ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'chosen': [{'content': 'It is blue.', 'role': 'assistant'}],\n",
       " 'rejected': [{'content': 'It is green.', 'role': 'assistant'}],\n",
       " 'prompt': [{'content': 'What color is the sky?', 'role': 'user'}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from trl import extract_prompt\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"chosen\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}, {\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}, {\"role\": \"assistant\", \"content\": \"In the sky.\"}],\n",
    "    ],\n",
    "    \"rejected\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}, {\"role\": \"assistant\", \"content\": \"It is green.\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}, {\"role\": \"assistant\", \"content\": \"In the sea.\"}],\n",
    "    ],\n",
    "})\n",
    "\n",
    "dataset = dataset.map(extract_prompt)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022ffbb",
   "metadata": {},
   "source": [
    "### Từ preference dataset với prompt ngầm định sang  unpaired preference dataset\n",
    "\n",
    "Để chuyển đổi một preference dataset với `prompt` ngầm định thành một `dataset`  unpaired preference dataset, hãy trích xuất `prompt` bằng [`extract_prompt`], và tách cặp `dataset` bằng [`unpair_preference_dataset`]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53502231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from trl import extract_prompt, unpair_preference_dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"chosen\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}, {\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}, {\"role\": \"assistant\", \"content\": \"In the sky.\"}],\n",
    "    ],\n",
    "    \"rejected\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}, {\"role\": \"assistant\", \"content\": \"It is green.\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}, {\"role\": \"assistant\", \"content\": \"In the sea.\"}],\n",
    "    ],\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dbd9625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389f210c02d74628b6e43d20afca6248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'chosen': [{'content': 'It is blue.', 'role': 'assistant'}],\n",
       " 'rejected': [{'content': 'It is green.', 'role': 'assistant'}],\n",
       " 'prompt': [{'content': 'What color is the sky?', 'role': 'user'}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(extract_prompt)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "752b2e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4c38565829485ebb75e8a7bd3dcae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': [{'content': 'What color is the sky?', 'role': 'user'}],\n",
       " 'completion': [{'content': 'It is blue.', 'role': 'assistant'}],\n",
       " 'label': True}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = unpair_preference_dataset(dataset)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66eec6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8132edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': [{'content': 'What color is the sky?', 'role': 'user'}],\n",
       " 'completion': [{'content': 'It is green.', 'role': 'assistant'}],\n",
       " 'label': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c236aa",
   "metadata": {},
   "source": [
    "### Từ preference dataset sang language modeling\n",
    "\n",
    "Để chuyển đổi một preference dataset thành một `dataset` `language modeling`, hãy xóa cột `rejected`, nối `prompt` và `chosen` vào cột `\"text\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20562e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f7abbcc730404195d6b5bffd70a10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'The sky is blue.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"The sky is\", \"The sun is\"],\n",
    "    \"chosen\": [\" blue.\", \" in the sky.\"],\n",
    "    \"rejected\": [\" green.\", \" in the sea.\"],\n",
    "})\n",
    "\n",
    "def concat_prompt_chosen(example):\n",
    "    return {\"text\": example[\"prompt\"] + example[\"chosen\"]}\n",
    "\n",
    "dataset = dataset.map(concat_prompt_chosen, remove_columns=[\"prompt\", \"chosen\", \"rejected\"])\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ad9f3",
   "metadata": {},
   "source": [
    "### Từ preference dataset sang prompt-completion\n",
    "\n",
    "Để chuyển đổi một preference dataset thành một `dataset` `prompt-completion`, hãy xóa cột `rejected`, và đổi tên cột `\"chosen\"` thành `\"completion\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c62c45e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'The sky is', 'completion': ' blue.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"The sky is\", \"The sun is\"],\n",
    "    \"chosen\": [\" blue.\", \" in the sky.\"],\n",
    "    \"rejected\": [\" green.\", \" in the sea.\"],\n",
    "})\n",
    "\n",
    "dataset = dataset.remove_columns(\"rejected\").rename_column(\"chosen\", \"completion\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1317fa4",
   "metadata": {},
   "source": [
    "### Từ dataset sở thích sang prompt-only\n",
    "\n",
    "Để chuyển đổi một `dataset` sở thích thành một `dataset` `prompt-only`, hãy xóa các cột `rejected` và `chosen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1e5caab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'The sky is'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"The sky is\", \"The sun is\"],\n",
    "    \"chosen\": [\" blue.\", \" in the sky.\"],\n",
    "    \"rejected\": [\" green.\", \" in the sea.\"],\n",
    "})\n",
    "\n",
    "dataset = dataset.remove_columns([\"chosen\", \"rejected\"])\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb88e00",
   "metadata": {},
   "source": [
    "### Từ dataset sở thích với prompt tường minh sang ngầm định\n",
    "\n",
    "Để chuyển đổi một `dataset` sở thích với `prompt` tường minh thành một `dataset` sở thích với `prompt` ngầm định, hãy nối `prompt` vào cả `chosen` và `rejected`, và xóa cột `prompt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e07a8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f58d531ec7429bb649db2caff88902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'chosen': [{'content': 'What color is the sky?', 'role': 'user'},\n",
       "  {'content': 'It is blue.', 'role': 'assistant'}],\n",
       " 'rejected': [{'content': 'What color is the sky?', 'role': 'user'},\n",
       "  {'content': 'It is green.', 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}],\n",
    "    ],\n",
    "    \"chosen\": [\n",
    "        [{\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "        [{\"role\": \"assistant\", \"content\": \"In the sky.\"}],\n",
    "    ],\n",
    "    \"rejected\": [\n",
    "        [{\"role\": \"assistant\", \"content\": \"It is green.\"}],\n",
    "        [{\"role\": \"assistant\", \"content\": \"In the sea.\"}],\n",
    "    ],\n",
    "})\n",
    "\n",
    "def concat_prompt_to_completions(example):\n",
    "    return {\"chosen\": example[\"prompt\"] + example[\"chosen\"], \"rejected\": example[\"prompt\"] + example[\"rejected\"]}\n",
    "\n",
    "dataset = dataset.map(concat_prompt_to_completions, remove_columns=\"prompt\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e8189d",
   "metadata": {},
   "source": [
    "### Từ dataset sở thích sang sở thích không theo cặp\n",
    "\n",
    "Để chuyển đổi `dataset` thành một `dataset` sở thích không theo cặp, hãy tách cặp `dataset` bằng [`unpair_preference_dataset`].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea33718a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52aabc631d4e4a0f8dafe3cedcf60337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': [{'content': 'What color is the sky?', 'role': 'user'}],\n",
       " 'completion': [{'content': 'It is blue.', 'role': 'assistant'}],\n",
       " 'label': True}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from trl import unpair_preference_dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\n",
    "        [{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
    "        [{\"role\": \"user\", \"content\": \"Where is the sun?\"}],\n",
    "    ],\n",
    "    \"chosen\": [\n",
    "        [{\"role\": \"assistant\", \"content\": \"It is blue.\"}],\n",
    "        [{\"role\": \"assistant\", \"content\": \"In the sky.\"}],\n",
    "    ],\n",
    "    \"rejected\": [\n",
    "        [{\"role\": \"assistant\", \"content\": \"It is green.\"}],\n",
    "        [{\"role\": \"assistant\", \"content\": \"In the sea.\"}],\n",
    "    ],\n",
    "})\n",
    "\n",
    "dataset = unpair_preference_dataset(dataset)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34d9173b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8a55f",
   "metadata": {},
   "source": [
    "> Hãy nhớ rằng các `completion` `\"chosen\"` và `\"rejected\"` trong một `dataset` sở thích có thể là tốt hoặc xấu.\n",
    "Trước khi áp dụng [`unpair_preference_dataset`], hãy đảm bảo rằng tất cả các `completion` `\"chosen\"` có thể được gán nhãn là tốt và tất cả các `completion` `\"rejected\"` là xấu.\n",
    "Điều này có thể được đảm bảo bằng cách kiểm tra điểm đánh giá tuyệt đối của mỗi `completion`, ví dụ như từ một mô hình phần thưởng (`reward model`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa2efa",
   "metadata": {},
   "source": [
    "### Từ dataset sở thích không theo cặp sang language modeling\n",
    "\n",
    "Để chuyển đổi một `dataset` sở thích không theo cặp thành một `dataset` `language modeling`, hãy nối các `prompt` với các `completion` tốt vào cột `\"text\"`, và xóa các cột `prompt`, `completion` và `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "972c11f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75084033e91d487fa623b69f48ed0dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc08bb3e0f474ae29800e6df840d8d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"The sky is\", \"The sun is\", \"The sky is\", \"The sun is\"],\n",
    "    \"completion\": [\" blue.\", \" in the sky.\", \" green.\", \" in the sea.\"],\n",
    "    \"label\": [True, True, False, False],\n",
    "})\n",
    "\n",
    "def concatenate_prompt_completion(example):\n",
    "    return {\"text\": example[\"prompt\"] + example[\"completion\"]}\n",
    "\n",
    "dataset = dataset.filter(lambda x: x[\"label\"]).map(concatenate_prompt_completion).remove_columns([\"prompt\", \"completion\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "039eb35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The sky is blue.'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05ecde1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6162ccc5",
   "metadata": {},
   "source": [
    "\n",
    "### Từ dataset sở thích không theo cặp sang prompt-completion\n",
    "\n",
    "Để chuyển đổi một `dataset` sở thích không theo cặp thành một `dataset` `prompt-completion`, hãy lọc các nhãn tốt, sau đó xóa các cột nhãn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8902b8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9899d83093943afb4d0e6ef860cbbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"The sky is\", \"The sun is\", \"The sky is\", \"The sun is\"],\n",
    "    \"completion\": [\" blue.\", \" in the sky.\", \" green.\", \" in the sea.\"],\n",
    "    \"label\": [True, True, False, False],\n",
    "})\n",
    "\n",
    "dataset = dataset.filter(lambda x: x[\"label\"]).remove_columns([\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "958d12f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'The sky is', 'completion': ' blue.'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79ed137d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58de1ee",
   "metadata": {},
   "source": [
    "### Từ dataset sở thích không theo cặp sang prompt-only\n",
    "\n",
    "Để chuyển đổi một `dataset` sở thích không theo cặp thành một `dataset` `prompt-only`, hãy xóa các cột `completion` và `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1dc85003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"The sky is\", \"The sun is\", \"The sky is\", \"The sun is\"],\n",
    "    \"completion\": [\" blue.\", \" in the sky.\", \" green.\", \" in the sea.\"],\n",
    "    \"label\": [True, True, False, False],\n",
    "})\n",
    "\n",
    "dataset = dataset.remove_columns([\"completion\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1209065a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'The sky is'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50c43798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b71af",
   "metadata": {},
   "source": [
    "### Từ dataset giám sát theo từng bước sang language modeling\n",
    "\n",
    "Để chuyển đổi một `dataset` giám sát theo từng bước thành một `dataset` `language modeling`, hãy nối các `prompt` với các `completion` tốt vào cột `\"text\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9261268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f717fd8f9ea047118fb5512e7fe9481b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd9d984d7054ecc8bdfb2a91a3748ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"Blue light\", \"Water\"],\n",
    "    \"completions\": [[\" scatters more in the atmosphere,\", \" so the sky is green.\"],\n",
    "                   [\" forms a less dense structure in ice,\", \" which causes it to expand when it freezes.\"]],\n",
    "    \"labels\": [[True, False], [True, True]],\n",
    "})\n",
    "\n",
    "def concatenate_prompt_completions(example):\n",
    "    completion = \"\".join(example[\"completions\"])\n",
    "    return {\"text\": example[\"prompt\"] + completion}\n",
    "\n",
    "dataset = dataset.filter(lambda x: all(x[\"labels\"])).map(concatenate_prompt_completions, remove_columns=[\"prompt\", \"completions\", \"labels\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6aa0d575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Water forms a less dense structure in ice, which causes it to expand when it freezes.'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130bbfae",
   "metadata": {},
   "source": [
    "### Từ dataset giám sát theo từng bước sang prompt completion\n",
    "\n",
    "Để chuyển đổi một `dataset` giám sát theo từng bước thành một `dataset` `prompt-completion`, hãy nối các `completion` tốt lại và xóa các nhãn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd8f5873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957410932bb1441e9aba710d313cf6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832422c853704f00bb7d1d8b23715737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"Blue light\", \"Water\"],\n",
    "    \"completions\": [[\" scatters more in the atmosphere,\", \" so the sky is green.\"],\n",
    "                   [\" forms a less dense structure in ice,\", \" which causes it to expand when it freezes.\"]],\n",
    "    \"labels\": [[True, False], [True, True]],\n",
    "})\n",
    "\n",
    "def join_completions(example):\n",
    "    completion = \"\".join(example[\"completions\"])\n",
    "    return {\"completion\": completion}\n",
    "\n",
    "dataset = dataset.filter(lambda x: all(x[\"labels\"])).map(join_completions, remove_columns=[\"completions\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd3de68",
   "metadata": {},
   "source": [
    "### Từ dataset giám sát theo từng bước sang prompt only\n",
    "\n",
    "Để chuyển đổi một `dataset` giám sát theo từng bước thành một `dataset` `prompt-only`, hãy xóa các cột `completions` và `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2e01dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"Blue light\", \"Water\"],\n",
    "    \"completions\": [[\" scatters more in the atmosphere,\", \" so the sky is green.\"],\n",
    "                   [\" forms a less dense structure in ice,\", \" which causes it to expand when it freezes.\"]],\n",
    "    \"labels\": [[True, False], [True, True]],\n",
    "})\n",
    "\n",
    "dataset = dataset.remove_columns([\"completions\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ec57a0",
   "metadata": {},
   "source": [
    "### Từ dataset giám sát theo từng bước sang sở thích không theo cặp\n",
    "\n",
    "Để chuyển đổi một `dataset` giám sát theo từng bước thành một `dataset` sở thích không theo cặp, hãy nối các `completions` và hợp nhất các `labels`.\n",
    "\n",
    "Phương pháp hợp nhất các nhãn phụ thuộc vào tác vụ cụ thể. Trong ví dụ này, chúng tôi sử dụng phép toán AND logic. Điều này có nghĩa là nếu các nhãn của từng bước cho biết tính đúng đắn của các bước riêng lẻ, nhãn kết quả sẽ phản ánh tính đúng đắn của toàn bộ chuỗi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81daa327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd8f7e323eb41a2ad5e21ad3fd5eb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"prompt\": [\"Blue light\", \"Water\"],\n",
    "    \"completions\": [[\" scatters more in the atmosphere,\", \" so the sky is green.\"],\n",
    "                   [\" forms a less dense structure in ice,\", \" which causes it to expand when it freezes.\"]],\n",
    "    \"labels\": [[True, False], [True, True]],\n",
    "})\n",
    "\n",
    "def merge_completions_and_labels(example):\n",
    "    return {\"prompt\": example[\"prompt\"], \"completion\": \"\".join(example[\"completions\"]), \"label\": all(example[\"labels\"])}\n",
    "\n",
    "dataset = dataset.map(merge_completions_and_labels, remove_columns=[\"completions\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422dc2f",
   "metadata": {},
   "source": [
    "## Vision datasets (Dataset hình ảnh)\n",
    "\n",
    "Một số `trainer` cũng hỗ trợ tinh chỉnh các mô hình ngôn ngữ-thị giác (vision-language models - VLMs) bằng cách sử dụng các cặp hình ảnh-văn bản. Trong trường hợp này, khuyến nghị sử dụng định dạng hội thoại, vì mỗi mô hình xử lý các trình giữ chỗ hình ảnh trong văn bản theo cách khác nhau.\n",
    "\n",
    "Một `dataset` thị giác hội thoại khác với một `dataset` hội thoại tiêu chuẩn ở hai điểm chính:\n",
    "\n",
    "1.  `Dataset` phải chứa khóa `images` với dữ liệu hình ảnh.\n",
    "2.  Trường `\"content\"` trong các tin nhắn phải là một danh sách các dictionary, trong đó mỗi dictionary chỉ định loại dữ liệu: `\"image\"` hoặc `\"text\"`.\n",
    "\n",
    "Ví dụ:\n",
    "\n",
    "```python\n",
    "# Dataset văn bản:\n",
    "\"content\": \"What color is the sky?\"\n",
    "\n",
    "# Dataset thị giác:\n",
    "\"content\": [\n",
    "    {\"type\": \"image\"}, \n",
    "    {\"type\": \"text\", \"text\": \"What color is the sky in the image?\"}\n",
    "]\n",
    "```\n",
    "\n",
    "Một ví dụ về `dataset` thị giác hội thoại là [openbmb/RLAIF-V-Dataset](https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3401a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
