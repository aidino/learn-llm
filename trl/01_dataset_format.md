Cháº¯c cháº¯n rá»“i, Ä‘Ã¢y lÃ  báº£n dá»‹ch tÃ i liá»‡u sang tiáº¿ng Viá»‡t, tuÃ¢n thá»§ cÃ¡c yÃªu cáº§u cá»§a báº¡n.

-----

# CÃ¡c Ä‘á»‹nh dáº¡ng vÃ  loáº¡i Dataset

HÆ°á»›ng dáº«n nÃ y cung cáº¥p tá»•ng quan vá» cÃ¡c Ä‘á»‹nh dáº¡ng vÃ  loáº¡i `dataset` Ä‘Æ°á»£c há»— trá»£ bá»Ÿi má»—i `trainer` trong `TRL`.

## Tá»•ng quan vá» cÃ¡c Ä‘á»‹nh dáº¡ng vÃ  loáº¡i dataset

  - ***Äá»‹nh dáº¡ng*** (`format`) cá»§a má»™t `dataset` Ä‘á» cáº­p Ä‘áº¿n cÃ¡ch dá»¯ liá»‡u Ä‘Æ°á»£c cáº¥u trÃºc, thÆ°á»ng Ä‘Æ°á»£c phÃ¢n loáº¡i lÃ  *standard* (tiÃªu chuáº©n) hoáº·c *conversational* (há»™i thoáº¡i).
  - ***Loáº¡i*** (`type`) Ä‘Æ°á»£c liÃªn káº¿t vá»›i tÃ¡c vá»¥ cá»¥ thá»ƒ mÃ  `dataset` Ä‘Æ°á»£c thiáº¿t káº¿, cháº³ng háº¡n nhÆ° *prompt-only* (chá»‰ cÃ³ prompt) hoáº·c *preference* (sá»Ÿ thÃ­ch). Má»—i loáº¡i Ä‘Æ°á»£c Ä‘áº·c trÆ°ng bá»Ÿi cÃ¡c cá»™t cá»§a nÃ³, cÃ¡c cá»™t nÃ y thay Ä‘á»•i tÃ¹y theo tÃ¡c vá»¥, nhÆ° Ä‘Æ°á»£c trÃ¬nh bÃ y trong báº£ng.


### Äá»‹nh dáº¡ng

#### Standard (TiÃªu chuáº©n)

Äá»‹nh dáº¡ng `dataset` tiÃªu chuáº©n thÆ°á»ng bao gá»“m cÃ¡c chuá»—i vÄƒn báº£n thuáº§n tÃºy. CÃ¡c cá»™t trong `dataset` thay Ä‘á»•i tÃ¹y thuá»™c vÃ o tÃ¡c vá»¥. ÄÃ¢y lÃ  Ä‘á»‹nh dáº¡ng Ä‘Æ°á»£c cÃ¡c `trainer` cá»§a `TRL` mong Ä‘á»£i. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c vÃ­ dá»¥ vá» Ä‘á»‹nh dáº¡ng `dataset` tiÃªu chuáº©n cho cÃ¡c tÃ¡c vá»¥ khÃ¡c nhau:

```python
# MÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ (Language modeling)
language_modeling_example = {"text": "The sky is blue."}
# Sá»Ÿ thÃ­ch (Preference)
preference_example = {"prompt": "The sky is", "chosen": " blue.", "rejected": " green."}
# Sá»Ÿ thÃ­ch khÃ´ng theo cáº·p (Unpaired preference)
unpaired_preference_example = {"prompt": "The sky is", "completion": " blue.", "label": True}
```

#### Conversational (Há»™i thoáº¡i)

CÃ¡c `dataset` há»™i thoáº¡i Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n Ä‘á»‘i thoáº¡i hoáº·c tÆ°Æ¡ng tÃ¡c trÃ² chuyá»‡n giá»¯a ngÆ°á»i dÃ¹ng vÃ  trá»£ lÃ½. KhÃ´ng giá»‘ng nhÆ° cÃ¡c Ä‘á»‹nh dáº¡ng `dataset` tiÃªu chuáº©n, chÃºng chá»©a cÃ¡c chuá»—i tin nháº¯n, trong Ä‘Ã³ má»—i tin nháº¯n cÃ³ má»™t `role` (vai trÃ², vÃ­ dá»¥: `"user"` hoáº·c `"assistant"`) vÃ  `content` (ná»™i dung, tá»©c vÄƒn báº£n tin nháº¯n).

```python
messages = [
Â  Â  {"role": "user", "content": "Hello, how are you?"},
Â  Â  {"role": "assistant", "content": "I'm doing great. How can I help you today?"},
Â  Â  {"role": "user", "content": "I'd like to show off how chat templating works!"},
]
```

CÅ©ng giá»‘ng nhÆ° cÃ¡c `dataset` tiÃªu chuáº©n, cÃ¡c cá»™t trong `dataset` há»™i thoáº¡i thay Ä‘á»•i tÃ¹y thuá»™c vÃ o tÃ¡c vá»¥. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c vÃ­ dá»¥ vá» Ä‘á»‹nh dáº¡ng `dataset` há»™i thoáº¡i cho cÃ¡c tÃ¡c vá»¥ khÃ¡c nhau:

```python
# Prompt vÃ  completion (Prompt-completion)
prompt_completion_example = {"prompt": [{"role": "user", "content": "What color is the sky?"}],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "completion": [{"role": "assistant", "content": "It is blue."}]}
# Sá»Ÿ thÃ­ch (Preference)
preference_example = {
Â  Â  "prompt": [{"role": "user", "content": "What color is the sky?"}],
Â  Â  "chosen": [{"role": "assistant", "content": "It is blue."}],
Â  Â  "rejected": [{"role": "assistant", "content": "It is green."}],
}
```

CÃ¡c `dataset` há»™i thoáº¡i ráº¥t há»¯u Ã­ch Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh trÃ² chuyá»‡n (`chat models`), nhÆ°ng pháº£i Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i sang Ä‘á»‹nh dáº¡ng `standard` trÆ°á»›c khi sá»­ dá»¥ng vá»›i cÃ¡c `trainer` cá»§a `TRL`. Äiá»u nÃ y thÆ°á»ng Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c `chat templates` dÃ nh riÃªng cho mÃ´ hÃ¬nh Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng. Äá»ƒ biáº¿t thÃªm thÃ´ng tin, hÃ£y tham kháº£o pháº§n [LÃ m viá»‡c vá»›i dataset há»™i thoáº¡i trong TRL](https://www.google.com/search?q=%23l%C3%A0m-vi%E1%BB%87c-v%E1%BB%9Bi-dataset-h%E1%BB%99i-tho%E1%BA%A1i-trong-trl).

## Tool Calling (Gá»i cÃ´ng cá»¥)

Má»™t sá»‘ `chat templates` há»— trá»£ *tool calling*, cho phÃ©p mÃ´ hÃ¬nh tÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c hÃ m bÃªn ngoÃ iâ€”Ä‘Æ°á»£c gá»i lÃ  **tools** (cÃ´ng cá»¥)â€”trong quÃ¡ trÃ¬nh sinh vÄƒn báº£n. Äiá»u nÃ y má»Ÿ rá»™ng kháº£ nÄƒng há»™i thoáº¡i cá»§a mÃ´ hÃ¬nh báº±ng cÃ¡ch cho phÃ©p nÃ³ xuáº¥t ra má»™t trÆ°á»ng `"tool_calls"` thay vÃ¬ má»™t tin nháº¯n `"content"` tiÃªu chuáº©n má»—i khi nÃ³ quyáº¿t Ä‘á»‹nh gá»i má»™t cÃ´ng cá»¥.

Sau khi trá»£ lÃ½ khá»Ÿi táº¡o má»™t lá»‡nh gá»i cÃ´ng cá»¥, cÃ´ng cá»¥ sáº½ thá»±c thi vÃ  tráº£ vá» káº¿t quáº£. Trá»£ lÃ½ sau Ä‘Ã³ cÃ³ thá»ƒ xá»­ lÃ½ káº¿t quáº£ nÃ y vÃ  tiáº¿p tá»¥c cuá»™c há»™i thoáº¡i má»™t cÃ¡ch phÃ¹ há»£p.

ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ Ä‘Æ¡n giáº£n vá» tÆ°Æ¡ng tÃ¡c gá»i cÃ´ng cá»¥:

```python
messages = [
Â  Â  {"role": "user", "content": "Turn on the living room lights."},
Â  Â  {"role": "assistant", "tool_calls": [
Â  Â  Â  Â  {"type": "function", "function": {
Â  Â  Â  Â  Â  Â  "name": "control_light",
Â  Â  Â  Â  Â  Â  "arguments": {"room": "living room", "state": "on"}
Â  Â  Â  Â  }}]
Â  Â  },
Â  Â  {"role": "tool", "name": "control_light", "content": "The lights in the living room are now on."},
Â  Â  {"role": "assistant", "content": "Done!"}
]
```

Khi chuáº©n bá»‹ `dataset` cho Supervised Fine-Tuning (`SFT`) vá»›i `tool calling`, Ä‘iá»u quan trá»ng lÃ  `dataset` cá»§a báº¡n pháº£i bao gá»“m má»™t cá»™t bá»• sung cÃ³ tÃªn lÃ  `tools`. Cá»™t nÃ y chá»©a danh sÃ¡ch cÃ¡c cÃ´ng cá»¥ cÃ³ sáºµn cho mÃ´ hÃ¬nh, thÆ°á»ng Ä‘Æ°á»£c `chat template` sá»­ dá»¥ng Ä‘á»ƒ xÃ¢y dá»±ng `system prompt`.

CÃ¡c cÃ´ng cá»¥ pháº£i Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh á»Ÿ Ä‘á»‹nh dáº¡ng `JSON schema` Ä‘Ã£ Ä‘Æ°á»£c mÃ£ hÃ³a. Báº¡n cÃ³ thá»ƒ tá»± Ä‘á»™ng táº¡o `schema` nÃ y tá»« chá»¯ kÃ½ hÃ m Python báº±ng cÃ¡ch sá»­ dá»¥ng tiá»‡n Ã­ch [`~transformers.utils.get_json_schema`]:

```python
from transformers.utils import get_json_schema

def control_light(room: str, state: str) -> str:
Â  Â  """
Â  Â  Controls the lights in a room.

Â  Â  Args:
Â  Â  Â  Â  room: The name of the room.
Â  Â  Â  Â  state: The desired state of the light ("on" or "off").

Â  Â  Returns:
Â  Â  Â  Â  str: A message indicating the new state of the lights.
Â  Â  """
Â  Â  return f"The lights in {room} are now {state}."

# Generate JSON schema
json_schema = get_json_schema(control_light)
```

`Schema` Ä‘Æ°á»£c táº¡o ra sáº½ trÃ´ng nhÆ° sau:

```python
{
Â  Â  "type": "function",
Â  Â  "function": {
Â  Â  Â  Â  "name": "control_light",
Â  Â  Â  Â  "description": "Controls the lights in a room.",
Â  Â  Â  Â  "parameters": {
Â  Â  Â  Â  Â  Â  "type": "object",
Â  Â  Â  Â  Â  Â  "properties": {
Â  Â  Â  Â  Â  Â  Â  Â  "room": {"type": "string", "description": "The name of the room."},
Â  Â  Â  Â  Â  Â  Â  Â  "state": {"type": "string", "description": 'The desired state of the light ("on" or "off").'},
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  "required": ["room", "state"],
Â  Â  Â  Â  },
Â  Â  Â  Â  "return": {"type": "string", "description": "str: A message indicating the new state of the lights."},
Â  Â  },
}
```

Má»™t má»¥c `dataset` hoÃ n chá»‰nh cho `SFT` cÃ³ thá»ƒ trÃ´ng nhÆ° sau:

```python
{"messages": messages, "tools": [json_schema]}
```

Äá»ƒ biáº¿t thÃªm thÃ´ng tin chi tiáº¿t vá» `tool calling`, hÃ£y tham kháº£o [má»¥c Tool Calling trong tÃ i liá»‡u cá»§a `transformers`](https://www.google.com/search?q=%5Bhttps://huggingface.co/docs/transformers/chat_extras%23tools-and-rag%5D\(https://huggingface.co/docs/transformers/chat_extras%23tools-and-rag\)) vÃ  bÃ i Ä‘Äƒng blog [Tool Use, Unified](https://huggingface.co/blog/unified-tool-use).

### CÃ¡c loáº¡i

#### MÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ (Language modeling)

Má»™t `dataset` mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ bao gá»“m má»™t cá»™t `"text"` (hoáº·c `"messages"` cho cÃ¡c `dataset` há»™i thoáº¡i) chá»©a má»™t chuá»—i vÄƒn báº£n hoÃ n chá»‰nh.

```python
# Äá»‹nh dáº¡ng standard
language_modeling_example = {"text": "The sky is blue."}
# Äá»‹nh dáº¡ng conversational
language_modeling_example = {"messages": [
Â  Â  {"role": "user", "content": "What color is the sky?"},
Â  Â  {"role": "assistant", "content": "It is blue."}
]}
```

#### Chá»‰ cÃ³ prompt (Prompt-only)

Trong má»™t `dataset` chá»‰ cÃ³ `prompt`, chá»‰ cÃ³ `prompt` ban Ä‘áº§u (cÃ¢u há»i hoáº·c cÃ¢u chÆ°a hoÃ n chá»‰nh) Ä‘Æ°á»£c cung cáº¥p dÆ°á»›i khÃ³a `"prompt"`. QuÃ¡ trÃ¬nh huáº¥n luyá»‡n thÆ°á»ng bao gá»“m viá»‡c táº¡o ra `completion` dá»±a trÃªn `prompt` nÃ y, nÆ¡i mÃ´ hÃ¬nh há»c cÃ¡ch tiáº¿p tá»¥c hoáº·c hoÃ n thÃ nh Ä‘áº§u vÃ o Ä‘Ã£ cho.

```python
# Äá»‹nh dáº¡ng standard
prompt_only_example = {"prompt": "The sky is"}
# Äá»‹nh dáº¡ng conversational
prompt_only_example = {"prompt": [{"role": "user", "content": "What color is the sky?"}]}
```

Äá»ƒ xem cÃ¡c vÃ­ dá»¥ vá» `dataset` chá»‰ cÃ³ `prompt`, hÃ£y tham kháº£o [bá»™ sÆ°u táº­p Prompt-only datasets](https://huggingface.co/collections/trl-lib/prompt-only-datasets-677ea25245d20252cea00368).

\<Tip\>

Máº·c dÃ¹ cáº£ hai loáº¡i `prompt-only` vÃ  `language modeling` Ä‘á»u tÆ°Æ¡ng tá»± nhau, chÃºng khÃ¡c nhau á»Ÿ cÃ¡ch xá»­ lÃ½ Ä‘áº§u vÃ o. Trong loáº¡i `prompt-only`, `prompt` Ä‘áº¡i diá»‡n cho má»™t Ä‘áº§u vÃ o chÆ°a hoÃ n chá»‰nh mÃ  mong Ä‘á»£i mÃ´ hÃ¬nh sáº½ hoÃ n thÃ nh hoáº·c tiáº¿p tá»¥c, trong khi á»Ÿ loáº¡i `language modeling`, Ä‘áº§u vÃ o Ä‘Æ°á»£c coi lÃ  má»™t cÃ¢u hoáº·c chuá»—i hoÃ n chá»‰nh. Hai loáº¡i nÃ y Ä‘Æ°á»£c `TRL` xá»­ lÃ½ khÃ¡c nhau. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t vÃ­ dá»¥ cho tháº¥y sá»± khÃ¡c biá»‡t trong Ä‘áº§u ra cá»§a hÃ m `apply_chat_template` cho má»—i loáº¡i:

```python
from transformers import AutoTokenizer
from trl import apply_chat_template

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-128k-instruct")

# VÃ­ dá»¥ cho loáº¡i prompt-only
prompt_only_example = {"prompt": [{"role": "user", "content": "What color is the sky?"}]}
apply_chat_template(prompt_only_example, tokenizer)
# Äáº§u ra: {'prompt': '<|user|>\nWhat color is the sky?<|end|>\n<|assistant|>\n'}

# VÃ­ dá»¥ cho loáº¡i language modeling
lm_example = {"messages": [{"role": "user", "content": "What color is the sky?"}]}
apply_chat_template(lm_example, tokenizer)
# Äáº§u ra: {'text': '<|user|>\nWhat color is the sky?<|end|>\n<|endoftext|>'}
```

  - Äáº§u ra cá»§a `prompt-only` bao gá»“m má»™t `'<|assistant|>\n'`, cho biáº¿t sá»± báº¯t Ä‘áº§u lÆ°á»£t cá»§a trá»£ lÃ½ vÃ  mong Ä‘á»£i mÃ´ hÃ¬nh táº¡o ra má»™t `completion`.
  - NgÆ°á»£c láº¡i, Ä‘áº§u ra cá»§a `language modeling` coi Ä‘áº§u vÃ o lÃ  má»™t chuá»—i hoÃ n chá»‰nh vÃ  káº¿t thÃºc nÃ³ báº±ng `'<|endoftext|>'`, bÃ¡o hiá»‡u sá»± káº¿t thÃºc cá»§a vÄƒn báº£n vÃ  khÃ´ng mong Ä‘á»£i báº¥t ká»³ ná»™i dung bá»• sung nÃ o.

\</Tip\>

#### Prompt vÃ  completion (Prompt-completion)

Má»™t `dataset` `prompt-completion` bao gá»“m má»™t `"prompt"` vÃ  má»™t `"completion"`.

```python
# Äá»‹nh dáº¡ng standard
prompt_completion_example = {"prompt": "The sky is", "completion": " blue."}
# Äá»‹nh dáº¡ng conversational
prompt_completion_example = {"prompt": [{"role": "user", "content": "What color is the sky?"}],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "completion": [{"role": "assistant", "content": "It is blue."}]}
```

Äá»ƒ xem cÃ¡c vÃ­ dá»¥ vá» `dataset` `prompt-completion`, hÃ£y tham kháº£o [bá»™ sÆ°u táº­p Prompt-completion datasets](https://huggingface.co/collections/trl-lib/prompt-completion-datasets-677ea2bb20bbb6bdccada216).

#### Sá»Ÿ thÃ­ch (Preference)

Má»™t `dataset` sá»Ÿ thÃ­ch (`preference`) Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c tÃ¡c vá»¥ mÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ chá»n giá»¯a hai hoáº·c nhiá»u `completion` cÃ³ thá»ƒ cÃ³ cho cÃ¹ng má»™t `prompt`. `Dataset` nÃ y bao gá»“m má»™t `"prompt"`, má»™t `completion` `"chosen"` (Ä‘Æ°á»£c chá»n), vÃ  má»™t `completion` `"rejected"` (bá»‹ tá»« chá»‘i). MÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ chá»n cÃ¢u tráº£ lá»i `"chosen"` thay vÃ¬ cÃ¢u tráº£ lá»i `"rejected"`.
Má»™t sá»‘ `dataset` cÃ³ thá»ƒ khÃ´ng bao gá»“m cá»™t `"prompt"`, trong trÆ°á»ng há»£p Ä‘Ã³ `prompt` lÃ  ngáº§m Ä‘á»‹nh vÃ  Ä‘Æ°á»£c bao gá»“m trá»±c tiáº¿p trong cÃ¡c `completion` `"chosen"` vÃ  `"rejected"`. ChÃºng tÃ´i khuyÃªn báº¡n nÃªn sá»­ dá»¥ng `prompt` tÆ°á»ng minh báº¥t cá»© khi nÃ o cÃ³ thá»ƒ.

```python
# Äá»‹nh dáº¡ng standard
## Prompt tÆ°á»ng minh (khuyáº¿n nghá»‹)
preference_example = {"prompt": "The sky is", "chosen": " blue.", "rejected": " green."}
# Prompt ngáº§m Ä‘á»‹nh
preference_example = {"chosen": "The sky is blue.", "rejected": "The sky is green."}

# Äá»‹nh dáº¡ng conversational
## Prompt tÆ°á»ng minh (khuyáº¿n nghá»‹)
preference_example = {"prompt": [{"role": "user", "content": "What color is the sky?"}],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "chosen": [{"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rejected": [{"role": "assistant", "content": "It is green."}]}
## Prompt ngáº§m Ä‘á»‹nh
preference_example = {"chosen": [{"role": "user", "content": "What color is the sky?"},
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â {"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rejected": [{"role": "user", "content": "What color is the sky?"},
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â {"role": "assistant", "content": "It is green."}]}
```

Äá»ƒ xem cÃ¡c vÃ­ dá»¥ vá» `dataset` sá»Ÿ thÃ­ch, hÃ£y tham kháº£o [bá»™ sÆ°u táº­p Preference datasets](https://huggingface.co/collections/trl-lib/preference-datasets-677e99b581018fcad9abd82c).

Má»™t sá»‘ `dataset` sá»Ÿ thÃ­ch cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y vá»›i [tháº» `dpo` trÃªn Hugging Face Hub](https://www.google.com/search?q=%5Bhttps://huggingface.co/datasets%3Fother%3Ddpo%5D\(https://huggingface.co/datasets%3Fother%3Ddpo\)). Báº¡n cÅ©ng cÃ³ thá»ƒ khÃ¡m phÃ¡ [DPO Collections cá»§a librarian-bots](https://huggingface.co/collections/librarian-bots/direct-preference-optimization-datasets-66964b12835f46289b6ef2fc) Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c `dataset` sá»Ÿ thÃ­ch.

#### Sá»Ÿ thÃ­ch khÃ´ng theo cáº·p (Unpaired preference)

Má»™t `dataset` sá»Ÿ thÃ­ch khÃ´ng theo cáº·p (`unpaired preference`) tÆ°Æ¡ng tá»± nhÆ° má»™t `dataset` sá»Ÿ thÃ­ch nhÆ°ng thay vÃ¬ cÃ³ cÃ¡c `completion` `"chosen"` vÃ  `"rejected"` cho cÃ¹ng má»™t `prompt`, nÃ³ bao gá»“m má»™t `"completion"` duy nháº¥t vÃ  má»™t `"label"` cho biáº¿t `completion` Ä‘Ã³ cÃ³ Ä‘Æ°á»£c Æ°a thÃ­ch hay khÃ´ng.

```python
# Äá»‹nh dáº¡ng standard
unpaired_preference_example = {"prompt": "The sky is", "completion": " blue.", "label": True}
# Äá»‹nh dáº¡ng conversational
unpaired_preference_example = {"prompt": [{"role": "user", "content": "What color is the sky?"}],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "completion": [{"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "label": True}
```

Äá»ƒ xem cÃ¡c vÃ­ dá»¥ vá» `dataset` sá»Ÿ thÃ­ch khÃ´ng theo cáº·p, hÃ£y tham kháº£o [bá»™ sÆ°u táº­p Unpaired preference datasets](https://huggingface.co/collections/trl-lib/unpaired-preference-datasets-677ea22bf5f528c125b0bcdf).

#### GiÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c (Stepwise supervision)

Má»™t `dataset` giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c (hoáº·c quy trÃ¬nh) tÆ°Æ¡ng tá»± nhÆ° má»™t `dataset` [sá»Ÿ thÃ­ch khÃ´ng theo cáº·p](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-unpaired-preference) nhÆ°ng bao gá»“m nhiá»u bÆ°á»›c cá»§a `completion`, má»—i bÆ°á»›c cÃ³ nhÃ£n riÃªng. Cáº¥u trÃºc nÃ y há»¯u Ã­ch cho cÃ¡c tÃ¡c vá»¥ cáº§n ghi nhÃ£n chi tiáº¿t, tá»«ng bÆ°á»›c, cháº³ng háº¡n nhÆ° cÃ¡c tÃ¡c vá»¥ suy luáº­n. Báº±ng cÃ¡ch Ä‘Ã¡nh giÃ¡ tá»«ng bÆ°á»›c riÃªng biá»‡t vÃ  cung cáº¥p cÃ¡c nhÃ£n má»¥c tiÃªu, phÆ°Æ¡ng phÃ¡p nÃ y giÃºp xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c nÆ¡i suy luáº­n Ä‘Ãºng vÃ  nÆ¡i xáº£y ra lá»—i, cho phÃ©p pháº£n há»“i cÃ³ má»¥c tiÃªu trÃªn tá»«ng pháº§n cá»§a quÃ¡ trÃ¬nh suy luáº­n.

```python
stepwise_example = {
Â  Â  "prompt": "Which number is larger, 9.8 or 9.11?",
Â  Â  "completions": ["The fractional part of 9.8 is 0.8, while the fractional part of 9.11 is 0.11.", "Since 0.11 is greater than 0.8, the number 9.11 is larger than 9.8."],
Â  Â  "labels": [True, False]
}
```

Äá»ƒ xem cÃ¡c vÃ­ dá»¥ vá» `dataset` giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c, hÃ£y tham kháº£o [bá»™ sÆ°u táº­p Stepwise supervision datasets](https://huggingface.co/collections/trl-lib/stepwise-supervision-datasets-677ea27fd4c5941beed7a96e).

## NÃªn sá»­ dá»¥ng loáº¡i dataset nÃ o?

Viá»‡c chá»n Ä‘Ãºng loáº¡i `dataset` phá»¥ thuá»™c vÃ o tÃ¡c vá»¥ báº¡n Ä‘ang thá»±c hiá»‡n vÃ  cÃ¡c yÃªu cáº§u cá»¥ thá»ƒ cá»§a `trainer` `TRL` báº¡n Ä‘ang sá»­ dá»¥ng. DÆ°á»›i Ä‘Ã¢y lÃ  tá»•ng quan ngáº¯n gá»n vá» cÃ¡c loáº¡i `dataset` Ä‘Æ°á»£c há»— trá»£ bá»Ÿi má»—i `trainer` `TRL`.

| TrainerÂ  Â  Â  Â  Â  Â  Â  Â  Â | Loáº¡i dataset mong Ä‘á»£iÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| ----------------------- | ------------------------------------------------------------------------------------------------------ |
| [`BCOTrainer`]Â  Â  Â  Â  Â  | [Sá»Ÿ thÃ­ch khÃ´ng theo cáº·p](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-unpaired-preference)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`CPOTrainer`]Â  Â  Â  Â  Â  | [Sá»Ÿ thÃ­ch (khuyáº¿n nghá»‹ prompt tÆ°á»ng minh)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`DPOTrainer`]Â  Â  Â  Â  Â  | [Sá»Ÿ thÃ­ch (khuyáº¿n nghá»‹ prompt tÆ°á»ng minh)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`GKDTrainer`]Â  Â  Â  Â  Â  | [Prompt vÃ  completion](https://www.google.com/search?q=%23prompt-v%C3%A0-completion-prompt-completion)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`GRPOTrainer`]Â  Â  Â  Â  Â | [Chá»‰ cÃ³ prompt](https://www.google.com/search?q=%23ch%E1%BB%89-c%C3%B3-prompt-prompt-only)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`IterativeSFTTrainer`] | [Sá»Ÿ thÃ­ch khÃ´ng theo cáº·p](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-unpaired-preference)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`KTOTrainer`]Â  Â  Â  Â  Â  | [Sá»Ÿ thÃ­ch khÃ´ng theo cáº·p](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-unpaired-preference) hoáº·c [Sá»Ÿ thÃ­ch (khuyáº¿n nghá»‹ prompt tÆ°á»ng minh)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference) |
| [`NashMDTrainer`]Â  Â  Â  Â | [Chá»‰ cÃ³ prompt](https://www.google.com/search?q=%23ch%E1%BB%89-c%C3%B3-prompt-prompt-only)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`OnlineDPOTrainer`]Â  Â  | [Chá»‰ cÃ³ prompt](https://www.google.com/search?q=%23ch%E1%BB%89-c%C3%B3-prompt-prompt-only)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`ORPOTrainer`]Â  Â  Â  Â  Â | [Sá»Ÿ thÃ­ch (khuyáº¿n nghá»‹ prompt tÆ°á»ng minh)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`PPOTrainer`]Â  Â  Â  Â  Â  | MÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ Ä‘Ã£ Ä‘Æ°á»£c token hÃ³a (`Tokenized language modeling`)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`PRMTrainer`]Â  Â  Â  Â  Â  | [GiÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c](https://www.google.com/search?q=%23gi%C3%A1m-s%C3%A1t-theo-t%E1%BB%ABng-b%C6%B0%E1%BB%9Bc-stepwise-supervision)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`RewardTrainer`]Â  Â  Â  Â | [Sá»Ÿ thÃ­ch (khuyáº¿n nghá»‹ prompt ngáº§m Ä‘á»‹nh)](https://www.google.com/search?q=%23s%E1%BB%9F-th%C3%ADch-preference)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| [`SFTTrainer`]Â  Â  Â  Â  Â  | [MÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯](https://www.google.com/search?q=%23m%C3%B4-h%C3%ACnh-h%C3%B3a-ng%C3%B4n-ng%E1%BB%AF-language-modeling) hoáº·c [Prompt vÃ  completion](https://www.google.com/search?q=%23prompt-v%C3%A0-completion-prompt-completion)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â |
| [`XPOTrainer`]Â  Â  Â  Â  Â  | [Chá»‰ cÃ³ prompt](https://www.google.com/search?q=%23ch%E1%BB%89-c%C3%B3-prompt-prompt-only)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |

\<Tip\>

CÃ¡c `trainer` cá»§a `TRL` chá»‰ há»— trá»£ cÃ¡c Ä‘á»‹nh dáº¡ng `dataset` tiÃªu chuáº©n, [tÃ­nh Ä‘áº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i](https://github.com/huggingface/trl/issues/2071). Náº¿u báº¡n cÃ³ má»™t `dataset` há»™i thoáº¡i, trÆ°á»›c tiÃªn báº¡n pháº£i chuyá»ƒn Ä‘á»•i nÃ³ sang Ä‘á»‹nh dáº¡ng tiÃªu chuáº©n.
Äá»ƒ biáº¿t thÃªm thÃ´ng tin vá» cÃ¡ch lÃ m viá»‡c vá»›i `dataset` há»™i thoáº¡i, hÃ£y tham kháº£o pháº§n [LÃ m viá»‡c vá»›i dataset há»™i thoáº¡i trong TRL](https://www.google.com/search?q=%23l%C3%A0m-vi%E1%BB%87c-v%E1%BB%9Bi-dataset-h%E1%BB%99i-tho%E1%BA%A1i-trong-trl).

\</Tip\>

## LÃ m viá»‡c vá»›i dataset há»™i thoáº¡i trong TRL

CÃ¡c `dataset` há»™i thoáº¡i ngÃ y cÃ ng phá»• biáº¿n, Ä‘áº·c biá»‡t lÃ  Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh trÃ² chuyá»‡n (`chat models`). Tuy nhiÃªn, má»™t sá»‘ `trainer` cá»§a `TRL` khÃ´ng há»— trá»£ `dataset` há»™i thoáº¡i á»Ÿ Ä‘á»‹nh dáº¡ng thÃ´ cá»§a chÃºng. (Äá»ƒ biáº¿t thÃªm thÃ´ng tin, xem [issue \#2071](https://github.com/huggingface/trl/issues/2071).) CÃ¡c `dataset` nÃ y trÆ°á»›c tiÃªn pháº£i Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i sang Ä‘á»‹nh dáº¡ng tiÃªu chuáº©n.
May máº¯n thay, `TRL` cung cáº¥p cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ dá»… dÃ ng xá»­ lÃ½ viá»‡c chuyá»ƒn Ä‘á»•i nÃ y, Ä‘Æ°á»£c trÃ¬nh bÃ y chi tiáº¿t dÆ°á»›i Ä‘Ã¢y.

### Chuyá»ƒn Ä‘á»•i má»™t dataset há»™i thoáº¡i thÃ nh má»™t dataset tiÃªu chuáº©n

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` há»™i thoáº¡i thÃ nh má»™t `dataset` tiÃªu chuáº©n, báº¡n cáº§n *Ã¡p dá»¥ng má»™t chat template* cho `dataset`. Má»™t `chat template` lÃ  má»™t cáº¥u trÃºc Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c thÆ°á»ng bao gá»“m cÃ¡c trÃ¬nh giá»¯ chá»— cho tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng vÃ  trá»£ lÃ½. `Template` nÃ y Ä‘Æ°á»£c cung cáº¥p bá»Ÿi `tokenizer` cá»§a mÃ´ hÃ¬nh báº¡n sá»­ dá»¥ng.

Äá»ƒ biáº¿t hÆ°á»›ng dáº«n chi tiáº¿t vá» cÃ¡ch sá»­ dá»¥ng `chat templating`, hÃ£y tham kháº£o [má»¥c Chat templating trong tÃ i liá»‡u cá»§a `transformers`](https://www.google.com/search?q=%5Bhttps://huggingface.co/docs/transformers/en/chat_templating%5D\(https://huggingface.co/docs/transformers/en/chat_templating\)).

Trong `TRL`, phÆ°Æ¡ng thá»©c báº¡n Ã¡p dá»¥ng Ä‘á»ƒ chuyá»ƒn Ä‘á»•i `dataset` sáº½ thay Ä‘á»•i tÃ¹y thuá»™c vÃ o tÃ¡c vá»¥. May máº¯n thay, `TRL` cung cáº¥p má»™t hÃ m trá»£ giÃºp cÃ³ tÃªn lÃ  [`apply_chat_template`] Ä‘á»ƒ Ä‘Æ¡n giáº£n hÃ³a quÃ¡ trÃ¬nh nÃ y. ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ vá» cÃ¡ch sá»­ dá»¥ng nÃ³:

```python
from transformers import AutoTokenizer
from trl import apply_chat_template

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-128k-instruct")

example = {
Â  Â  "prompt": [{"role": "user", "content": "What color is the sky?"}],
Â  Â  "completion": [{"role": "assistant", "content": "It is blue."}]
}

apply_chat_template(example, tokenizer)
# Äáº§u ra:
# {'prompt': '<|user|>\nWhat color is the sky?<|end|>\n<|assistant|>\n', 'completion': 'It is blue.<|end|>\n<|endoftext|>'}
```

NgoÃ i ra, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng phÆ°Æ¡ng thá»©c [`~datasets.Dataset.map`] Ä‘á»ƒ Ã¡p dá»¥ng `template` trÃªn toÃ n bá»™ `dataset`:

```python
from datasets import Dataset
from trl import apply_chat_template

dataset_dict = {
Â  Â  "prompt": [[{"role": "user", "content": "What color is the sky?"}],
Â  Â  Â  Â  Â  Â  Â  Â [{"role": "user", "content": "Where is the sun?"}]],
Â  Â  "completion": [[{"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â [{"role": "assistant", "content": "In the sky."}]]
}

dataset = Dataset.from_dict(dataset_dict)
dataset = dataset.map(apply_chat_template, fn_kwargs={"tokenizer": tokenizer})
# Äáº§u ra:
# {'prompt': ['<|user|>\nWhat color is the sky?<|end|>\n<|assistant|>\n',
#Â  Â  Â  Â  Â  Â  Â '<|user|>\nWhere is the sun?<|end|>\n<|assistant|>\n'],
#Â  'completion': ['It is blue.<|end|>\n<|endoftext|>', 'In the sky.<|end|>\n<|endoftext|>']}
```

\<Tip warning={true}\>

ChÃºng tÃ´i khuyÃªn báº¡n nÃªn sá»­ dá»¥ng hÃ m [`apply_chat_template`] thay vÃ¬ gá»i trá»±c tiáº¿p `tokenizer.apply_chat_template`. Viá»‡c xá»­ lÃ½ cÃ¡c `chat template` cho cÃ¡c `dataset` khÃ´ng pháº£i lÃ  `language modeling` cÃ³ thá»ƒ phá»©c táº¡p vÃ  cÃ³ thá»ƒ dáº«n Ä‘áº¿n lá»—i, cháº³ng háº¡n nhÆ° Ä‘áº·t nháº§m `system prompt` vÃ o giá»¯a má»™t cuá»™c há»™i thoáº¡i.
Äá»ƒ biáº¿t thÃªm vÃ­ dá»¥, xem [\#1930 (comment)](https://github.com/huggingface/trl/pull/1930#issuecomment-2292908614). HÃ m [`apply_chat_template`] Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ nhá»¯ng sá»± phá»©c táº¡p nÃ y vÃ  Ä‘áº£m báº£o Ã¡p dá»¥ng Ä‘Ãºng cÃ¡c `chat template` cho cÃ¡c tÃ¡c vá»¥ khÃ¡c nhau.

\</Tip\>

\<Tip warning={true}\>

Äiá»u quan trá»ng cáº§n lÆ°u Ã½ lÃ  cÃ¡c `chat template` lÃ  Ä‘áº·c trÆ°ng cho tá»«ng mÃ´ hÃ¬nh. VÃ­ dá»¥, náº¿u báº¡n sá»­ dá»¥ng `chat template` tá»« [meta-llama/Meta-Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct) vá»›i vÃ­ dá»¥ trÃªn, báº¡n sáº½ nháº­n Ä‘Æ°á»£c má»™t Ä‘áº§u ra khÃ¡c:

```python
apply_chat_template(example, AutoTokenizer.from_pretrained("meta-llama/Meta-Llama-3.1-8B-Instruct"))
# Äáº§u ra:
# {'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWhat color is the sky?<|im_end|>\n<|im_start|>assistant\n',
#Â  'completion': 'It is blue.<|im_end|>\n'}
```

LuÃ´n sá»­ dá»¥ng `chat template` Ä‘Æ°á»£c liÃªn káº¿t vá»›i mÃ´ hÃ¬nh báº¡n Ä‘ang lÃ m viá»‡c. Sá»­ dá»¥ng sai `template` cÃ³ thá»ƒ dáº«n Ä‘áº¿n káº¿t quáº£ khÃ´ng chÃ­nh xÃ¡c hoáº·c khÃ´ng mong muá»‘n.

\</Tip\>

## Sá»­ dá»¥ng báº¥t ká»³ dataset nÃ o vá»›i TRL: tiá»n xá»­ lÃ½ vÃ  chuyá»ƒn Ä‘á»•i

Nhiá»u `dataset` cÃ³ Ä‘á»‹nh dáº¡ng Ä‘Æ°á»£c thiáº¿t káº¿ riÃªng cho cÃ¡c tÃ¡c vá»¥ cá»¥ thá»ƒ, cÃ³ thá»ƒ khÃ´ng tÆ°Æ¡ng thÃ­ch trá»±c tiáº¿p vá»›i `TRL`. Äá»ƒ sá»­ dá»¥ng cÃ¡c `dataset` nhÆ° váº­y vá»›i `TRL`, báº¡n cÃ³ thá»ƒ cáº§n pháº£i tiá»n xá»­ lÃ½ vÃ  chuyá»ƒn Ä‘á»•i chÃºng sang Ä‘á»‹nh dáº¡ng báº¯t buá»™c.

Äá»ƒ lÃ m Ä‘iá»u nÃ y dá»… dÃ ng hÆ¡n, chÃºng tÃ´i cung cáº¥p má»™t bá»™ [script vÃ­ dá»¥](https://github.com/huggingface/trl/tree/main/examples/datasets) bao gá»“m cÃ¡c chuyá»ƒn Ä‘á»•i `dataset` phá»• biáº¿n.

### VÃ­ dá»¥: Dataset UltraFeedback

HÃ£y láº¥y [dataset UltraFeedback](https://huggingface.co/datasets/openbmb/UltraFeedback) lÃ m vÃ­ dá»¥. DÆ°á»›i Ä‘Ã¢y lÃ  báº£n xem trÆ°á»›c cá»§a `dataset`:

\<iframe
Â  src="[https://huggingface.co/datasets/openbmb/UltraFeedback/embed/viewer/default/train](https://huggingface.co/datasets/openbmb/UltraFeedback/embed/viewer/default/train)"
Â  frameborder="0"
Â  width="100%"
Â  height="560px"
\>\</iframe\>

NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ á»Ÿ trÃªn, Ä‘á»‹nh dáº¡ng `dataset` khÃ´ng khá»›p vá»›i cáº¥u trÃºc mong Ä‘á»£i. NÃ³ khÃ´ng á»Ÿ Ä‘á»‹nh dáº¡ng há»™i thoáº¡i, tÃªn cá»™t khÃ¡c nhau vÃ  káº¿t quáº£ liÃªn quan Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau (vÃ­ dá»¥: Bard, GPT-4) vÃ  cÃ¡c khÃ­a cáº¡nh (vÃ­ dá»¥: "helpfulness", "honesty").

Báº±ng cÃ¡ch sá»­ dá»¥ng script chuyá»ƒn Ä‘á»•i Ä‘Æ°á»£c cung cáº¥p [`examples/datasets/ultrafeedback.py`](https://www.google.com/search?q=%5Bhttps://github.com/huggingface/trl/tree/main/examples/datasets/ultrafeedback.py%5D\(https://github.com/huggingface/trl/tree/main/examples/datasets/ultrafeedback.py\)), báº¡n cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i `dataset` nÃ y thÃ nh loáº¡i sá»Ÿ thÃ­ch khÃ´ng theo cáº·p (`unpaired preference`), vÃ  Ä‘áº©y nÃ³ lÃªn Hub:

```sh
python examples/datasets/ultrafeedback.py --push_to_hub --repo_id trl-lib/ultrafeedback-gpt-3.5-turbo-helpfulness
```

Sau khi chuyá»ƒn Ä‘á»•i, `dataset` sáº½ trÃ´ng nhÆ° tháº¿ nÃ y:

\<iframe
Â  src="[https://huggingface.co/datasets/trl-lib/ultrafeedback-gpt-3.5-turbo-helpfulness/embed/viewer/default/train?row=0](https://huggingface.co/datasets/trl-lib/ultrafeedback-gpt-3.5-turbo-helpfulness/embed/viewer/default/train?row=0)"
Â  frameborder="0"
Â  width="100%"
Â  height="560px"
\>\</iframe\>

BÃ¢y giá», báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng `dataset` nÃ y vá»›i `TRL`\!

Báº±ng cÃ¡ch Ä‘iá»u chá»‰nh cÃ¡c script Ä‘Æ°á»£c cung cáº¥p hoáº·c táº¡o script cá»§a riÃªng báº¡n, báº¡n cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i báº¥t ká»³ `dataset` nÃ o thÃ nh má»™t Ä‘á»‹nh dáº¡ng tÆ°Æ¡ng thÃ­ch vá»›i `TRL`.

## CÃ¡c tiá»‡n Ã­ch Ä‘á»ƒ chuyá»ƒn Ä‘á»•i cÃ¡c loáº¡i dataset

Pháº§n nÃ y cung cáº¥p mÃ£ vÃ­ dá»¥ Ä‘á»ƒ giÃºp báº¡n chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c loáº¡i `dataset` khÃ¡c nhau. Máº·c dÃ¹ má»™t sá»‘ chuyá»ƒn Ä‘á»•i cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n sau khi Ã¡p dá»¥ng `chat template` (tá»©c lÃ  á»Ÿ Ä‘á»‹nh dáº¡ng `standard`), chÃºng tÃ´i khuyÃªn báº¡n nÃªn thá»±c hiá»‡n chuyá»ƒn Ä‘á»•i trÆ°á»›c khi Ã¡p dá»¥ng `chat template` Ä‘á»ƒ Ä‘áº£m báº£o nÃ³ hoáº¡t Ä‘á»™ng nháº¥t quÃ¡n.

Äá»ƒ Ä‘Æ¡n giáº£n, má»™t sá»‘ vÃ­ dá»¥ dÆ°á»›i Ä‘Ã¢y khÃ´ng tuÃ¢n theo khuyáº¿n nghá»‹ nÃ y vÃ  sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng `standard`. Tuy nhiÃªn, cÃ¡c chuyá»ƒn Ä‘á»•i cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng trá»±c tiáº¿p cho Ä‘á»‹nh dáº¡ng há»™i thoáº¡i mÃ  khÃ´ng cáº§n sá»­a Ä‘á»•i.

| Tá»« \\ Äáº¿nÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | MÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | Prompt-completionÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | Prompt-onlyÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | Sá»Ÿ thÃ­ch vá»›i prompt ngáº§m Ä‘á»‹nhÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | Sá»Ÿ thÃ­chÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | Sá»Ÿ thÃ­ch khÃ´ng theo cáº·pÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | GiÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c |
| ------------------------------- | ----------------------------------------------------------------------- | ----------------------------------------------------------------------- | ----------------------------------------------------------------- | --------------------------------------------------------- | --------------------------------------------------------- | ------------------------------------------------------------------------- | -------------------- |
| MÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  |
| Prompt-completionÂ  Â  Â  Â  Â  Â  Â  Â | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-prompt-completion-sang-language-modeling)Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-prompt-completion-sang-prompt-only)Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  |
| Prompt-onlyÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  |
| Sá»Ÿ thÃ­ch vá»›i prompt ngáº§m Ä‘á»‹nh | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-v%E1%BB%9Bi-prompt-ng%E1%BA%A7m-%C4%91%E1%BB%8Bnh-sang-language-modeling) | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-v%E1%BB%9Bi-prompt-ng%E1%BA%A7m-%C4%91%E1%BB%8Bnh-sang-prompt-completion) | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-v%E1%BB%9Bi-prompt-ng%E1%BA%A7m-%C4%91%E1%BB%8Bnh-sang-prompt-only) | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-v%E1%BB%9Bi-prompt-ng%E1%BA%A7m-%C4%91%E1%BB%8Bnh-sang-t%C6%B0%E1%BB%9Dng-minh) | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-v%E1%BB%9Bi-prompt-ng%E1%BA%A7m-%C4%91%E1%BB%8Bnh-sang-s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p) | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  |
| Sá»Ÿ thÃ­chÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-sang-language-modeling)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-sang-prompt-completion)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-sang-prompt-only)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-v%E1%BB%9Bi-prompt-t%C6%B0%E1%BB%9Dng-minh-sang-ng%E1%BA%A7m-%C4%91%E1%BB%8Bnh) | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-sang-s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p)Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  |
| Sá»Ÿ thÃ­ch khÃ´ng theo cáº·pÂ  Â  Â  Â  Â  Â  Â | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-sang-language-modeling)Â  Â  Â  Â  Â  Â  Â | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-sang-prompt-completion)Â  Â  Â  Â  Â  Â  Â | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p-sang-prompt-only)Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  |
| GiÃ¡m sÃ¡t theo tá»«ng bÆ°á»›cÂ  Â  Â  Â  Â  Â  | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-gi%C3%A1m-s%C3%A1t-theo-t%E1%BB%ABng-b%C6%B0%E1%BB%9Bc-sang-language-modeling)Â  Â  Â  Â  Â  Â  | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-gi%C3%A1m-s%C3%A1t-theo-t%E1%BB%ABng-b%C6%B0%E1%BB%9Bc-sang-prompt-completion)Â  Â  Â  Â  Â  Â  | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-gi%C3%A1m-s%C3%A1t-theo-t%E1%BB%ABng-b%C6%B0%E1%BB%9Bc-sang-prompt-only)Â  Â  Â  Â  Â  Â  | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | [ğŸ”—](https://www.google.com/search?q=%23t%E1%BB%AB-dataset-gi%C3%A1m-s%C3%A1t-theo-t%E1%BB%ABng-b%C6%B0%E1%BB%9Bc-sang-s%E1%BB%9F-th%C3%ADch-kh%C3%B4ng-theo-c%E1%BA%B7p)Â  Â  Â  Â  Â  Â  | N/AÂ  Â  Â  Â  Â  Â  Â  Â  Â  |

### Tá»« dataset prompt-completion sang language modeling

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` `prompt-completion` thÃ nh má»™t `dataset` `language modeling`, hÃ£y ná»‘i `prompt` vÃ  `completion`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["The sky is", "The sun is"],
Â  Â  "completion": [" blue.", " in the sky."],
})

def concat_prompt_completion(example):
Â  Â  return {"text": example["prompt"] + example["completion"]}

dataset = dataset.map(concat_prompt_completion, remove_columns=["prompt", "completion"])
```

```python
>>> dataset[0]
{'text': 'The sky is blue.'}
```

### Tá»« dataset prompt-completion sang prompt-only

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` `prompt-completion` thÃ nh má»™t `dataset` `prompt-only`, hÃ£y xÃ³a `completion`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["The sky is", "The sun is"],
Â  Â  "completion": [" blue.", " in the sky."],
})

dataset = dataset.remove_columns("completion")
```

```python
>>> dataset[0]
{'prompt': 'The sky is'}
```

### Tá»« dataset sá»Ÿ thÃ­ch vá»›i prompt ngáº§m Ä‘á»‹nh sang language modeling

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch vá»›i `prompt` ngáº§m Ä‘á»‹nh thÃ nh má»™t `dataset` `language modeling`, hÃ£y xÃ³a cá»™t `rejected` vÃ  Ä‘á»•i tÃªn cá»™t `"chosen"` thÃ nh `"text"`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "chosen": ["The sky is blue.", "The sun is in the sky."],
Â  Â  "rejected": ["The sky is green.", "The sun is in the sea."],
})

dataset = dataset.rename_column("chosen", "text").remove_columns("rejected")
```

```python
>>> dataset[0]
{'text': 'The sky is blue.'}
```

### Tá»« dataset sá»Ÿ thÃ­ch vá»›i prompt ngáº§m Ä‘á»‹nh sang prompt-completion

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch vá»›i `prompt` ngáº§m Ä‘á»‹nh thÃ nh má»™t `dataset` `prompt-completion`, hÃ£y trÃ­ch xuáº¥t `prompt` báº±ng [`extract_prompt`], xÃ³a cá»™t `rejected`, vÃ  Ä‘á»•i tÃªn cá»™t `"chosen"` thÃ nh `"completion"`.

```python
from datasets import Dataset
from trl import extract_prompt

dataset = Dataset.from_dict({
Â  Â  "chosen": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}, {"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}, {"role": "assistant", "content": "In the sky."}],
Â  Â  ],
Â  Â  "rejected": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}, {"role": "assistant", "content": "It is green."}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}, {"role": "assistant", "content": "In the sea."}],
Â  Â  ],
})
dataset = dataset.map(extract_prompt).remove_columns("rejected").rename_column("chosen", "completion")
```

```python
>>> dataset[0]
{'prompt': [{'role': 'user', 'content': 'What color is the sky?'}], 'completion': [{'role': 'assistant', 'content': 'It is blue.'}]}
```

### Tá»« dataset sá»Ÿ thÃ­ch vá»›i prompt ngáº§m Ä‘á»‹nh sang prompt-only

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch vá»›i `prompt` ngáº§m Ä‘á»‹nh thÃ nh má»™t `dataset` `prompt-only`, hÃ£y trÃ­ch xuáº¥t `prompt` báº±ng [`extract_prompt`], vÃ  xÃ³a cÃ¡c cá»™t `rejected` vÃ  `chosen`.

```python
from datasets import Dataset
from trl import extract_prompt

dataset = Dataset.from_dict({
Â  Â  "chosen": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}, {"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}, {"role": "assistant", "content": "In the sky."}],
Â  Â  ],
Â  Â  "rejected": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}, {"role": "assistant", "content": "It is green."}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}, {"role": "assistant", "content": "In the sea."}],
Â  Â  ],
})
dataset = dataset.map(extract_prompt).remove_columns(["chosen", "rejected"])
```

```python
>>> dataset[0]
{'prompt': [{'role': 'user', 'content': 'What color is the sky?'}]}
```

### Tá»« dataset sá»Ÿ thÃ­ch vá»›i prompt ngáº§m Ä‘á»‹nh sang tÆ°á»ng minh

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch vá»›i `prompt` ngáº§m Ä‘á»‹nh thÃ nh má»™t `dataset` sá»Ÿ thÃ­ch vá»›i `prompt` tÆ°á»ng minh, hÃ£y trÃ­ch xuáº¥t `prompt` báº±ng [`extract_prompt`].

```python
from datasets import Dataset
from trl import extract_prompt

dataset = Dataset.from_dict({
Â  Â  "chosen": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}, {"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}, {"role": "assistant", "content": "In the sky."}],
Â  Â  ],
Â  Â  "rejected": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}, {"role": "assistant", "content": "It is green."}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}, {"role": "assistant", "content": "In the sea."}],
Â  Â  ],
})

dataset = dataset.map(extract_prompt)
```

```python
>>> dataset[0]
{'prompt': [{'role': 'user', 'content': 'What color is the sky?'}],
Â 'chosen': [{'role': 'assistant', 'content': 'It is blue.'}],
Â 'rejected': [{'role': 'assistant', 'content': 'It is green.'}]}
```

### Tá»« dataset sá»Ÿ thÃ­ch vá»›i prompt ngáº§m Ä‘á»‹nh sang sá»Ÿ thÃ­ch khÃ´ng theo cáº·p

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch vá»›i `prompt` ngáº§m Ä‘á»‹nh thÃ nh má»™t `dataset` sá»Ÿ thÃ­ch khÃ´ng theo cáº·p, hÃ£y trÃ­ch xuáº¥t `prompt` báº±ng [`extract_prompt`], vÃ  tÃ¡ch cáº·p `dataset` báº±ng [`unpair_preference_dataset`].

```python
from datasets import Dataset
from trl import extract_prompt, unpair_preference_dataset

dataset = Dataset.from_dict({
Â  Â  "chosen": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}, {"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}, {"role": "assistant", "content": "In the sky."}],
Â  Â  ],
Â  Â  "rejected": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}, {"role": "assistant", "content": "It is green."}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}, {"role": "assistant", "content": "In the sea."}],
Â  Â  ],
})

dataset = dataset.map(extract_prompt)
dataset = unpair_preference_dataset(dataset)
```

```python
>>> dataset[0]
{'prompt': [{'role': 'user', 'content': 'What color is the sky?'}],
Â 'completion': [{'role': 'assistant', 'content': 'It is blue.'}],
Â 'label': True}
```

\<Tip warning={true}\>

HÃ£y nhá»› ráº±ng cÃ¡c `completion` `"chosen"` vÃ  `"rejected"` trong má»™t `dataset` sá»Ÿ thÃ­ch cÃ³ thá»ƒ lÃ  tá»‘t hoáº·c xáº¥u.
TrÆ°á»›c khi Ã¡p dá»¥ng [`unpair_preference_dataset`], hÃ£y Ä‘áº£m báº£o ráº±ng táº¥t cáº£ cÃ¡c `completion` `"chosen"` cÃ³ thá»ƒ Ä‘Æ°á»£c gÃ¡n nhÃ£n lÃ  tá»‘t vÃ  táº¥t cáº£ cÃ¡c `completion` `"rejected"` lÃ  xáº¥u.
Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘áº£m báº£o báº±ng cÃ¡ch kiá»ƒm tra Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ tuyá»‡t Ä‘á»‘i cá»§a má»—i `completion`, vÃ­ dá»¥ nhÆ° tá»« má»™t mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng (`reward model`).

\</Tip\>

### Tá»« dataset sá»Ÿ thÃ­ch sang language modeling

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch thÃ nh má»™t `dataset` `language modeling`, hÃ£y xÃ³a cá»™t `rejected`, ná»‘i `prompt` vÃ  `chosen` vÃ o cá»™t `"text"`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["The sky is", "The sun is"],
Â  Â  "chosen": [" blue.", " in the sky."],
Â  Â  "rejected": [" green.", " in the sea."],
})

def concat_prompt_chosen(example):
Â  Â  return {"text": example["prompt"] + example["chosen"]}

dataset = dataset.map(concat_prompt_chosen, remove_columns=["prompt", "chosen", "rejected"])
```

```python
>>> dataset[0]
{'text': 'The sky is blue.'}
```

### Tá»« dataset sá»Ÿ thÃ­ch sang prompt-completion

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch thÃ nh má»™t `dataset` `prompt-completion`, hÃ£y xÃ³a cá»™t `rejected`, vÃ  Ä‘á»•i tÃªn cá»™t `"chosen"` thÃ nh `"completion"`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["The sky is", "The sun is"],
Â  Â  "chosen": [" blue.", " in the sky."],
Â  Â  "rejected": [" green.", " in the sea."],
})

dataset = dataset.remove_columns("rejected").rename_column("chosen", "completion")
```

```python
>>> dataset[0]
{'prompt': 'The sky is', 'completion': ' blue.'}
```

### Tá»« dataset sá»Ÿ thÃ­ch sang prompt-only

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch thÃ nh má»™t `dataset` `prompt-only`, hÃ£y xÃ³a cÃ¡c cá»™t `rejected` vÃ  `chosen`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["The sky is", "The sun is"],
Â  Â  "chosen": [" blue.", " in the sky."],
Â  Â  "rejected": [" green.", " in the sea."],
})

dataset = dataset.remove_columns(["chosen", "rejected"])
```

```python
>>> dataset[0]
{'prompt': 'The sky is'}
```

### Tá»« dataset sá»Ÿ thÃ­ch vá»›i prompt tÆ°á»ng minh sang ngáº§m Ä‘á»‹nh

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch vá»›i `prompt` tÆ°á»ng minh thÃ nh má»™t `dataset` sá»Ÿ thÃ­ch vá»›i `prompt` ngáº§m Ä‘á»‹nh, hÃ£y ná»‘i `prompt` vÃ o cáº£ `chosen` vÃ  `rejected`, vÃ  xÃ³a cá»™t `prompt`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}],
Â  Â  ],
Â  Â  "chosen": [
Â  Â  Â  Â  [{"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  [{"role": "assistant", "content": "In the sky."}],
Â  Â  ],
Â  Â  "rejected": [
Â  Â  Â  Â  [{"role": "assistant", "content": "It is green."}],
Â  Â  Â  Â  [{"role": "assistant", "content": "In the sea."}],
Â  Â  ],
})

def concat_prompt_to_completions(example):
Â  Â  return {"chosen": example["prompt"] + example["chosen"], "rejected": example["prompt"] + example["rejected"]}

dataset = dataset.map(concat_prompt_to_completions, remove_columns="prompt")
```

```python
>>> dataset[0]
{'chosen': [{'role': 'user', 'content': 'What color is the sky?'}, {'role': 'assistant', 'content': 'It is blue.'}],
Â 'rejected': [{'role': 'user', 'content': 'What color is the sky?'}, {'role': 'assistant', 'content': 'It is green.'}]}
```

### Tá»« dataset sá»Ÿ thÃ­ch sang sá»Ÿ thÃ­ch khÃ´ng theo cáº·p

Äá»ƒ chuyá»ƒn Ä‘á»•i `dataset` thÃ nh má»™t `dataset` sá»Ÿ thÃ­ch khÃ´ng theo cáº·p, hÃ£y tÃ¡ch cáº·p `dataset` báº±ng [`unpair_preference_dataset`].

```python
from datasets import Dataset
from trl import unpair_preference_dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": [
Â  Â  Â  Â  [{"role": "user", "content": "What color is the sky?"}],
Â  Â  Â  Â  [{"role": "user", "content": "Where is the sun?"}],
Â  Â  ],
Â  Â  "chosen": [
Â  Â  Â  Â  [{"role": "assistant", "content": "It is blue."}],
Â  Â  Â  Â  [{"role": "assistant", "content": "In the sky."}],
Â  Â  ],
Â  Â  "rejected": [
Â  Â  Â  Â  [{"role": "assistant", "content": "It is green."}],
Â  Â  Â  Â  [{"role": "assistant", "content": "In the sea."}],
Â  Â  ],
})

dataset = unpair_preference_dataset(dataset)
```

```python
>>> dataset[0]
{'prompt': [{'role': 'user', 'content': 'What color is the sky?'}],
Â 'completion': [{'role': 'assistant', 'content': 'It is blue.'}],
Â 'label': True}
```

\<Tip warning={true}\>

HÃ£y nhá»› ráº±ng cÃ¡c `completion` `"chosen"` vÃ  `"rejected"` trong má»™t `dataset` sá»Ÿ thÃ­ch cÃ³ thá»ƒ lÃ  tá»‘t hoáº·c xáº¥u.
TrÆ°á»›c khi Ã¡p dá»¥ng [`unpair_preference_dataset`], hÃ£y Ä‘áº£m báº£o ráº±ng táº¥t cáº£ cÃ¡c `completion` `"chosen"` cÃ³ thá»ƒ Ä‘Æ°á»£c gÃ¡n nhÃ£n lÃ  tá»‘t vÃ  táº¥t cáº£ cÃ¡c `completion` `"rejected"` lÃ  xáº¥u.
Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘áº£m báº£o báº±ng cÃ¡ch kiá»ƒm tra Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ tuyá»‡t Ä‘á»‘i cá»§a má»—i `completion`, vÃ­ dá»¥ nhÆ° tá»« má»™t mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng (`reward model`).

\</Tip\>

### Tá»« dataset sá»Ÿ thÃ­ch khÃ´ng theo cáº·p sang language modeling

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch khÃ´ng theo cáº·p thÃ nh má»™t `dataset` `language modeling`, hÃ£y ná»‘i cÃ¡c `prompt` vá»›i cÃ¡c `completion` tá»‘t vÃ o cá»™t `"text"`, vÃ  xÃ³a cÃ¡c cá»™t `prompt`, `completion` vÃ  `label`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["The sky is", "The sun is", "The sky is", "The sun is"],
Â  Â  "completion": [" blue.", " in the sky.", " green.", " in the sea."],
Â  Â  "label": [True, True, False, False],
})

def concatenate_prompt_completion(example):
Â  Â  return {"text": example["prompt"] + example["completion"]}

dataset = dataset.filter(lambda x: x["label"]).map(concatenate_prompt_completion).remove_columns(["prompt", "completion", "label"])
```

```python
>>> dataset[0]
{'text': 'The sky is blue.'}
```

### Tá»« dataset sá»Ÿ thÃ­ch khÃ´ng theo cáº·p sang prompt-completion

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch khÃ´ng theo cáº·p thÃ nh má»™t `dataset` `prompt-completion`, hÃ£y lá»c cÃ¡c nhÃ£n tá»‘t, sau Ä‘Ã³ xÃ³a cÃ¡c cá»™t nhÃ£n.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["The sky is", "The sun is", "The sky is", "The sun is"],
Â  Â  "completion": [" blue.", " in the sky.", " green.", " in the sea."],
Â  Â  "label": [True, True, False, False],
})

dataset = dataset.filter(lambda x: x["label"]).remove_columns(["label"])
```

```python
>>> dataset[0]
{'prompt': 'The sky is', 'completion': ' blue.'}
```

### Tá»« dataset sá»Ÿ thÃ­ch khÃ´ng theo cáº·p sang prompt-only

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` sá»Ÿ thÃ­ch khÃ´ng theo cáº·p thÃ nh má»™t `dataset` `prompt-only`, hÃ£y xÃ³a cÃ¡c cá»™t `completion` vÃ  `label`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["The sky is", "The sun is", "The sky is", "The sun is"],
Â  Â  "completion": [" blue.", " in the sky.", " green.", " in the sea."],
Â  Â  "label": [True, True, False, False],
})

dataset = dataset.remove_columns(["completion", "label"])
```

```python
>>> dataset[0]
{'prompt': 'The sky is'}
```

### Tá»« dataset giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c sang language modeling

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c thÃ nh má»™t `dataset` `language modeling`, hÃ£y ná»‘i cÃ¡c `prompt` vá»›i cÃ¡c `completion` tá»‘t vÃ o cá»™t `"text"`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["Blue light", "Water"],
Â  Â  "completions": [[" scatters more in the atmosphere,", " so the sky is green."],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â [" forms a less dense structure in ice,", " which causes it to expand when it freezes."]],
Â  Â  "labels": [[True, False], [True, True]],
})

def concatenate_prompt_completions(example):
Â  Â  completion = "".join(example["completions"])
Â  Â  return {"text": example["prompt"] + completion}

dataset = dataset.filter(lambda x: all(x["labels"])).map(concatenate_prompt_completions, remove_columns=["prompt", "completions", "labels"])
```

```python
>>> dataset[0]
{'text': 'Blue light scatters more in the atmosphere, so the sky is green.'}
```

### Tá»« dataset giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c sang prompt completion

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c thÃ nh má»™t `dataset` `prompt-completion`, hÃ£y ná»‘i cÃ¡c `completion` tá»‘t láº¡i vÃ  xÃ³a cÃ¡c nhÃ£n.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["Blue light", "Water"],
Â  Â  "completions": [[" scatters more in the atmosphere,", " so the sky is green."],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â [" forms a less dense structure in ice,", " which causes it to expand when it freezes."]],
Â  Â  "labels": [[True, False], [True, True]],
})

def join_completions(example):
Â  Â  completion = "".join(example["completions"])
Â  Â  return {"completion": completion}

dataset = dataset.filter(lambda x: all(x["labels"])).map(join_completions, remove_columns=["completions", "labels"])
```

```python
>>> dataset[0]
{'prompt': 'Blue light', 'completion': ' scatters more in the atmosphere, so the sky is green.'}
```

### Tá»« dataset giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c sang prompt only

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c thÃ nh má»™t `dataset` `prompt-only`, hÃ£y xÃ³a cÃ¡c cá»™t `completions` vÃ  `labels`.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["Blue light", "Water"],
Â  Â  "completions": [[" scatters more in the atmosphere,", " so the sky is green."],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â [" forms a less dense structure in ice,", " which causes it to expand when it freezes."]],
Â  Â  "labels": [[True, False], [True, True]],
})

dataset = dataset.remove_columns(["completions", "labels"])
```

```python
>>> dataset[0]
{'prompt': 'Blue light'}
```

### Tá»« dataset giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c sang sá»Ÿ thÃ­ch khÃ´ng theo cáº·p

Äá»ƒ chuyá»ƒn Ä‘á»•i má»™t `dataset` giÃ¡m sÃ¡t theo tá»«ng bÆ°á»›c thÃ nh má»™t `dataset` sá»Ÿ thÃ­ch khÃ´ng theo cáº·p, hÃ£y ná»‘i cÃ¡c `completions` vÃ  há»£p nháº¥t cÃ¡c `labels`.

PhÆ°Æ¡ng phÃ¡p há»£p nháº¥t cÃ¡c nhÃ£n phá»¥ thuá»™c vÃ o tÃ¡c vá»¥ cá»¥ thá»ƒ. Trong vÃ­ dá»¥ nÃ y, chÃºng tÃ´i sá»­ dá»¥ng phÃ©p toÃ¡n AND logic. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  náº¿u cÃ¡c nhÃ£n cá»§a tá»«ng bÆ°á»›c cho biáº¿t tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a cÃ¡c bÆ°á»›c riÃªng láº», nhÃ£n káº¿t quáº£ sáº½ pháº£n Ã¡nh tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a toÃ n bá»™ chuá»—i.

```python
from datasets import Dataset

dataset = Dataset.from_dict({
Â  Â  "prompt": ["Blue light", "Water"],
Â  Â  "completions": [[" scatters more in the atmosphere,", " so the sky is green."],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â [" forms a less dense structure in ice,", " which causes it to expand when it freezes."]],
Â  Â  "labels": [[True, False], [True, True]],
})

def merge_completions_and_labels(example):
Â  Â  return {"prompt": example["prompt"], "completion": "".join(example["completions"]), "label": all(example["labels"])}

dataset = dataset.map(merge_completions_and_labels, remove_columns=["completions", "labels"])
```

```python
>>> dataset[0]
{'prompt': 'Blue light', 'completion': ' scatters more in the atmosphere, so the sky is green.', 'label': False}
```

## Vision datasets (Dataset hÃ¬nh áº£nh)

Má»™t sá»‘ `trainer` cÅ©ng há»— trá»£ tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯-thá»‹ giÃ¡c (vision-language models - VLMs) báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c cáº·p hÃ¬nh áº£nh-vÄƒn báº£n. Trong trÆ°á»ng há»£p nÃ y, khuyáº¿n nghá»‹ sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng há»™i thoáº¡i, vÃ¬ má»—i mÃ´ hÃ¬nh xá»­ lÃ½ cÃ¡c trÃ¬nh giá»¯ chá»— hÃ¬nh áº£nh trong vÄƒn báº£n theo cÃ¡ch khÃ¡c nhau.

Má»™t `dataset` thá»‹ giÃ¡c há»™i thoáº¡i khÃ¡c vá»›i má»™t `dataset` há»™i thoáº¡i tiÃªu chuáº©n á»Ÿ hai Ä‘iá»ƒm chÃ­nh:

1.  `Dataset` pháº£i chá»©a khÃ³a `images` vá»›i dá»¯ liá»‡u hÃ¬nh áº£nh.
2.  TrÆ°á»ng `"content"` trong cÃ¡c tin nháº¯n pháº£i lÃ  má»™t danh sÃ¡ch cÃ¡c dictionary, trong Ä‘Ã³ má»—i dictionary chá»‰ Ä‘á»‹nh loáº¡i dá»¯ liá»‡u: `"image"` hoáº·c `"text"`.

VÃ­ dá»¥:

```python
# Dataset vÄƒn báº£n:
"content": "What color is the sky?"

# Dataset thá»‹ giÃ¡c:
"content": [
Â  Â  {"type": "image"},Â 
Â  Â  {"type": "text", "text": "What color is the sky in the image?"}
]
```

Má»™t vÃ­ dá»¥ vá» `dataset` thá»‹ giÃ¡c há»™i thoáº¡i lÃ  [openbmb/RLAIF-V-Dataset](https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset). DÆ°á»›i Ä‘Ã¢y lÃ  cháº¿ Ä‘á»™ xem nhÃºng cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n cá»§a `dataset`, cho phÃ©p báº¡n khÃ¡m phÃ¡ nÃ³ trá»±c tiáº¿p:

\<iframe
Â  src="[https://huggingface.co/datasets/trl-lib/rlaif-v/embed/viewer/default/train](https://huggingface.co/datasets/trl-lib/rlaif-v/embed/viewer/default/train)"
Â  frameborder="0"
Â  width="100%"
Â  height="560px"
\>\</iframe\>