#!/usr/bin/env python3
"""
Test script cho HybridVisionDataCollator ƒë·ªÉ verify t·∫•t c·∫£ c√°c scenarios

Usage:
    python test_hybrid_collator.py
"""

import sys
from PIL import Image

def create_test_samples():
    """Create test samples cho different scenarios."""
    
    # Sample 1: Text + Image
    sample_with_image = {
        "conversations": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "Gi·∫£i b√†i to√°n n√†y:"},
                    {"type": "image", "image": Image.new('RGB', (224, 224), color='red')}
                ]
            },
            {
                "role": "assistant",
                "content": [
                    {"type": "text", "text": "ƒê√¢y l√† c√°ch gi·∫£i..."}
                ]
            }
        ]
    }
    
    # Sample 2: Text only
    sample_text_only = {
        "conversations": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "2 + 2 b·∫±ng bao nhi·ªÅu?"}
                ]
            },
            {
                "role": "assistant",
                "content": [
                    {"type": "text", "text": "2 + 2 = 4"}
                ]
            }
        ]
    }
    
    # Sample 3: Multiple images
    sample_multi_images = {
        "conversations": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "So s√°nh hai h√¨nh n√†y:"},
                    {"type": "image", "image": Image.new('RGB', (224, 224), color='blue')},
                    {"type": "image", "image": Image.new('RGB', (224, 224), color='green')}
                ]
            },
            {
                "role": "assistant",
                "content": [
                    {"type": "text", "text": "H√¨nh ƒë·∫ßu l√† m√†u xanh d∆∞∆°ng, h√¨nh th·ª© hai l√† m√†u xanh l√°..."}
                ]
            }
        ]
    }
    
    # Sample 4: Image in answer
    sample_image_in_answer = {
        "conversations": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "V·∫Ω h√¨nh vu√¥ng cho t√¥i"}
                ]
            },
            {
                "role": "assistant",
                "content": [
                    {"type": "text", "text": "ƒê√¢y l√† h√¨nh vu√¥ng:"},
                    {"type": "image", "image": Image.new('RGB', (224, 224), color='yellow')}
                ]
            }
        ]
    }
    
    return [sample_with_image, sample_text_only, sample_multi_images, sample_image_in_answer]

def test_image_detection():
    """Test image detection logic c·ªßa HybridVisionDataCollator."""
    print("üß™ Testing image detection logic...")
    
    class MockHybridCollator:
        def _validate_and_process_image(self, img):
            if img is None:
                return None
            if not hasattr(img, 'convert'):
                return None
            img = img.convert('RGB')
            if img.size[0] < 1 or img.size[1] < 1:
                return None
            return img
        
        def _extract_images_from_conversation(self, conv):
            images = []
            for message in conv:
                for content in message.get("content", []):
                    if content.get("type") == "image" and "image" in content:
                        img = content["image"]
                        processed_img = self._validate_and_process_image(img)
                        if processed_img is not None:
                            images.append(processed_img)
            return images
        
        def _has_real_images(self, conv):
            images = self._extract_images_from_conversation(conv)
            return len(images) > 0
        
        def _create_text_only_conversation(self, conv):
            text_only_conv = []
            for message in conv:
                text_only_message = {
                    "role": message["role"],
                    "content": []
                }
                for content in message.get("content", []):
                    if content.get("type") == "text":
                        text_only_message["content"].append(content)
                if not text_only_message["content"]:
                    text_only_message["content"] = [{"type": "text", "text": ""}]
                text_only_conv.append(text_only_message)
            return text_only_conv
    
    collator = MockHybridCollator()
    test_samples = create_test_samples()
    
    results = []
    for i, sample in enumerate(test_samples):
        conv = sample["conversations"]
        has_images = collator._has_real_images(conv)
        images = collator._extract_images_from_conversation(conv)
        
        print(f"Sample {i}: {'HAS IMAGES' if has_images else 'TEXT ONLY'} ({len(images)} images)")
        
        # Test text-only conversion
        if not has_images:
            text_only_conv = collator._create_text_only_conversation(conv)
            print(f"  Text-only conversion: {len(text_only_conv)} messages")
        
        results.append(has_images)
    
    # Expected: [True, False, True, True]
    expected = [True, False, True, True]
    success = results == expected
    
    print(f"Results: {results}")
    print(f"Expected: {expected}")
    print(f"Image detection test: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    
    return success

def test_batch_classification():
    """Test batch classification logic."""
    print("\nüß™ Testing batch classification...")
    
    test_samples = create_test_samples()
    
    # Mock classification logic
    image_samples = []
    text_only_samples = []
    
    for idx, sample in enumerate(test_samples):
        conv = sample["conversations"]
        
        # Check for images (simplified)
        has_images = False
        for message in conv:
            for content in message.get("content", []):
                if content.get("type") == "image" and content.get("image") is not None:
                    has_images = True
                    break
            if has_images:
                break
        
        if has_images:
            image_samples.append((idx, sample))
            print(f"Sample {idx}: IMAGE SAMPLE ‚úÖ")
        else:
            text_only_samples.append((idx, sample))
            print(f"Sample {idx}: TEXT ONLY üìù")
    
    print(f"\nBatch composition:")
    print(f"- Image samples: {len(image_samples)}")
    print(f"- Text-only samples: {len(text_only_samples)}")
    
    # Expected: 3 image samples, 1 text-only
    success = len(image_samples) == 3 and len(text_only_samples) == 1
    
    print(f"Batch classification test: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    
    return success

def test_image_token_insertion():
    """Test strategic image token insertion."""
    print("\nüß™ Testing image token insertion...")
    
    def _insert_image_token_strategically(text, num_images=1):
        if '<image>' in text:
            return text
            
        lines = text.split('\n')
        
        # Strategy 1: Insert sau user role marker
        for i, line in enumerate(lines):
            if any(marker in line.lower() for marker in ['<|user|>', 'user:', 'human:']):
                insert_pos = i + 1
                for _ in range(num_images):
                    lines.insert(insert_pos, '<image>')
                    insert_pos += 1
                return '\n'.join(lines)
        
        # Strategy 2: Insert ·ªü ƒë·∫ßu content
        if len(lines) > 0:
            for _ in range(num_images):
                lines.insert(1, '<image>')
            return '\n'.join(lines)
        
        # Fallback: insert ·ªü ƒë·∫ßu
        image_tokens = '\n'.join(['<image>'] * num_images)
        return image_tokens + '\n' + text
    
    # Test cases
    test_texts = [
        "user: What is 2+2?\nassistant: 2+2 = 4",
        "<|user|>\nSolve this problem\n<|assistant|>\nHere's the solution",
        "Simple text without role markers",
        ""
    ]
    
    success = True
    for i, text in enumerate(test_texts):
        result = _insert_image_token_strategically(text, num_images=1)
        has_token = '<image>' in result
        
        print(f"Test {i}: {'‚úÖ' if has_token else '‚ùå'}")
        print(f"  Original: {repr(text[:50])}")
        print(f"  Result: {repr(result[:100])}")
        
        if not has_token:
            success = False
    
    print(f"Image token insertion test: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    
    return success

def test_mixed_batch_scenarios():
    """Test different batch scenarios."""
    print("\nüß™ Testing mixed batch scenarios...")
    
    test_samples = create_test_samples()
    
    scenarios = [
        {"name": "Pure image batch", "samples": [0, 2, 3]},  # All have images
        {"name": "Pure text batch", "samples": [1]},         # Only text
        {"name": "Mixed batch", "samples": [0, 1, 2]},       # Mix of both
        {"name": "All samples", "samples": [0, 1, 2, 3]}     # Everything
    ]
    
    success = True
    
    for scenario in scenarios:
        print(f"\nScenario: {scenario['name']}")
        selected_samples = [test_samples[i] for i in scenario['samples']]
        
        # Classify samples
        image_count = 0
        text_count = 0
        
        for sample in selected_samples:
            conv = sample["conversations"]
            has_images = False
            for message in conv:
                for content in message.get("content", []):
                    if content.get("type") == "image" and content.get("image") is not None:
                        has_images = True
                        break
                if has_images:
                    break
            
            if has_images:
                image_count += 1
            else:
                text_count += 1
        
        print(f"  Image samples: {image_count}, Text samples: {text_count}")
        
        # Determine expected processing type
        if image_count > 0 and text_count > 0:
            expected_type = "mixed"
        elif image_count > 0:
            expected_type = "image_only"
        else:
            expected_type = "text_only"
        
        print(f"  Expected processing: {expected_type}")
        
        # Verify this matches scenario expectation
        scenario_success = True
        if scenario['name'] == "Pure image batch" and expected_type != "image_only":
            scenario_success = False
        elif scenario['name'] == "Pure text batch" and expected_type != "text_only":
            scenario_success = False
        elif scenario['name'] == "Mixed batch" and expected_type != "mixed":
            scenario_success = False
        elif scenario['name'] == "All samples" and expected_type != "mixed":
            scenario_success = False
        
        print(f"  Result: {'‚úÖ PASSED' if scenario_success else '‚ùå FAILED'}")
        success &= scenario_success
    
    print(f"\nMixed batch scenarios test: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    
    return success

def main():
    """Main test function."""
    print("üîß HybridVisionDataCollator Comprehensive Test")
    print("=" * 60)
    
    success = True
    
    # Test 1: Image detection
    success &= test_image_detection()
    
    # Test 2: Batch classification
    success &= test_batch_classification()
    
    # Test 3: Image token insertion
    success &= test_image_token_insertion()
    
    # Test 4: Mixed batch scenarios
    success &= test_mixed_batch_scenarios()
    
    print(f"\n{'='*60}")
    if success:
        print("üéâ ALL TESTS PASSED!")
        print("HybridVisionDataCollator should handle all scenarios correctly:")
        print("  ‚úÖ Pure image batches")
        print("  ‚úÖ Pure text batches")  
        print("  ‚úÖ Mixed batches")
        print("  ‚úÖ Strategic token insertion")
        print("  ‚úÖ Image validation")
    else:
        print("‚ùå SOME TESTS FAILED!")
        print("Please review the implementation.")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)