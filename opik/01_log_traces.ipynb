{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2177b38c",
   "metadata": {},
   "source": [
    "# Log traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5323baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik.integrations.openai import track_openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "client = track_openai(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04974a",
   "metadata": {},
   "source": [
    "### Using an integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453f4a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Started logging traces to the \"Default Project\" project at https://www.comet.com/opik/api/v1/session/redirect/projects/?trace_id=01983a90-acbb-7a11-9a6f-fe39ea3e2495&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\":\"user\", \"content\": \"Hello, world!\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3414a62",
   "metadata": {},
   "source": [
    "### Using function decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ed8d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here to assist you with any specific information or topics you'd like to explore. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "import opik\n",
    "import openai\n",
    "\n",
    "@opik.track\n",
    "def retrieve_context(input_text):\n",
    "    # Your retrieval logic here, here we are just returning a hardcoded list of strings\n",
    "    context =[\n",
    "        \"What specific information are you looking for?\",\n",
    "        \"How can I assist you with your interests today?\",\n",
    "        \"Are there any topics you'd like to explore or learn more about?\",\n",
    "    ]\n",
    "    return context\n",
    "@opik.track\n",
    "def generate_response(input_text, context):\n",
    "    full_prompt = (\n",
    "        f\" If the user asks a question that is not specific, use the context to provide a relevant response.\\n\"\n",
    "        f\"Context: {', '.join(context)}\\n\"\n",
    "        f\"User: {input_text}\\n\"\n",
    "        f\"AI:\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": full_prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "@opik.track(name=\"my_llm_application\")\n",
    "def llm_chain(input_text):\n",
    "    context = retrieve_context(input_text)\n",
    "    response = generate_response(input_text, context)\n",
    "    return response\n",
    "# Use the LLM chain\n",
    "result = llm_chain(\"Hello, how are you?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce43a51",
   "metadata": {},
   "source": [
    "The `@track` decorator will only track the input and output of the decorated function. If you are using OpenAI, we recommend you also use the `track_openai` function to track the LLM call as well as token usage:\n",
    "\n",
    "```python\n",
    "from opik.integrations.openai import track_openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "client = track_openai(client)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278445eb",
   "metadata": {},
   "source": [
    "### Scoring traces\n",
    "\n",
    "B·∫°n c√≥ th·ªÉ log (ghi l·∫°i) c√°c ƒëi·ªÉm ph·∫£n h·ªìi cho c√°c **trace** b·∫±ng c√°ch s·ª≠ d·ª•ng h√†m `opik_context.update_current_trace`. ƒêi·ªÅu n√†y c√≥ th·ªÉ h·ªØu √≠ch n·∫øu c√≥ m·ªôt s·ªë **metrics** (ch·ªâ s·ªë) ƒë√£ ƒë∆∞·ª£c b√°o c√°o nh∆∞ m·ªôt ph·∫ßn c·ªßa `chain` ho·∫∑c `agent` c·ªßa b·∫°n\n",
    "\n",
    "ƒê·ªÉ d·ªÖ hi·ªÉu, h√£y coi m·ªói y√™u c·∫ßu b·∫°n g·ª≠i ƒë·∫øn ·ª©ng d·ª•ng LLM c·ªßa m√¨nh l√† m·ªôt \"nhi·ªám v·ª•\". **`Trace`** ch√≠nh l√† **to√†n b·ªô h√†nh tr√¨nh x·ª≠ l√Ω** nhi·ªám v·ª• ƒë√≥, t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. \"Trace\" l√† g√¨ trong ng·ªØ c·∫£nh LLM?\n",
    "\n",
    "M·ªôt `trace` ghi l·∫°i t·∫•t c·∫£ c√°c b∆∞·ªõc m√† ·ª©ng d·ª•ng c·ªßa b·∫°n ƒë√£ th·ª±c hi·ªán ƒë·ªÉ t·∫°o ra m·ªôt c√¢u tr·∫£ l·ªùi cu·ªëi c√πng. Trong m·ªôt ·ª©ng d·ª•ng LLM ph·ª©c t·∫°p, m·ªôt `trace` kh√¥ng ch·ªâ l√† m·ªôt l·∫ßn g·ªçi API duy nh·∫•t. N√≥ c√≥ th·ªÉ bao g·ªìm nhi·ªÅu b∆∞·ªõc, v√≠ d·ª•:\n",
    "\n",
    "  * **ƒê·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng:** \"T√≥m t·∫Øt b√†i b√°o n√†y cho t√¥i.\"\n",
    "  * **B∆∞·ªõc 1: G·ªçi Tool/API:** H·ªá th·ªëng g·ªçi m·ªôt c√¥ng c·ª• ƒë·ªÉ l·∫•y n·ªôi dung t·ª´ URL c·ªßa b√†i b√°o.\n",
    "  * **B∆∞·ªõc 2: X·ª≠ l√Ω d·ªØ li·ªáu:** Tr√≠ch xu·∫•t vƒÉn b·∫£n ch√≠nh t·ª´ trang web.\n",
    "  * **B∆∞·ªõc 3: G·ªçi LLM:** G·ª≠i vƒÉn b·∫£n ƒë√£ tr√≠ch xu·∫•t ƒë·∫øn m·ªôt LLM (v√≠ d·ª•: GPT-4, Gemini) v·ªõi `prompt` \"H√£y t√≥m t·∫Øt vƒÉn b·∫£n sau: ...\".\n",
    "  * **B∆∞·ªõc 4: Ph√¢n t√≠ch k·∫øt qu·∫£ (t√πy ch·ªçn):** H·ªá th·ªëng c√≥ th·ªÉ ch·∫°y m·ªôt ph√¢n t√≠ch c·∫£m x√∫c (sentiment analysis) tr√™n b·∫£n t√≥m t·∫Øt.\n",
    "  * **ƒê·∫ßu ra cu·ªëi c√πng:** Tr·∫£ v·ªÅ b·∫£n t√≥m t·∫Øt cho ng∆∞·ªùi d√πng.\n",
    "\n",
    "To√†n b·ªô chu·ªói s·ª± ki·ªán n√†y ƒë∆∞·ª£c g√≥i g·ªçn trong m·ªôt **`trace`**. Vi·ªác theo d√µi (tracking) c√°c `trace` gi√∫p b·∫°n c√≥ m·ªôt c√°i nh√¨n chi ti·∫øt v√† minh b·∫°ch v·ªÅ c√°ch ·ª©ng d·ª•ng c·ªßa m√¨nh ho·∫°t ƒë·ªông \"d∆∞·ªõi mui xe\".\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. \"Scoring\" (Ch·∫•m ƒëi·ªÉm) m·ªôt Trace nghƒ©a l√† g√¨?\n",
    "\n",
    "**Scoring** l√† qu√° tr√¨nh b·∫°n **g√°n m·ªôt ho·∫∑c nhi·ªÅu ƒëi·ªÉm s·ªë (score) ho·∫∑c nh√£n (label) cho m·ªôt `trace`** ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng ho·∫∑c hi·ªáu su·∫•t c·ªßa n√≥. ƒê√¢y kh√¥ng ph·∫£i l√† ƒëi·ªÉm s·ªë do LLM t·ª± ƒë·ªông t·∫°o ra, m√† l√† c√°c **`metrics` (ch·ªâ s·ªë)** m√† *b·∫°n* ƒë·ªãnh nghƒ©a v√† ghi l·∫°i.\n",
    "\n",
    "C√°c lo·∫°i ƒëi·ªÉm s·ªë b·∫°n c√≥ th·ªÉ `log` (ghi l·∫°i) bao g·ªìm:\n",
    "\n",
    "  * **ƒêi·ªÉm ph·∫£n h·ªìi c·ªßa ng∆∞·ªùi d√πng:** Ng∆∞·ªùi d√πng c√≥ b·∫•m n√∫t \"th√≠ch\" üëç ho·∫∑c \"kh√¥ng th√≠ch\" üëé kh√¥ng?\n",
    "  * **ƒê·ªô ch√≠nh x√°c (Accuracy):** C√¢u tr·∫£ l·ªùi c√≥ ƒë√∫ng s·ª± th·∫≠t kh√¥ng? (V√≠ d·ª•: b·∫°n c√≥ th·ªÉ ch·∫•m ƒëi·ªÉm 1 n·∫øu ƒë√∫ng, 0 n·∫øu sai).\n",
    "  * **M·ª©c ƒë·ªô li√™n quan (Relevance):** K·∫øt qu·∫£ t√¨m ki·∫øm ho·∫∑c c√¢u tr·∫£ l·ªùi c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng?\n",
    "  * **ƒê·ªôc h·∫°i (Toxicity):** C√¢u tr·∫£ l·ªùi c√≥ ch·ª©a n·ªôi dung kh√¥ng ph√π h·ª£p kh√¥ng?\n",
    "  * **Ch·ªâ s·ªë nghi·ªáp v·ª• (Business Metrics):** K·∫øt qu·∫£ c√≥ gi√∫p ng∆∞·ªùi d√πng ho√†n th√†nh m·ªôt t√°c v·ª• c·ª• th·ªÉ kh√¥ng (v√≠ d·ª•: ƒë·∫∑t h√†ng th√†nh c√¥ng)?\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Vai tr√≤ c·ªßa `opik_context.update_current_trace`\n",
    "\n",
    "ƒê√¢y ch√≠nh l√† c√¥ng c·ª• k·ªπ thu·∫≠t ƒë·ªÉ b·∫°n th·ª±c hi·ªán vi·ªác \"scoring\".\n",
    "\n",
    "Khi m·ªôt `chain` ho·∫∑c `agent` c·ªßa b·∫°n ƒëang ch·∫°y, n√≥ ƒëang ·ªü trong m·ªôt `trace` ƒëang ho·∫°t ƒë·ªông. H√†m `opik_context.update_current_trace` cho ph√©p b·∫°n **th√™m th√¥ng tin v√†o `trace` ƒë√≥ ngay t·∫°i th·ªùi ƒëi·ªÉm n√≥ ƒëang ch·∫°y**.\n",
    "\n",
    "C·ª• th·ªÉ, b·∫°n c√≥ th·ªÉ th√™m c√°c `score` m√† b·∫°n ƒë√£ t√≠nh to√°n ƒë∆∞·ª£c. V√≠ d·ª•, sau khi LLM tr·∫£ v·ªÅ k·∫øt qu·∫£, b·∫°n c√≥ th·ªÉ ch·∫°y m·ªôt h√†m ri√™ng ƒë·ªÉ ki·ªÉm tra xem c√¢u tr·∫£ l·ªùi c√≥ ch·ª©a th√¥ng tin tr√≠ch d·∫´n ngu·ªìn hay kh√¥ng, v√† sau ƒë√≥ g·ªçi `update_current_trace` ƒë·ªÉ ghi l·∫°i ƒëi·ªÉm \"c√≥ tr√≠ch d·∫´n\" = 1 ho·∫∑c 0.\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. V√≠ d·ª• th·ª±c t·∫ø trong m·ªôt `chain`\n",
    "\n",
    "H√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n c√≥ m·ªôt `chain` d·ªãch thu·∫≠t v√† ƒë√°nh gi√° c·∫£m x√∫c:\n",
    "\n",
    "1.  **Input:** \"I love this new product, it's amazing\\!\"\n",
    "2.  **Chain Step 1 (D·ªãch thu·∫≠t):** D·ªãch sang ti·∫øng Vi·ªát -\\> \"T√¥i y√™u s·∫£n ph·∫©m m·ªõi n√†y, n√≥ th·∫≠t tuy·ªát v·ªùi\\!\"\n",
    "3.  **Chain Step 2 (ƒê√°nh gi√° c·∫£m x√∫c):** Ph√¢n t√≠ch c√¢u ti·∫øng Vi·ªát v√† cho ra k·∫øt qu·∫£ `sentiment: \"T√≠ch c·ª±c\"`.\n",
    "4.  **Chain Step 3 (T·ª± ƒë√°nh gi√°):** B·∫°n c√≥ m·ªôt h√†m n·ªôi b·ªô ƒë·ªÉ ki·ªÉm tra xem k·∫øt qu·∫£ d·ªãch c√≥ gi·ªØ nguy√™n √Ω nghƒ©a kh√¥ng. H√†m n√†y tr·∫£ v·ªÅ `{ \"translation_quality\": 0.95 }`.\n",
    "\n",
    "L√∫c n√†y, b·∫°n c√≥ th·ªÉ d√πng `opik_context.update_current_trace` ƒë·ªÉ ghi l·∫°i ƒëi·ªÉm s·ªë n√†y:\n",
    "\n",
    "```python\n",
    "# Gi·∫£ s·ª≠ ƒë√¢y l√† ƒëo·∫°n code trong chain c·ªßa b·∫°n\n",
    "from opik import opik_context\n",
    "\n",
    "# ... code d·ªãch thu·∫≠t v√† ƒë√°nh gi√° c·∫£m x√∫c ...\n",
    "\n",
    "# T·ª± t√≠nh to√°n m·ªôt metric\n",
    "translation_score = calculate_translation_quality(original_text, translated_text) # Gi·∫£ s·ª≠ tr·∫£ v·ªÅ 0.95\n",
    "\n",
    "# Ghi l·∫°i ƒëi·ªÉm s·ªë n√†y v√†o trace hi·ªán t·∫°i\n",
    "opik_context.update_current_trace({\n",
    "    \"scores\": {\n",
    "        \"translation_quality\": translation_score,\n",
    "        \"sentiment_score\": 1 # 1 cho T√≠ch c·ª±c, -1 cho Ti√™u c·ª±c\n",
    "    }\n",
    "})\n",
    "\n",
    "```\n",
    "\n",
    "Khi b·∫°n xem l·∫°i `trace` n√†y tr√™n giao di·ªán c·ªßa `opik`, b·∫°n s·∫Ω th·∫•y kh√¥ng ch·ªâ c√°c b∆∞·ªõc th·ª±c thi m√† c√≤n c·∫£ c√°c ƒëi·ªÉm s·ªë `translation_quality` v√† `sentiment_score` m√† b·∫°n ƒë√£ ghi l·∫°i.\n",
    "\n",
    "### L·ª£i √≠ch ch√≠nh\n",
    "\n",
    "  * **G·ª° l·ªói (Debugging):** D·ªÖ d√†ng x√°c ƒë·ªãnh b∆∞·ªõc n√†o trong `chain` ho·∫∑c `agent` ƒëang ho·∫°t ƒë·ªông k√©m hi·ªáu qu·∫£.\n",
    "  * **ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng:** Thu th·∫≠p d·ªØ li·ªáu c√≥ c·∫•u tr√∫c v·ªÅ hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh theo c√°c ti√™u ch√≠ quan tr·ªçng ƒë·ªëi v·ªõi b·∫°n.\n",
    "  * **C·∫£i ti·∫øn li√™n t·ª•c:** D·ª±a v√†o c√°c `score` ƒë√£ thu th·∫≠p, b·∫°n c√≥ th·ªÉ tinh ch·ªânh `prompt`, thay ƒë·ªïi m√¥ h√¨nh, ho·∫∑c ƒëi·ªÅu ch·ªânh logic c·ªßa `agent` ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ƒë·∫ßu ra theo th·ªùi gian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012a9de",
   "metadata": {},
   "source": [
    "### Logging additional data\n",
    "\n",
    "\n",
    "Nh∆∞ ƒë√£ ƒë·ªÅ c·∫≠p ·ªü tr√™n, `decorator` **`@track`** ch·ªâ ghi nh·∫≠t k√Ω **ƒë·∫ßu v√†o (`input`)** v√† **ƒë·∫ßu ra (`output`)** c·ªßa h√†m ƒë∆∞·ª£c trang tr√≠. N·∫øu b·∫°n mu·ªën ghi nh·∫≠t k√Ω d·ªØ li·ªáu b·ªï sung, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m **`update_current_span`** v√† h√†m **`update_current_trace`** ƒë·ªÉ c·∫≠p nh·∫≠t th·ªß c√¥ng `span` v√† `trace`:\n",
    "\n",
    "```python\n",
    "from opik import track, opik_context\n",
    "\n",
    "@track\n",
    "def llm_chain(input_text):\n",
    "    # LLM chain code\n",
    "    # ...\n",
    "\n",
    "    # Update the trace\n",
    "    opik_context.update_current_trace(\n",
    "        tags=[\"llm_chatbot\"],\n",
    "    )\n",
    "\n",
    "    # Update the span\n",
    "    opik_context.update_current_span(\n",
    "        name=\"llm_chain\"\n",
    "    )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867126e8",
   "metadata": {},
   "source": [
    "### Configuring the project name\n",
    "\n",
    "```python\n",
    "import opik\n",
    "\n",
    "@opik.track(project_name=\"my_project\")\n",
    "def my_function(input):\n",
    "    # Function code\n",
    "    return input\n",
    "\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.environ[\"OPIK_PROJECT_NAME\"] = \"my_project\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ebfd5b",
   "metadata": {},
   "source": [
    "### Flushing the trace\n",
    "\n",
    "\"Flushing the trace\" (X·∫£ trace) c√≥ nghƒ©a l√† **bu·ªôc t·∫•t c·∫£ d·ªØ li·ªáu theo d√µi (trace data) ƒë√£ ƒë∆∞·ª£c thu th·∫≠p ph·∫£i ƒë∆∞·ª£c g·ª≠i ƒëi ngay l·∫≠p t·ª©c** thay v√¨ ch·ªù ƒë·ª£i ƒë·ªÉ g·ª≠i theo t·ª´ng ƒë·ª£t.\n",
    "\n",
    "Th√¥ng th∆∞·ªùng, ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t, c√°c h·ªá th·ªëng gi√°m s√°t s·∫Ω thu th·∫≠p d·ªØ li·ªáu v√†o m·ªôt b·ªô ƒë·ªám (buffer) v√† g·ª≠i ch√∫ng ƒëi m·ªôt c√°ch b·∫•t ƒë·ªìng b·ªô trong n·ªÅn. Tuy nhi√™n, vi·ªác \"x·∫£ trace\" s·∫Ω ƒë·∫£m b·∫£o d·ªØ li·ªáu c·ªßa b·∫°n kh√¥ng b·ªã m·∫•t, ƒë·∫∑c bi·ªát l√† trong c√°c ·ª©ng d·ª•ng ch·∫°y nhanh v√† k·∫øt th√∫c ƒë·ªôt ng·ªôt.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# Ho·∫°t ƒë·ªông M·∫∑c ƒë·ªãnh (`flush=False`) ‚öôÔ∏è\n",
    "\n",
    "ƒê·ªÉ kh√¥ng l√†m ch·∫≠m ·ª©ng d·ª•ng ch√≠nh c·ªßa b·∫°n, c√°c c√¥ng c·ª• theo d√µi nh∆∞ `opik` th∆∞·ªùng ho·∫°t ƒë·ªông theo c∆° ch·∫ø b·∫•t ƒë·ªìng b·ªô:\n",
    "\n",
    "1.  **Thu th·∫≠p d·ªØ li·ªáu:** Khi `chain` ho·∫∑c `agent` c·ªßa b·∫°n ch·∫°y, d·ªØ li·ªáu v·ªÅ c√°c b∆∞·ªõc th·ª±c thi, th·ªùi gian, v√† metadata ƒë∆∞·ª£c ghi v√†o m·ªôt b·ªô ƒë·ªám t·∫°m th·ªùi trong b·ªô nh·ªõ.\n",
    "2.  **G·ª≠i theo l√¥ (Batching):** M·ªôt ti·∫øn tr√¨nh ch·∫°y n·ªÅn (background process) s·∫Ω ƒë·ªãnh k·ª≥ gom d·ªØ li·ªáu t·ª´ b·ªô ƒë·ªám v√† g·ª≠i ch√∫ng th√†nh t·ª´ng l√¥ ƒë·∫øn m√°y ch·ªß gi√°m s√°t.\n",
    "\n",
    "C√°ch n√†y r·∫•t hi·ªáu qu·∫£ v√¨ n√≥ gi·∫£m thi·ªÉu s·ªë l∆∞·ª£ng y√™u c·∫ßu m·∫°ng v√† kh√¥ng b·∫Øt ·ª©ng d·ª•ng c·ªßa b·∫°n ph·∫£i ch·ªù ƒë·ª£i.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# Khi n√†o c·∫ßn \"X·∫£ Trace\" (`flush=True`) ‚ö°\n",
    "\n",
    "V·∫•n ƒë·ªÅ v·ªõi c∆° ch·∫ø m·∫∑c ƒë·ªãnh l√† n·∫øu ·ª©ng d·ª•ng c·ªßa b·∫°n k·∫øt th√∫c qu√° nhanh (v√≠ d·ª•: m·ªôt k·ªãch b·∫£n d√≤ng l·ªánh, m·ªôt h√†m serverless), ch∆∞∆°ng tr√¨nh ch√≠nh c√≥ th·ªÉ tho√°t **tr∆∞·ªõc khi** ti·∫øn tr√¨nh n·ªÅn k·ªãp g·ª≠i d·ªØ li·ªáu ƒëi. K·∫øt qu·∫£ l√† b·∫°n s·∫Ω b·ªã m·∫•t `trace` ƒë√≥.\n",
    "\n",
    "Vi·ªác thi·∫øt l·∫≠p **`flush=True`** trong decorator `@track` gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y.\n",
    "\n",
    "```python\n",
    "from opik import track\n",
    "\n",
    "@track(flush=True)\n",
    "def my_short_running_task():\n",
    "    # ... c√°c b∆∞·ªõc x·ª≠ l√Ω nhanh ...\n",
    "    return \"Done\"\n",
    "\n",
    "# Khi h√†m n√†y ch·∫°y xong, ch∆∞∆°ng tr√¨nh s·∫Ω ƒë·ª£i cho ƒë·∫øn khi \n",
    "# to√†n b·ªô d·ªØ li·ªáu c·ªßa trace n√†y ƒë∆∞·ª£c g·ª≠i ƒëi th√†nh c√¥ng.\n",
    "my_short_running_task()\n",
    "```\n",
    "\n",
    "Khi `flush=True`, sau khi h√†m ƒë∆∞·ª£c `decorate` th·ª±c thi xong, ch∆∞∆°ng tr√¨nh s·∫Ω **d·ª´ng l·∫°i v√† ch·ªù** cho ƒë·∫øn khi t·∫•t c·∫£ d·ªØ li·ªáu c·ªßa `trace` ƒë√≥ ƒë∆∞·ª£c g·ª≠i ƒëi v√† nh·∫≠n ƒë∆∞·ª£c x√°c nh·∫≠n t·ª´ m√°y ch·ªß.\n",
    "\n",
    "**C√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng ch√≠nh:**\n",
    "\n",
    "  * **H√†m Serverless:** Nh∆∞ AWS Lambda hay Google Cloud Functions, v√¨ m√¥i tr∆∞·ªùng th·ª±c thi c√≥ th·ªÉ b·ªã ƒë√≥ng bƒÉng ho·∫∑c t·∫Øt ngay sau khi h√†m ho√†n th√†nh.\n",
    "  * **K·ªãch b·∫£n ng·∫Øn (Scripts):** C√°c file Python ch·∫°y m·ªôt l·∫ßn ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu r·ªìi tho√°t.\n",
    "  * **G·ª° l·ªói (Debugging):** Khi b·∫°n mu·ªën th·∫•y `trace` xu·∫•t hi·ªán tr√™n dashboard ngay l·∫≠p t·ª©c ƒë·ªÉ ki·ªÉm tra.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# ƒê√°nh ƒë·ªïi c·∫ßn c√¢n nh·∫Øc\n",
    "\n",
    "  * **`flush=False` (M·∫∑c ƒë·ªãnh):**\n",
    "\n",
    "      * ‚úÖ **∆Øu ƒëi·ªÉm:** Hi·ªáu su·∫•t cao, ƒë·ªô tr·ªÖ (latency) c·ªßa ·ª©ng d·ª•ng th·∫•p.\n",
    "      * ‚ö†Ô∏è **Nh∆∞·ª£c ƒëi·ªÉm:** C√≥ nguy c∆° m·∫•t d·ªØ li·ªáu n·∫øu ·ª©ng d·ª•ng k·∫øt th√∫c ƒë·ªôt ng·ªôt.\n",
    "\n",
    "  * **`flush=True`:**\n",
    "\n",
    "      * ‚úÖ **∆Øu ƒëi·ªÉm:** ƒê·∫£m b·∫£o 100% d·ªØ li·ªáu ƒë∆∞·ª£c ghi l·∫°i.\n",
    "      * ‚ö†Ô∏è **Nh∆∞·ª£c ƒëi·ªÉm:** TƒÉng nh·∫π ƒë·ªô tr·ªÖ cho t√°c v·ª• v√¨ ph·∫£i ch·ªù m·∫°ng, c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn c√°c ·ª©ng d·ª•ng ƒë√≤i h·ªèi ph·∫£n h·ªìi t·ª©c th√¨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93df7a7",
   "metadata": {},
   "source": [
    "### Disabling automatic logging of function input and output\n",
    "\n",
    "```python\n",
    "import opik\n",
    "\n",
    "@opik.track(capture_input=False, capture_output=False)\n",
    "def llm_chain(input_text):\n",
    "    # LLM chain code\n",
    "    return input_text\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdbd929",
   "metadata": {},
   "source": [
    "### Disable all tracing\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.environ[\"OPIK_TRACK_DISABLE\"] = \"true\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8467fd1",
   "metadata": {},
   "source": [
    "## Using the low-level Opik client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800d26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik import Opik\n",
    "client = Opik(project_name=\"Opik client demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fafa0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Started logging traces to the \"Opik client demo\" project at https://www.comet.com/opik/api/v1/session/redirect/projects/?trace_id=01983ab0-44e0-7852-adae-5805500e69ed&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==.\n"
     ]
    }
   ],
   "source": [
    "# Create a trace\n",
    "trace = client.trace(\n",
    "    name=\"my_trace\",\n",
    "    input={\"user_question\": \"Hello, how are you?\"},\n",
    "    output={\"response\": \"Comment √ßa va?\"}\n",
    ")\n",
    "# Add a span\n",
    "trace.span(\n",
    "    name=\"Add prompt template\",\n",
    "    input={\"text\": \"Hello, how are you?\", \"prompt_template\": \"Translate the following text to French: {text}\"},\n",
    "    output={\"text\": \"Translate the following text to French: hello, how are you?\"}\n",
    ")\n",
    "# Add an LLM call\n",
    "trace.span(\n",
    "    name=\"llm_call\",\n",
    "    type=\"llm\",\n",
    "    input={\"prompt\": \"Translate the following text to French: hello, how are you?\"},\n",
    "    output={\"response\": \"Comment √ßa va?\"}\n",
    ")\n",
    "# End the trace\n",
    "trace.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b5df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
